\chapter{Graphentheorie}
Wir wollen zum Abschluß der Vorlesung wenigstens ein graphentheoretisches Problem
vorstellen: Das Problem der Berechnung  kürzester Wege. 


\section{Die Berechnung kürzester Wege}
Um das Problem der Berechnung kürzester Wege formulieren zu können, führen wir zunächst 
den Begriff des \emph{gewichteten Graphen} ein.  

\begin{Definition}[Gewichteter Graph]
{\em
  Ein  {\em gewichteter Graph} ist ein Tripel
   $\langle \nodes, \edges, \weight{\cdot} \rangle$ so dass gilt:
  \begin{enumerate}
  \item $\nodes$ ist eine Menge von \emph{Knoten}.
  \item $\edges \subseteq \nodes \times \nodes$ ist eine Menge von \emph{Kanten}.
  \item $\weight{\cdot}: \edges \rightarrow \N \backslash\{0\}$ ist eine Funktion,
        die jeder Kante eine positive \emph{Länge} zuordnet.
        \conclude
  \end{enumerate}
}
\end{Definition}

\noindent
Ein \emph{Pfad} $P$ ist eine Liste der Form \\[0.2cm]
\hspace*{1.3cm} $P = [ x_1, x_2, x_3, \cdots, x_n ]$ \\[0.2cm]
so dass für alle $i = 1, \cdots, n-1$ gilt: \\[0.2cm]
\hspace*{1.3cm} $\pair(x_i,x_{i+1}) \in \edges$. \\[0.2cm]
Die Menge aller Pfade bezeichnen wir mit $\paths$.
Die Länge eines Pfads definieren wir als die Summe der Länge aller Kanten:
\\[0.2cm]
\hspace*{1.3cm} $\Weight{[x_1,x_2, \cdots, x_n]} \df \sum\limits_{i=1}^{n-1} \Weight{\pair(x_i,x_{i+1})}$. \\[0.2cm]
Ist $p = [x_1, x_2, \cdots, x_n]$ ein Pfad, so sagen wir, dass $p$ den Knoten $x_1$ mit dem
Knoten $x_n$ verbindet.   Die Menge alle Pfade, die den Knoten $v$ mit dem Knoten $w$
verbinden, bezeichnen wir als \\[0.2cm]
\hspace*{1.3cm} 
 $\paths(v,w) \df \bigl\{ [x_1, x_2, \cdots, x_n] \in \paths \mid x_1 = v \,\wedge\, x_n = w \}$.
\\[0.2cm]
Damit können wir nun das Problem der Berechnung kürzester Wege formulieren.
\begin{Definition}[Kürzeste-Wege-Problem]
{\em
  Gegeben sei ein gewichteter Graph $G = \langle \nodes, \edges, \weight{\cdot} \rangle$ 
  und ein  Knoten $\source \in \nodes$.  Dann besteht das 
  {\em kürzeste-Wege-Problem}  darin, die folgende Funktion zu berechnen: \\[0.2cm]
  \hspace*{1.3cm} $\spath: \nodes \rightarrow \N$ \\[0.1cm]
  \hspace*{1.3cm} $\spath(v) \df \mathtt{min}\bigl\{ \weight{p} \mid p \in \paths(\source,v) \bigr\}$.
  \conclude  
}
\end{Definition}

\subsection{Ein naiver Algorithmus zur Lösung des kürzeste-Wege-Problems}
Als erstes betrachten wir einen ganz naiven Algorithmus zur Lösung des kürzeste-Wege-Problems.
Die Idee ist, dass wir eine Funktion \\[0.2cm]
\hspace*{1.3cm} $\texttt{dist}: \nodes \rightarrow \N \cup \{\Omega\}$ \\[0.2cm]
definieren, die für einen Punkt $u \in \nodes$ eine obere Abschätzung des Abstandes zum Knoten
\textsl{source} angibt, es soll also immer gelten: \\[0.2cm]
\hspace*{1.3cm} $\textsl{dist}(u) \not= \Omega \;\rightarrow\; \spath(u) \leq
\textsl{dist}(u)$. \\[0.2cm]
Die Funktion \textsl{dist} liefert zu einem Knoten $x$ die kürzeste bisher
bekannte Entfernung zum Knoten \textsl{source}.  Solange noch kein Pfad von
\textsl{source} zu dem Knoten $u$ gefunden worden ist, gilt $\textsl{dist}(u) = \Omega$.
Anfangs ist die Funktion $\textsl{dist}()$ also nur für den Knoten \textsl{source}
definiert, es gilt \\[0.2cm]
\hspace*{1.3cm} $\textsl{dist}(\textsl{source}) = 0$. \\[0.2cm]
Später, wenn wir für einen Knoten $u$ einen Pfad gefunden haben, der den Knoten
\textsl{source} mit dem Knoten $u$ verbindet und wenn es zusätzlich eine Kante
$\pair(u,v)$ gibt, die den Knoten $u$ mit einem anderen Knoten $v$ verbindet, dann wissen
wir, dass auch der Knoten $v$ von \textsl{source} erreichbar ist.  Zusätzlich wissen wir,
dass dieser Weg die Länge $\textsl{dist}(u) + \weight{\pair(u,v)}$ hat.  Falls bisher also
$\textsl{dist}(v)$ undefiniert war, weil wir noch keinen Weg gefunden hatten, der
\textsl{source} mit $v$ verbindet, können wir \\
\hspace*{1.3cm} $\textsl{dist}(v) := \textsl{dist}(u) + \weight{\pair(u,v)}$ \\[0.2cm]
setzen.  Diese Zuweisung ist ebenfalls gültig wenn $\textsl{dist}(v)$ bereits definiert
ist aber einen Wert hat, der größer als $\textsl{dist}(u) + \weight{\pair(u,v)}$ ist.
Wir fassen diese Überlegungen in den beiden
\textsl{ASM}-Regeln zusammen, die in Abbildung \ref{fig:rule-naive} dargestellt sind.  
Die Abkürzung \textsc{ASM} steht für \emph{abstract state machine}.
Dieser Begriff wurde von 
Yuri Gurevich \cite{gurevich:91} eingeführt und von Egon Börger \cite{boerger:2003} zur
Spezifikation und Verifikation von 
Algorithmen  propagiert und weiterentwickelt.  ASMs sind eine Art Pseudo-Code.  Die 
wesentlichen Eigenschaften von ASMs sind wie folgt:
\begin{enumerate}
\item ASMs bestehen aus Regeln.  Dabei besteht jede Regel
      aus einem Namen, einer Bedingung und einer Menge von Zuweisungen.
\item Bei der Abarbeitung der Regeln wird willkürlich eine Regel ausgewählt, deren
      Bedingung wahr ist und die Zuweisungen dieser Regel werden ausgeführt.
\item Bei Zuweisungen können nicht nur Variablen geändert werden, sondern es können auch die Werte,
      die eine Funktion an einer Stelle annimmt, verändert werden können.  Eine Zuweisung
      kann also die Form
      \\[0.2cm]
      \hspace*{1.3cm}
      $f(x) := y$
      \\[0.2cm]
      haben.  Diese Zuweisung ändert die Funktion $f$ so ab, dass die Funktion anschließend an der Stelle $x$
      den Wert $y$ annimmt.
\item Wenn es keine Regel mehr gibt, deren Bedingung wahr ist, dann hält die ASM an.
\item Die Zuweisungen einer Regel werden alle gleichzeitig ausgeführt.  In der Regel 
      \\[0.2cm]
      \hspace*{0.8cm} \texttt{\underline{Rule}} \textsl{swap}            \\
      \hspace*{1.3cm} \texttt{\underline{if} x < y \underline{then}}     \\
      \hspace*{1.8cm} \texttt{x := y;}                                   \\
      \hspace*{1.8cm} \texttt{y := x;}                                   \\
      \hspace*{1.3cm} \texttt{\underline{endif}}                         \\[0.2cm]
      werden die beiden Zuweisungen also gleichzeitig ausgeführt, so dass im Endeffekt die
      Werte von \texttt{x} und \texttt{y} vertauscht werden.
\end{enumerate}
Wie ASMs im Detail funktionieren, erklären wir bei der Diskussion des in Abbildung
\ref{fig:rule-naive} gegebenen Beispiels.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  commandchars  = \\\{\},
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    \underline{Rule} \textsl{Init}
        \underline{if}  \(\textsl{dist}(\textsl{source}) = \Omega\)
        \underline{then}
            \(\textsl{dist}(\textsl{source})\) := \(0\);
        \underline{endif}
        
    \underline{Rule} \textsl{Run}
        \underline{if} \underline{choose} \(\langle{}u,v\rangle\in\edges\) \underline{satisf}y\underline{in}g
            \(\textsl{dist}(u) \not= \Omega\) \underline{and}  \((\textsl{dist}(v) = \Omega\) \underline{or} \(\textsl{dist}(u)+\weight{\langle{}u,v\rangle}<\textsl{dist}(v))\)
        \underline{then}
            \(\textsl{dist}(v)\) := \(\textsl{dist}(u)+\weight{\langle{}u,v\rangle}\);
        \underline{endif}
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{ASM-Regeln zur Lösung des kürzeste-Wege-Problems.}
  \label{fig:rule-naive}
\end{figure} 
\begin{enumerate}
\item Die erste Regel hat den Namen \textsl{Init}.
      In dieser Regel wird  $\textsl{dist}(\textsl{source})$ auf den Wert 0
      gesetzt, wenn die Funktion \textsl{dist} an der Stelle \textsl{source}
      noch undefiniert ist.  Diese Regel kann nur einmal ausgeführt werden,
      denn nach Ausführung der Regel ist $\textsl{dist}(source)$ von $\Omega$ verschieden.
\item Die zweite Regel benutzt das Konstrukt \texttt{choose}.
      Dieses Konstrukt hat allgemein die Form 
      \\[0.2cm]
      \hspace*{1.3cm}
      \texttt{choose} $\langle x_1, \cdots, x_n\rangle \in M: F(x_1,\cdots,x_n)$
      \\[0.2cm]
      Hierbei sind $x_1, \cdots, x_n$ verschiedene Variablen, $M$ ist eine Menge von
      $n$-Tupeln und \linebreak 
      $F(x_1,\cdots,x_n)$ ist eine
      logische Formel, in der diese Variablen auftreten.
      Das \texttt{choose}-\linebreak
      Konstrukt liefert genau dann als Ergebnis \texttt{true}
      zurück, wenn es in der Menge $M$ ein Tupel $\langle t_1,\cdots,t_n\rangle$ gibt, so dass die Formel 
      $F(t_1,\cdots,t_n)$ wahr wird.  In diesem Fall werden gleichzeitig die Variablen
      $x_1,\cdots,x_n$ mit den entsprechenden Elementen belegt.
      
      Bei der zweiten Regel suchen wir über das \texttt{choose}-Konstrukt
      eine Kante $\pair(u,v)$, für die gilt: 
      \begin{enumerate}
      \item $\textsl{dist}(u)$ ist definiert, es gibt also einen Pfad von
            dem Knoten $\textsl{source}$  zu dem Knoten $u$.
      \item $\textsl{dist}(v)$ ist undefiniert oder größer als 
            $\textsl{dist}(u)+\weight{\langle{}u,v\rangle}$. 
      \end{enumerate}
      Dann können wir die Abschätzung
      für den Abstand $\textsl{dist}(v)$ von dem Knoten $\textsl{source}$ zu dem Knoten
      $v$ zu dem Wert $\textsl{dist}(u)+\weight{\langle{}u,v\rangle}$ verbessern.
\end{enumerate}
Der Algorithmus um das kürzeste-Wege-Problem zu lösen besteht nun darin,
dass wir die ASM-Regeln solange ausführen, wie dies möglich ist. 
Der Algorithmus terminiert, denn die Regel \textsl{Init} kann nur einmal ausgeführt
werden und die Regel \textsl{Run} vermindert bei jeder Ausführung den Wert
der Funktion $\textsl{dist}()$ an einem Punkt.  Da der Werte-Bereich dieser Funktion aus
natürlichen Zahlen besteht, geht das nur endlich oft.


\subsection{Der Algorithmus von Moore}
\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  commandchars  = \\\{\},
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    \underline{Rule} \textsl{Init}
        \underline{if}   \(\textsl{dist}(\textsl{source}) = \Omega\)
        \underline{then} \(\textsl{dist}(\textsl{source})\) := \(0\);
             \textsl{mode}\,        := \textsl{scan};
             \textsl{Fringe}\,      := \(\{ \textsl{source} \}\);
        \underline{endif}
        
    \underline{Rule} \textsl{Scan}
        \underline{if}   \(\textsl{mode} = \mathtt{scan}\) \underline{and} \underline{choose} \(u\in\textsl{Fringe}\) 
        \underline{then}
           \({\cal E}\!\)      := \(\textsl{edges}(u)\);
            \(\textsl{Fringe}\) := \(\texttt{Fringe} \backslash \{u\}\);
            \(\textsl{mode}\)   := \texttt{relabel};
        \underline{endif}

    \underline{Rule} \textsl{Relabel}
        \underline{if}        \(\textsl{mode} = \textsl{relabel}\)
             \underline{and}  \underline{choose} \(\langle{}u,v\rangle\in{\cal{}E}\) \underline{satisfying}  
                      \(\textsl{dist}(v)=\Omega\) \underline{or} \(\textsl{dist}(u)+\weight{\langle{}u,v\rangle}<\textsl{dist}(v)\);
        \underline{then}
            \(\textsl{dist}(v)\) := \(\textsl{dist}(u)+\weight{\langle{}u,v\rangle}\);
            \(\textsl{Fringe}\;\) := \(\texttt{Fringe}\cup\{v\}\);
        \underline{else} 
            \(\textsl{mode}\;\)   := \texttt{scan};
        \underline{endif}
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Algorithmus von Moore zur Lösung des kürzeste-Wege-Problems.}
  \label{fig:rules-moore}
\end{figure} 

\noindent
Der oben gezeigte Algorithmus lässt sich zwar prinzipiell implementieren, er ist aber 
viel zu ineffizient um praktisch nützlich zu sein.
Beim naiven Algorithmus ist die Frage, in welcher Reihenfolge Knoten ausgewählt werden,
nicht weiter spezifiert.   Edward F. Moore \cite{moore:59} hat den Algorithmus in naheliegender Weise
verbessert,  indem er über die Auswahl der Knoten Buch führte.  
Dazu benutzen wir die Variable \textsl{Fringe}, die die Menge aller Knoten enthält, von denen aus
noch kürzere Pfade gefunden werden können.  Am Anfang enthält diese Menge nur den Knoten
\texttt{source}.  Jedesmal, wenn für einem Knoten $v$ die Funktion
$\mathtt{dist}(v)$ geändert wird, wird $v$ der Menge \textsl{Fringe} hinzugefügt.
Umgekehrt wird $v$ aus der Menge \textsl{Fringe} entfernt, wenn alle Kanten, die von $v$
ausgehen, betrachtet worden sind.  Um leichter über diese Kanten iterieren zu können,
nehmen wir an, dass eine Funktion \\[0.2cm]
\hspace*{1.3cm} $\textsl{edges}: \nodes \rightarrow 2^{\edges}$ \\[0.2cm]
gegeben ist, die für einen gegebenen Knoten $u$ die Menge aller Kanten $\pair(u,v)$
berechnet, die von dem Knoten $u$ ausgehen.  Es gilt also \\[0.2cm]
\hspace*{1.3cm} $\textsl{edges}(u) = \{ \pair(u,v) \mid \pair(u,v) \in \edges \}$.
\\[0.2cm]
Der Algorithmus läuft nun in drei Phasen ab.
\begin{enumerate}
\item In der \emph{Initialisierungs}-Phase setzen wir $\textsl{dist}(\textsl{source}) := 0$.
\item In der \emph{Scanning}-Phase wählen wir einen Knoten $u$ aus der Menge \textsl{Fringe} aus,
      entfernen ihn aus dieser Menge und setzen \\[0.2cm]
      \hspace*{1.3cm} ${\cal E} := \textsl{edges}(u)$. \\[0.2cm]
      Ansschließend wechseln wir in die \emph{Relabeling}-Phase.
\item In der \emph{Relabeling}-Phase wählen wir eine Kante 
      $\pair(u,v) \in {\cal E}$ aus, für die \\[0.2cm]
      \hspace*{1.3cm} $\textsl{dist}(v)=\Omega$ \quad oder \quad
      $\textsl{dist}(u) + \weight{\langle{}u,v\rangle} < \textsl{dist}(v)$ \\[0.2cm]
      gilt.  Dann ändern wir die Abstands-Funktion \textsl{dist} für den Knoten $v$ ab
      und fügen gleichzeitig den Knoten $v$ der Menge \textsl{Fringe} hinzu.

      Falls wir keinen Knoten finden können, für den wir die 
      Funktion $\textsl{dist}(u)$ verkleinern können, wechseln wir wieder in die \emph{Scanning}-Phase zurück.
\end{enumerate}
Der Algorithmus bricht ab, wenn die Menge $\textsl{Fringe}$ leer wird.
Abbildung \ref{fig:rules-moore} auf Seite \pageref{fig:rules-moore} zeigt die
Spezifikation dieses Algorithmus durch eine ASM.

\subsection{Der Algorithmus von Dijkstra}
\begin{figure}[!htt]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  commandchars  = \\\{\},
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    \underline{Rule} \textsl{Init}
        \underline{if}   \(\textsl{dist}(\textsl{source}) = \Omega\)
        \underline{then} 
             \(\textsl{Fringe}.\textsl{insert}(0,\textsl{source})\);
             \textsl{dist}(\textsl{source}) := \(0\);
             \textsl{Visited}      := \(\{ \textsl{source} \}\);
             \textsl{mode}         := \textsl{scan};
        \underline{endif}
        
    \underline{Rule} \textsl{Scan}
        \underline{if}     \(\textsl{mode} = \textsl{scan}\)
           \underline{and} \underline{not} \texttt{Fringe}.\texttt{isEmpty}()  
        \underline{then}
            \(\langle{d,u}\rangle\) := \textsl{Fringe}.\textsl{top}();
            \textsl{Fringe}.remove();
            \textsl{Visited} := \(\textsl{Visited} \cup \{ u \}\);
           \({\cal E}\,\)    := \(\textsl{edges}(u)\);            
            \(\textsl{mode}\;\) := \texttt{relabel};
        \underline{endif}

    \underline{Rule} \textsl{Relabel}
        \underline{if}        \(\textsl{mode} = \textsl{relabel}\)
             \underline{and}  \underline{choose} \(\langle{}u,v\rangle\in{\cal{}E}\) \underline{satisfying}  
                      \(\textsl{dist}(v)=\Omega\) \underline{or} \(\textsl{dist}(u)+\weight{\langle{}u,v\rangle}<\textsl{dist}(v)\);
        \underline{then}
            \(\textsl{dist}(v)\) := \(\textsl{dist}(u)+\weight{\langle{}u,v\rangle}\);
            \underline{if} \(\textsl{dist}(v) = \Omega\) \underline{then}
                \(\textsl{Fringe}\) := \(\texttt{Fringe}.\textsl{insert}(\textsl{dist}(v),v)\);
            \underline{else}
                \(\textsl{Fringe}\) := \(\texttt{Fringe}.\textsl{change}(\textsl{dist}(v),v)\);
            \underline{endif} 
        \underline{else} 
            \(\textsl{mode}\;\) := \texttt{scan};
        \underline{endif}
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{ASM-Regeln für den Algorithmus von Dijkstra.}
  \label{fig:rules-dijkstra}
\end{figure} 

\noindent
Im Algorithmus von Moore ist die Frage, in welcher Weise die Knoten aus der Menge
\textsl{Fringe} ausgewählt werden, nicht weiter spezifiziert.  
Die Idee bei dem  von Edsger W.~Dijkstra (1930 -- 2002) im Jahre 1959 veröffentlichten
Algorithmus \cite{dijkstra:59}
besteht darin, in der Regel \textsl{Scan} immer den Knoten auszuwählen, der den geringsten Abstand zu
dem Knoten \textsl{source} hat.
Dazu wird die Menge \textsl{Fringe} durch eine Prioritäts-Warteschlange
implementiert.  Als Prioritäten wählen wir die Entfernungen zu dem Knoten \texttt{source}.
Abbildung \ref{fig:rules-dijkstra} auf Seite \pageref{fig:rules-dijkstra} zeigt die 
Spezifikation des Algorithmus von Dijkstra zur Berechnung der kürzesten Wege.
Gegenüber dem Algorithmus von Moore hat sich vor allem die Regel \textsl{Scan} geändert,
denn dort wählen wir jetzt immer den Knoten aus der Menge \textsl{Fringe}, der den
kleinsten Abstand zum Knoten \textsl{source} hat.

In den ASM-Regeln taucht noch eine Variable mit dem Namen \textsl{Visited} auf.
Diese Variable bezeichnet die Menge der Knoten, die der Algorithmus schon \textsl{besucht}
hat.  Genauer sind das die Knoten, die aus der Prioritäts-Warteschlange \texttt{Fringe}
entfernt wurden und für die dann anschließend in der Regel \textsl{Relabel} alle
benachbarten Knoten untersucht wurden.  Die Menge \textsl{Visited} hat keine Bedeutung für
die eigentliche Implementierung des Algorithmus.  Die Variable wird eingeführt um eine Invariante formulieren
zu können, die für den Beweis der Korrektheit des Algorithmus zentral ist.  Die Invariante lautet
\\[0.2cm]
\hspace*{1.3cm}
$\forall u\in\mathtt{Visited}: \textsl{dist}(u) = \textsl{sp}(u)$.
\\[0.2cm]
Für alle Knoten aus \textsl{Visited} liefert die Funktion \textsl{dist}() also bereits den
kürzesten Abstand zum Knoten \textsl{source}.  
\vspace*{0.1cm}

\noindent
\textbf{Beweis}: Wir zeigen durch Induktion, dass jedesmal wenn wir einen Knoten $u$ in die Menge
\textsl{Visited} einfügen, die Gleichung $\textsl{dist}(u) = \textsl{sp}(u)$ gilt.
In den ASM-Regeln gibt es zwei Stellen, bei denen wir der Menge \textsl{Visited} neue
Elemente hinzufügen.
\begin{enumerate}
\item[I.A.:]
      In Zeile 6 fügen wir den Start-Knoten \textsl{source} in die Menge \textsl{Visited}
      ein.  Wegen $\textsl{sp}(\textsl{source}) = 0$ ist die Behauptung in diesem Fall
      offensichtlich.
\item[I.S.:]
      In Zeile 16 fügen wir den Knoten $u$ in die Menge \textsl{Visited} ein.
      Wir betrachten nun die Situation unmittelbar vor dem Einfügen von $u$.
      Wir können annehmen, dass $u$ noch nicht in der Menge \textsl{Visited}
      enthalten ist, denn sonst wird $u$  ja nicht wirklich in \textsl{Visited} eingefügt.
      Wir führen den Beweis nun indirekt und nehmen an, dass 
      \\[0.2cm]
      \hspace*{1.3cm} $\textsl{dist}(u) > \textsl{sp}(u)$
      \\[0.2cm]
      gilt.  Dann gibt es einen kürzesten Pfad 
      \\[0.2cm]
      \hspace*{1.3cm} $p = [ x_0 = \textsl{source}, x_1, \cdots, x_n = u ]$
      \\[0.2cm]
      von \textsl{source} nach $u$, der insgesamt die Länge $\textsl{sp}(u)$ hat.
      Es sei  $i\in\{0,\cdots,n-1\}$ der Index für den 
      \\[0.2cm]
      \hspace*{1.3cm}
      $x_0\in \textsl{Visited}$, $\cdots$, $x_i\in \textsl{Visited}$ \quad aber \quad $x_{i+1} \not\in \mathtt{Visited}$,
      \\[0.2cm]
      gilt, $x_i$ ist also der erste Knoten aus dem Pfad $p$, für den $x_{i+1}$ nicht mehr
      in der Menge
      \textsl{Visited} liegt.  Nachdem $x_i$ in die Menge Visited eingefügt wurde,
      wurde für alle Knoten, die mit $x_i$ über eine Kante verbunden sind,
      die Funktion \textsl{dist}() neu ausgerechnet.  Insbesondere
      wurde auch $\textsl{dist}(x_{i+1})$ neu berechnet und der Knoten $x_{i+1}$ wurde 
      spätestens zu diesem Zeitpunkt in die Menge \textsl{Fringe} eingefügt.
      Außerdem wissen wir, dass $\textsl{dist}(x_{i+1}) = \textsl{sp}(x_{i+1})$ gilt,
      denn nach Induktions-Voraussetzung gilt $\textsl{dist}(x_i) = \textsl{sp}(x_i)$
      und die Kante $\pair(x_i,x_{i+1})$ ist Teil eines kürzesten Pfades von $x_i$ nach $x_{i+1}$.
      
      Da wir nun angenommen haben, dass $x_{i+1} \not\in \textsl{Visited}$ ist,
      muss $x_{i+1}$ immer noch in der Pri\-ori\-täts-Warteschlange \textsl{Fringe} liegen.
      Also muss $\textsl{dist}(x_{i+1}) \geq \textsl{dist}(u)$ gelten,
      denn sonst wäre $x_{i+1}$ vor $u$ aus der Prioritäts-Warteschlange entfernt worden.
      Wegen $\textsl{sp}(x_{i+1}) = \textsl{dist}(x_{i+1})$ haben wir dann aber
      den Widerspruch 
      \\[0.2cm]
      \hspace*{1.3cm} 
      $\textsl{sp}(u) \geq \textsl{sp}(x_{i+1}) = \textsl{dist}(x_{i+1}) \geq
      \textsl{dist}(u) > \textsl{sp}(u)$.
      \hspace*{\fill} $\Box$
\end{enumerate}

\subsection{Implementierung in \textsl{Java}}
\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    import java.util.*;
    
    public class Node implements Comparable<Node>
    {
        private String     mName;
        private List<Edge> mEdges;
    
        public Node(String name) {
            mName  = name;
            mEdges = new LinkedList<Edge>();
        }   
        public String     toString() { return mName;  }
        public String     getName () { return mName;  }
        public List<Edge> getEdges() { return mEdges; }
        public void       setEdges(List<Edge> edges) { mEdges = edges; }
            
        public int compareTo(Node node) {
            return mName.compareTo(node.mName);
        }
    }
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Die Klasse Node.}
\label{fig:Graph/Node.java}
\end{figure}

Zunächst müssen wir überlegen, wie wir einen Graphen repräsentieren wollen.
Abbildung \ref{fig:Graph/Node.java} zeigt die Klasse \texttt{Node}, mit der wir die Knoten
des Graphen repräsentieren.
\begin{enumerate}
\item Die Klasse \texttt{Node} implementiert die Schnittstelle \texttt{Comparable},
      damit wir später Knoten als Schlüssel einer \texttt{TreeMap} verwenden können.
      Dies ist bei der Funktion $\textsl{dist}()$ erforderlich.
\item Ein Knoten hat einen eindeutigen Namen, der in der Member-Variablen \texttt{mName}
      abgespeichert wird.  Dieser Name ist beim Einlesen eines Graphen nützlich.
\item Weiterhin verwaltet ein Knoten eine Liste von Kanten in der Member-Variablen
      \texttt{mEdges}.  Diese Liste repräsentiert den Funktionswert $\textsl{edges}(\mathtt{this})$.
\item Die Methode $\textsl{compareTo}()$ vergleicht Knoten an Hand ihres Namens.
\end{enumerate}

\begin{figure}[!ht]
\centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm,
                ]
    class Edge {
        private Node    mSource;
        private Node    mTarget;
        private Integer mLength;
        
        public Edge(Node source, Node target, Integer length) {
            mSource = source;
            mTarget = target;
            mLength = length;
        }   
        public Node    getSource() { return mSource; }
        public Node    getTarget() { return mTarget; }
        public Integer getLength() { return mLength; }
        public String  toString () {
            return "<" + mSource + ", " + mTarget + ">: " + mLength;
        }
    }
\end{Verbatim}
\vspace*{-0.3cm}
\caption{Die Klasse \texttt{Edge}.}
\label{fig:Graph/Edge.java}
\end{figure}

\noindent
Die Klasse \texttt{Edge} repräsentiert eine Kante $\pair(x,y)$ in unserem Graphen.
\begin{enumerate}
\item Die Variable \texttt{mSource} entspricht dem Start-Knoten $x$ der Kante $\pair(x,y)$.
\item Die Variable \texttt{mTarget} entspricht dem Ziel-Knoten $y$ der Kante $\pair(x,y)$.
\item Die Variable \texttt{mLength} gibt die Länge der Kante $\pair(x,y)$ an.
\end{enumerate}

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  commandchars  = \\\{\}, 
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    public class Dijkstra \{
        \(\vdots\)
        public Map<Node, Integer> shortestPath(Node source) 
        \{
            Map<Node, Integer> dist = new TreeMap<Node, Integer>();
            dist.put(source, 0);
            HeapTree<Integer, Node> fringe = new HeapTree<Integer, Node>();
            fringe.insert(0, source);
            while (!fringe.isEmpty()) \{
                Pair<Integer, Node> p     = fringe.top();
                Integer             distU = p.getFirst();
                Node                u     = p.getSecond();
                fringe.remove();
                for (Edge edge: u.getEdges()) \{
                    Node v = edge.getTarget();
                    if (dist.get(v) == null) \{
                        Integer d = distU + edge.getLength();
                        dist.put(v, d);
                        fringe.insert(d, v);
                    \} else \{
                        Integer oldDist = dist.get(v);
                        Integer newDist = dist.get(u) + edge.getLength();
                        if (newDist < oldDist) \{
                            dist.put(v, newDist);
                            fringe.change(newDist, v);
                        \}
                    \}
                \}
            \}
            return dist;
        \}
    \}
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Dijkstra's Algorithmus zur Lösung des kürzeste-Wege-Problems.}
  \label{fig:dijkstra}
\end{figure}

\noindent 
Abbildung \ref{fig:dijkstra} auf Seite \pageref{fig:dijkstra} zeigt eine
Implementierung des von Dijkstra vorgeschlagenen Algorithmus in \textsl{Java}.
Die Methode $\textsl{shortestPath}()$ bekommt als Argument einen Knoten \texttt{source}.
Sie berechnet den Abstand aller anderen Knoten zu diesem Knoten.
\begin{enumerate}
\item In Zeile 5 und 6 initialsieren wir  die Funktion \textsl{dist} und
      implementieren die Zuweisung \\[0.2cm]
      \hspace*{1.3cm} $\textsl{dist}(\textsl{source}) \df 0$.
\item In Zeile 7 und 8 wird die Menge \texttt{fringe} initialisiert. 
      Diese Menge repräsentieren wir durch eine Prioritäts-Warteschlange,
      wobei wir nicht die von \textsl{Java} zur Verfügung gestellte Klasse benutzen
      sondern die Klasse, die wir im Kapitel \ref{chap:prioqueue}
      entwickelt haben.  Dies ist erforderlich, weil die von \textsl{Java} zur Verfügung
      gestellte Klasse \texttt{PriorityQueue} keine Methode $\textsl{change}()$ anbietet,
      mit der die Priorität eines Elementes geändert werden kann.

      Am Anfang enthält die Prioritäts-Warteschlange \textsl{fringe} nur den Knoten \texttt{source}.
\item Die \texttt{while}-Schleife in Zeile 9 -- 29 implementiert die Scanning-Phase.
      Solange die Prioritäts-Warteschlange \textsl{fringe} nicht leer ist,
      holen wir den Knoten $u$ mit dem kürzesten Abstand zum Knoten \textsl{source}
      aus der Warteschlange heraus.
\item Die Relabeling-Phase wird durch die \texttt{for}-Schleife in Zeile 18 -- 27
      implementiert.  Hierbei iterieren wir über alle Kanten $\pair(u,v)$, die
      von dem Knoten $u$ ausgehen.  Dann gibt es zwei Fälle:
      \begin{enumerate}
      \item Falls die Funktion \textsl{dist} für den Knoten $v$ noch undefiniert
            ist, dann realisieren wir in Zeile 17 die Zuweisung \\[0.2cm]
            \hspace*{1.3cm} $\textsl{dist}(v) \df \textsl{dist}(u) + \weight{\pair(u,v)}$.
            \\[0.2cm]
            Gleichzeitig fügen wir den Knoten $v$ in die Menge $\textsl{Fringe}$ ein.
      \item Andernfalls ist $\textsl{dist}(v)$ schon definiert.  Dann kommt es
            darauf an, ob der neu entdeckte Weg von \textsl{source} nach $v$
            über $u$ kürzer ist als die Länge des bisher gefundenen Pfades.
            Falls dies so ist, ändern wir die Funktion \textsl{dist}
            entsprechend ab.  Gleichzeitig müssen wir die Priorität des Knotens
            $v$ in der Warteschlange erhöhen.
      \end{enumerate}
\end{enumerate}

\subsection{Komplexität}
Wenn ein Knoten $u$ aus der Warteschlange \textsl{Fringe} entfernt wird, ist er anschließend ein Element der
Menge \textsl{Visited} und aus der oben gezeigten Invariante folgt, dass dann 
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{sp}(u) = \textsl{dist}(u)$
\\[0.2cm]
gilt.  Daraus folgt aber notwendigerweise, dass der Knoten $u$ nie wieder in die Menge \textsl{Fringe}
eingefügt werden kann, denn ein Knoten $v$ wird nur dann in \textsl{Fringe} neu eingefügt, wenn die Funktion
$\textsl{dist}(v)$ noch undefiniert ist.  Das Einfügen eines Knoten in eine Prioritäts-Warteschlange mit $n$
Elementen kostet eine Rechenzeit, die durch $\Oh\bigl(\log_2(n)\bigr)$ abgeschätzt werden kann.  Da die
Warteschlange sicher nie mehr als $\#V$ knoten enthalten kann und da jeder Knoten maximal einmal eingefügt
werden kann, liefert das einen Term der Form 
\\[0.2cm]
\hspace*{1.3cm}
$\Oh\bigl(\#V \cdot \log_2(\#V)\bigr)$ 
\\[0.2cm]
für das Einfügen der Knoten.  Neben dem Aufruf von $\textsl{fringe}.\textsl{insert}(d,v)$ müssen
wir auch die Komplexität des Aufrufs $\textsl{fringe}.\textsl{change}(\mathtt{newDist}, v)$ analysieren.
Die Anzahl dieser Aufrufe ist durch die Anzahl der Kanten begrenzt, die zu dem Knoten $v$ hinfügen.
Da ein Aufruf von $q.\textsl{change}()$ für eine Prioritäts-Warteschlange $q$ mit $n$ Elementen Rechenzeit
in der Höhe von $\Oh\bigl(\log_2(n)\bigr)$ erfordert, haben wir also insgesamt für den Aufruf von
$\textsl{change}()$ die Abschätzung
\\[0.2cm]
\hspace*{1.3cm}
$\Oh\bigl(\#E \cdot \log_2(\#V)\bigr)$
\\[0.2cm]
Dabei bezeichnet $\#E$ die Anzahl der Kanten. Damit erhalten wir für die
Komplexität von Dijkstra's Algorithmus den Ausdruck \\[0.2cm]
\hspace*{1.3cm} $\Oh\bigl((\#\edges + \#\nodes) * \ln(\#\nodes)\bigr)$. \\[0.2cm]
Ist die Zahl der Kanten, die von den Knoten ausgehen können, durch eine feste Zahl begrenzt
(z.B. wenn von jedem Knoten nur maximal 4 Kanten ausgehen), so
kann  die Gesamt-Zahl der Kanten durch ein festes Vielfaches der Knoten-Zahl abgeschätzt
werden.  Dann ist  die Komplexität für Dijkstra's Algorithmus zur  Bestimmung der kürzesten Wege
durch den Ausdruck  
\\[0.2cm]
\hspace*{1.3cm}
$\Oh\bigl(\#\nodes * \log_2(\#\nodes)\bigr)$ 
\\[0.2cm]
gegeben.




%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "algorithmen"
%%% End: 
