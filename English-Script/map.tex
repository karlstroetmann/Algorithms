\chapter{Sets and Maps}
Wir haben bereits im ersten Semester gesehen, wie wichtig Mengen und funktionale Relationen, die wir
im Folgenden als Abbildungen bezeichnen werden, in
der Informatik sind.  In diesem Kapitel zeigen wir, wie sich Mengen und Abbildungen
effizient implementieren lassen.  Wir können uns dabei auf Abbildungen beschränken, denn eine
Menge $M$ lässt sich immer als eine Abbildung $f$ in die Menge $\{\mathtt{true}, \mathtt{false}\}$
darstellen, wenn wir
\\[0.2cm]
\hspace*{1.3cm}
$x \in M \; \stackrel{\textrm{\scriptsize def}}{\Longleftrightarrow} \; f(x) = \mathtt{true}$
\\[0.2cm]
definieren.  Der Rest dieses Kapitels ist wie folgt aufgebaut:
\begin{enumerate}
\item Zunächst definieren wir den abstrakten Daten-Typ der \emph{Abbildungen}.

      Anschließend stellen wir verschiedene Implementierungen dieses Daten-Typs vor.

\item Wir beginnen mit geordneten binären Bäumen.  Die durchschnittliche 
      Komplexität beim Einfügen eines Elements ist logarithmisch.  Leider wächst
      die Komplexität im schlechtesten Fall linear mit der Anzahl der Enträge.
\item Wir betrachten als nächstes \emph{balancierte binäre Bäume}.  Bei diesen wächst die Komplexität der
      Operationen auch im schlechtesten Fall nur logarithmisch mit der Zahl der Einträge.
\item Anschließend betrachten wir die Daten-Struktur der \emph{Tries}, die dann verwendet
      werden kann, wenn die Schlüssel, nach denen gesucht werden soll, Strings sind.
\item \textsl{Hash-Tabellen} stellen eine weitere Möglichkeit zur Implementierung
      von Abbildungen dar und werden im vierten Abschnitt diskutiert.
\end{enumerate}

\section[ADT Map]{Der abstrakte Daten-Typ der \emph{Abbildung}} 
In vielen Anwendungen der Informatik spielen \emph{Abbildungen} einer Menge von
sogenannten \emph{Schlüsseln} in eine Menge von sogenannten \emph{Werten} eine wichtige
Rolle. Als ein Beispiel betrachten wir ein elektronisches Telefon-Buch wie es
beispielsweise von einem Handy zur Verfügung gestellt wird.  Die wesentlichen
Funktionen, die ein solches Telefon-Buch anbietet, sind:
\begin{enumerate}
\item Nachschlagen eines gegebenen Namens und Ausgabe der diesem Namen zugeordneten
      Telefon-Nummer.
\item Einfügen eines neuen Eintrags mit Namen und Telefon-Nummer.
\item Löschen eines vorhandenen Eintrags.
\end{enumerate}
Im Falle des Telefon-Buchs sind die \emph{Schlüssel} die Namen und die \emph{Werte} sind
die Telefon-Nummern.  

\begin{Definition}[Abbildung] \hspace*{\fill} \\
{\em
  Wir definieren den abstrakten Daten-Typ der \emph{Abbildung} wie folgt:
  \begin{enumerate}
  \item Als Namen wählen wir \textsl{Map}.
  \item Die Menge der Typ-Parameter ist $\{ \textsl{Key}, \textsl{Value} \}$.
  \item Die Menge der Funktions-Zeichen ist \\[0.1cm]
       \hspace*{1.3cm} 
       $\{ \textsl{map}, \textsl{find}, \textsl{insert}, \textsl{delete} \}$.
  \item Die Typ-Spezifikationen der Funktions-Zeichen sind gegeben durch:
        \begin{enumerate}
        \item $\textsl{map}: \textsl{Map}$

              Der Aufruf $\textsl{Map}()$ erzeugt eine leere Abbildung, also
              eine Abbildung, in der keine Werte gespeichert sind.
        \item $\textsl{find}: \textsl{Map} \times \textsl{Key} \rightarrow \textsl{Value} \cup \{\Omega\}$

              Der Aufruf $m.\textsl{find}(k)$ überprüft, ob in der Abbildung $m$
              zu dem Schlüssel $k$ ein Wert abgespeichert ist.  Wenn ja, wird dieser Wert
              zurück gegeben, sonst wird der Wert $\Omega$ zurück gegeben.
        \item $\textsl{insert}: \textsl{Map} \times \textsl{Key} \times \textsl{Value} \rightarrow \textsl{Map}$

              Der Aufruf $m.\textsl{insert}(k,v)$ fügt in der Abbildung $m$
              für den Schlüssel $k$ den Wert $v$ ein.  Falls zu dem Schlüssel $k$ bereits
              ein Eintrag in der Abbildung $m$ existiert, so wird dieser überschrieben.
              Andernfalls wird ein entsprechender Eintrag neu angelegt.
              Als Ergebnis wird die geänderte Abbildung zurück gegeben.
        \item $\textsl{delete}: \textsl{Map} \times \textsl{Key} \rightarrow \textsl{Map}$

              Der Aufruf $m.\textsl{delete}(k)$ entfernt den Eintrag zu dem Schlüssel $k$
              in der Abbildung $m$.  Falls kein solcher Eintrag existiert, bleibt die 
              Abbildung $m$ unverändert.  Als Ergebnis wird die eventuell geänderte
              Abbildung zurück gegeben.
        \end{enumerate}
  \item Das genaue Verhalten der Funktionen wird durch die nachfolgenden Axiome
        spezifiziert.
        \begin{enumerate}
        \item $\textsl{map}().\textsl{find}(k) = \Omega$,

              denn der Aufruf $\textsl{map}()$ erzeugt eine leere Abbildung, in der sich
              zu keinem Schlüssel ein Wert findet.
        \item $m.\textsl{insert}(k, v).\textsl{find}(k) = v$,

              denn wenn wir zu dem Schlüssel $k$ einen Wert $v$ einfügen, so finden 
              wir anschließend eben diesen Wert $v$, wenn wir nach $k$ suchen.
        \item $k_1 \not= k_2 \rightarrow 
               m.\textsl{insert}(k_1, v).\textsl{find}(k_2) = m.\textsl{find}(k_2)$,

              denn wenn wir für einen Schlüssel $k_1$ eine Wert einfügen, so ändert das
              nichts an dem Wert, der für einen anderen Schlüssel $k_2$ abgespeichert ist.
        \item $m.\textsl{delete}(k).\textsl{find}(k\bigr) = \Omega$,

              denn wenn wir einen Schlüssel $k$ löschen, so finden wir anschließend auch
              keinen Wert mehr, der unter dem Schlüssel $k$ abgespeichert ist.
        \item $k_1 \not= k_2 \rightarrow 
               m.\textsl{delete}(k_1).\textsl{find}(k_2) = m.\textsl{find}(k_2)$,

              denn wenn wir einen Schlüssel $k_1$ löschen, so ändert das nichts an dem
              Wert, der unter einem anderen Schlüssel $k_2$ abgespeichert ist. \hspace*{\fill} $\Box$
        \end{enumerate}
  \end{enumerate}
}
\end{Definition}

Es ist in \textsc{SetlX} sehr einfach, den ADT \textsl{Abbildung} zu implementieren.
Dazu müssen wir uns nur klar machen, dass Abbildungen nichts anderes sind als Funktionen
und die können wir in der Mengenlehre durch binäre Relationen darstellen.
Ist $r$ eine binäre Relation die genau ein Paar der Form $[k,v]$ enthält, bei dem die
erste Komponente den Wert $k$ hat, dann liefert der Ausdruck \\[0.1cm]
\hspace*{1.3cm} $r[k]$
\\[0.1cm]
als Ergebnis den Wert $v$.  Umgekehrt wird durch den Aufruf \\[0.1cm]
\hspace*{1.3cm} $r[k] := v$ \\[0.1cm]
das Paar $[k,v]$ in die Relation $r$ eingefügt.  Um den Eintrag unter einem Schlüssel $k$
zu löschen, reicht es aus, dem Schlüssel $k$ den undefinierten Wert $\Omega$ zuzuweisen: \\[0.1cm]
\hspace*{1.3cm} $r[k] := \mathtt{om}$. \\[0.1cm]
Dieser Wert wird auch bei der Auswertung des Ausdrucks $r[k]$ zurück gegeben, wenn die
binäre Relation kein Paar der Form $[k,v]$ enthält.
Abbildung \ref{fig:map-trivial.stlx} zeigt
eine Implementierung des ADT Abbildung, die diese Überlegungen unmittelbar umsetzt.

\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    class map() {
        mRelation := {};
      static {
        find   := k |-> mRelation[k];
        insert := procedure(k, v) { mRelation[k] := v;  };
        delete := procedure(k)    { mRelation[k] := om; };
      }
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Eine triviale Implementierung des ADT \textsl{Map} in \textsc{SetlX}.}
  \label{fig:map-trivial.stlx}
\end{figure} 


\section{Geordnete binäre Bäume}
Falls auf der Menge \textsl{Key} der Schlüssel eine totale Ordnung $\leq$ existiert, so kann
eine einfache und zumindest im statistischen Durchschnitt effiziente Implementierung des
abstrakte Daten-Typs \textsl{Map} mit Hilfe \emph{geordneter binärer Bäume} erfolgen.
Um diesen Begriff definieren zu können, führen wir zunächst \emph{binäre Bäume} ein.

\begin{Definition}[Binäre Bäume] \hspace*{\fill} \\
{\em
  Gegeben sei eine Menge $\textsl{Key}$ von Schlüsseln und eine Menge $\textsl{Value}$ von
  Werten.  Dann definieren wir
  die Menge der binären Bäume $\Bin$ induktiv mit Hilfe der
  beiden Funktions-Zeichen \textsl{Nil} und \textsl{Node}, deren Typ-Spezifikationen 
  wie folgt gegeben sind: \\[0.1cm]
  \hspace*{1.3cm} 
  $\textsl{Nil}: \Bin$ \qquad und \qquad  $\textsl{Node}: \textsl{Key} \times \textsl{Value} \times \Bin \times \Bin \rightarrow \Bin$.
  \begin{enumerate}
  \item $\textsl{Nil}$ ist ein binärer Baum.

        Dieser Baum wird als der \emph{leere Baum} bezeichnet.
  \item $\textsl{Node}(k, v, l, r)$ ist ein binärer Baum, falls gilt: 
        \begin{enumerate}
        \item $k$ ist ein Schlüssel aus der Menge $\textsl{Key}$.
        \item $v$ ist ein Wert aus der Menge $\textsl{Value}$.
        \item $l$ ist ein binärer Baum.

              $l$ wird als der \emph{linke Teilbaum} von $\textsl{Node}(k, v, l, r)$ bezeichnet.
        \item $r$ ist ein binärer Baum.

              $r$ wird als der \emph{rechte Teilbaum} von $\textsl{Node}(k, v, l, r)$ bezeichnet.
              \hspace*{\fill} $\Box$
        \end{enumerate}
  \end{enumerate}
}
\end{Definition}

\noindent
Als nächstes definieren wir, was wir unter einem \emph{geordneten binären Baum} verstehen.
\begin{Definition}[Geordnete binäre Bäume] \hspace*{\fill} \\
{\em
  Die Menge $\Bin_<$ der \emph{geordneten binären Bäume} wird induktiv definiert.
  \begin{enumerate}
  \item $\textsl{Nil} \in \Bin_<$
  \item $\textsl{Node}(k, v, l, r) \in \Bin_<$ \quad falls folgendes gilt:
        \begin{enumerate}
        \item $k$ ist ein Schlüssel aus der Menge $\textsl{Key}$.
        \item $v$ ist ein Wert aus der Menge $\textsl{Value}$.
        \item $l$ und $r$ sind geordnete binäre Bäume.
        \item Alle Schlüssel, die in dem linken Teilbaum $l$ auftreten,
              sind kleiner als $k$.
        \item Alle Schlüssel, die in dem rechten Teilbaum $r$ auftreten,
              sind größer als $k$.
        \end{enumerate}
        Die beiden letzten  Bedingungen bezeichnen wir als die \emph{Ordnungs-Bedingung}.
        \hspace*{\fill} $\Box$
  \end{enumerate}
}  
\end{Definition}
Geordnete binäre Bäume lassen sich grafisch wir folgt darstellen:
\begin{enumerate}
\item Der leere Baum \textsl{Nil} wird durch einen dicken schwarzen Punkt dargestellt.
\item Ein Baum der Form $\textsl{Node}(k,v,l,r)$ wird dargestellt,  indem zunächst ein
      Oval gezeichnet wird, in dem oben der Schlüssel $k$ und darunter, getrennt durch
      einen waagerechten Strich, der dem Schlüssel zugeordnete Wert $v$ eingetragen wird.
      Dieses Oval bezeichnen wir auch als einen \emph{Knoten} des binären Baums.
      Anschließend wird links unten von diesem Knoten rekursiv der Baum $l$ ge\-zeich\-net
      und  rechts unten wird rekursiv der Baum $r$ gezeichnet. Zum Abschluß zeichnen wir
      von dem mit $k$ und $v$ markierten Knoten jeweils einen Pfeil zu dem linken und dem
      rechten Teilbaum.
\end{enumerate}
Abbildung \ref{fig:graph1} zeigt ein Beispiel für einen
geordneten binären Baum.  Der oberste Knoten, in der Abbildung ist das der mit dem Schlüssel
$8$ und dem Wert $22$ markierte Knoten, wird als die \emph{Wurzel} des Baums bezeichnet.
Ein \emph{Pfad der Länge} $k$ in dem Baum ist eine Liste $[n_0,n_1, \cdots, n_k]$ von
$k+1$ Knoten, die durch Pfeile verbunden sind. Identifizieren wir Knoten mit ihren
Markierungen, so ist \\[0.1cm]
\hspace*{1.3cm} $\bigl[ \pair(8,22), \pair(12,18), \pair(10,16), \pair(9,39) \bigr]$ \\[0.1cm]
ein Pfad der Länge 3.


\begin{figure}[!ht]
  \centering
  \framebox{\epsfig{file=Abbildungen/graph1.eps}} 
  \caption{Ein geordneter binärer Baum}
  \label{fig:graph1}
\end{figure}


Wir überlegen uns nun, wie wir mit Hilfe geordneter binärer Bäume den ADT \textsl{Map}
implementieren können.  Wir spezifizieren die einzelnen Methoden dieses Daten-Typs durch
bedingte Gleichungen.  Der Konstruktor $\textsl{map}()$ liefert als Ergebnis den leeren Baum zurück:
\[ \textsl{map}() = \textsl{Nil}. \]
Für die Methode $\textsl{find}()$ erhalten wir die folgenden Gleichungen:
\begin{enumerate}
\item $\textsl{Nil}.\textsl{find}(k) = \Omega$,

      denn der leere Baum repräsentiert die leere Abbildung.
\item $\textsl{Node}(k, v, l, r), k).\textsl{find}(k) = v$,

      denn der Knoten $\textsl{Node}(k,v,l,r)$ speichert die Zuordnung $k \mapsto v$.
\item $k_1 < k_2 \rightarrow \textsl{Node}(k_2, v, l, r).\textsl{find}(k_1) = l.\textsl{find}(k_1)$,

      denn wenn $k_1$ kleiner als $k_2$ ist, dann kann aufgrund der Ordnungs-Bedingung
      eine Zuordnung für $k_1$ nur in dem linken Teilbaum $l$ gespeichert sein.
\item $k_1 > k_2 \rightarrow \textsl{Node}(k_2, v, l, r).\textsl{find}(k_1) = r.\textsl{find}(k_1)$,

      denn wenn $k_1$ größer als $k_2$ ist, dann kann aufgrund der Ordnungs-Bedingung
      eine Zuordnung für $k_1$ nur in dem rechten Teilbaum $r$ gespeichert sein.
\end{enumerate}
Als nächstes definieren wir die Funktion \textsl{insert}.  Die Definition erfolgt
ebenfalls mit Hilfe rekursiver Gleichungen und ist ganz analog zur Definition der 
Funktion \textsl{find}.
\begin{enumerate}
\item $\textsl{Nil}.\textsl{insert}(k,v) = \textsl{Node}(k,v, \textsl{Nil}, \textsl{Nil})$,
  
      denn wenn der Baum vorher leer ist, so kann die einzufügende Information direkt an
      der Wurzel abgespeichert werden.
\item $\textsl{Node}(k,v_2,l,r).\textsl{insert}(k,v_1) = \textsl{Node}(k, v_1, l, r)$,

      denn wenn wir den Schlüssel $k$ an der Wurzel finden, überschreiben wir einfach den zugeordneten 
      Wert.
\item $k_1 < k_2 \rightarrow 
         \textsl{Node}(k_2, v_2, l, r).\textsl{insert}(k_1, v_1) = \textsl{Node}(k_2, v_2, l.\textsl{insert}(k_1, v_1), r)$,

      denn wenn der Schlüssel $k_1$, unter dem wir Informationen einfügen wollen, kleiner
      als der Schlüssel $k_2$ an der Wurzel ist, so müssen wir die einzufügende
      Information im linken Teilbaum einfügen.
\item $k_1 > k_2 \rightarrow 
         \textsl{Node}(k_2, v_2, l, r).\textsl{insert}(k_1, v_1) = 
         \textsl{Node}(k_2, v_2, l, r.\textsl{insert}(k_1, v_1))$,

      denn wenn der Schlüssel $k_1$, unter dem wir Informationen einfügen wollen, größer
      als der Schlüssel $k_2$ an der Wurzel ist, so müssen wir die einzufügende
      Information im rechten Teilbaum einfügen.
\end{enumerate}
Als letztes definieren wir die Methode \textsl{delete}. Diese Definition ist schwieriger als
die Implementierung der andern beiden Methoden.  Falls wir in einen Baum der Form
$t =\textsl{Node}(k,v,l,r)$ den Eintrag mit dem Schlüssel $k$ löschen wollen, so
kommt es auf die beiden Teilbäume $l$ und $r$ an.  Ist $l$ der leere Teilbaum,
so liefert $t.\textsl{delete}(k)$ als Ergebnis den Teilbaum $r$ zurück.
Ist $r$ der leere Teilbaum, so ist das Ergebnis $l$.  Problematisch ist die Situation,
wenn weder $l$ noch $r$ leer sind.  
Die Lösung besteht dann darin, dass wir in dem rechten
Teilbaum $r$ den Knoten mit dem kleinsten Schlüssel suchen und diesen Knoten aus dem
Baum $r$ entfernen.  Den dadurch entstehenden Baum nennen wir $r'$.
 Anschließend überschreiben wir in $t =\textsl{Node}(k,v,l,r')$ die
Werte $k$ und $v$ mit dem eben gefundenen kleinsten Schlüssel $k_{min}$ und dem $k_{min}$
zugeordneten Wert $v_{min}$.  Der dadurch entstehende binäre Baum 
$t=\textsl{Node}(k_{min},v_{min},l,r')$
 ist auch wieder
geordnet, denn einerseits ist der Schlüssel $k_{min}$  größer als der Schlüssel $k$ und
damit sicher auch größer als alle Schlüssel im linken Teilbaum $l$ und andererseits ist
$k_{min}$ kleiner als alle  Schlüssel im Teilbaum $r'$, denn $k_{min}$ ist ja der
kleinste Schlüssel aus $r$.  

Zur Veranschaulichung betrachten wir ein Beispiel: Wenn wir in dem Baum aus Abbildung 
\ref{fig:graph1} den Knoten mit der Markierung $\pair(4,16)$ löschen wollen,
so suchen wir zunächst in dem Teilbaum, dessen Wurzel mit $\pair(6,36)$ markiert ist, den
Knoten, der mit dem kleinsten Schlüssel markiert ist.  Dies ist der Knoten mit der
Markierung $\pair(5,25)$.  Wir löschen diesen Knoten und überschreiben die Markierung
$\pair(4,16)$ mit der Markierung $\pair(5,25)$.  Abbildung 
\ref{fig:graph2} auf Seite \pageref{fig:graph2} zeigt das Ergebnis.

\begin{figure}[!th]
  \centering
  \framebox{\epsfig{file=graph2.eps}} 
  \caption{Der geordnete binärer Baum aus Abbildung 
          \ref{fig:graph1} nach dem Entfernen des Knotens mit der Markierung $\pair(4,16)$.}
  \label{fig:graph2}
\end{figure}

Wir geben nun bedingte Gleichungen an, welche die Methode \textsl{delMin} spezifizieren.
\begin{enumerate}
\item $\textsl{Node}(k, v, \textsl{Nil}, r).\textsl{delMin}() = [r, k, v]$,

      denn wenn der linke Teilbaum leer ist, muss $k$ der kleinste Schlüssel in 
      dem Baum sein.  Wenn wir diesen  Schlüssel nebst dem zugehörigen Wert aus dem Baum
      entfernen, bleibt der rechte Teilbaum übrig.
\item $l\not= \textsl{Nil} \wedge l.\textsl{delMin}() = [l',k_{min}, v_{min}] \;\rightarrow$ \\[0.1cm]
       \hspace*{1.3cm} 
       $\textsl{Node}(k, v, l, r).\textsl{delMin}() = [\textsl{Node}(k, v, l', r), k_{min}, v_{min}]$,

      denn wenn der linke Teilbaum $l$ in dem binären Baum $t = \textsl{Node}(k, v, l, r)$
      nicht leer ist, so muss der kleinste Schlüssel von $t$ in $l$ liegen.
      Wir entfernen daher rekursiv den kleinsten Schlüssel aus $l$ und erhalten dabei den
      Baum $l'$.  In dem ursprünglich gegebenen Baum $t$ ersetzen wir $l$ durch $l'$ und erhalten
      $t = \textsl{Node}(k, v, l', r)$.
\end{enumerate}
Damit können wir nun die Methode $\mathtt{delete}()$ spezifizieren.
\begin{enumerate}
\item $\textsl{Nil}.\textsl{delete}(k) = \textsl{Nil}$.
\item $\textsl{Node}(k,v,\textsl{Nil},r).\textsl{delete}\bigl(k\bigr) = r$.
\item $\textsl{Node}(k,v,l,\textsl{Nil}).\textsl{delete}(k) = l$.
\item $l \not= \textsl{Nil} \,\wedge\, r \not= \textsl{Nil} \,\wedge\, r.\textsl{delMin}() = [r',k_{min}, v_{min}]  \;\rightarrow$ \\[0.1cm]
      \hspace*{1.3cm}
      $\textsl{Node}(k,v,l,r).\textsl{delete}(k) = \textsl{Node}(k_{min},v_{min},l,r')$.
      
      Falls der zu entfernende Schlüssel mit dem Schlüssel an der Wurzel des Baums
      übereinstimmt,  entfernen wir mit dem Aufruf $r\mathtt{.}\textsl{delMin}()$
      den kleinsten Schlüssel aus dem rechten Teilbaum  $r$ und produzieren dabei den Baum $r'$.
      Gleichzeitig berechnen wir dabei für den rechten Teilbaum den kleinsten Schlüssel $k_{min}$ und den
      diesem Schlüssel zugeordneten Wert $v_{min}$.  Diese Werte setzen wir nun an die
      Wurzel des neuen Baums.

\item $k_1 < k_2 \rightarrow \textsl{Node}(k_2,v_2,l,r).\textsl{delete}\bigl(k_1) = 
       \textsl{Node}(k_2,v_2,l.\textsl{delete}(k_1),r)$,

      Falls der zu entfernende Schlüssel kleiner ist als der Schlüssel an der Wurzel,
      so kann sich der Schlüssel nur im linken Teilbaum befinden.  Daher wird der
      Schlüssel $k_1$ rekursiv in dem linken Teilbaum $l$ entfernt.
\item $k_1 > k_2 \rightarrow \textsl{Node}(k_2,v_2,l,r).\textsl{delete}(k_1) = 
       \textsl{Node}(k_2,v_2,l,r.\textsl{delete}(k_1))$,

      denn in diesem Fall kann sich der Eintrag mit dem Schlüssel $k_1$  nur in dem
      rechten Teilbaum $r$ befinden.
\end{enumerate}

\subsection{Implementing Ordered Binary Trees in \textsc{SetlX}}
Figure \ref{fig:binary-tree.stlx-1} and Figure \ref{fig:binary-tree.stlx-2} show how ordered binary
trees can be implemented in \textsc{SetlX}.  Objects of class \texttt{map} encapsulate ordered
binary trees.  We discuss the implementation of this class next.
\begin{enumerate}
\item The constructor map is called with one argument.  This argument, called \texttt{cmp}
      in line 1, is a function representing a total order ''$<$''.  The idea is that the function
      \texttt{cmp} is called with two arguments and we have
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathtt{cmp}(x,y)$ \quad if and only if \quad $x < y$.
      \\[0.2cm]
      The function \texttt{cmp} is later stored in the member variable \texttt{mCmpFct} in line 6.
\item The class \texttt{map} represents a node in an ordered binary tree.  In order to do so, it
      maintains four additional member variables.
      \begin{enumerate}
      \item \texttt{mKey} is the key stored at this node.  For an empty node, \texttt{mKey}
            has the value \texttt{om}, which represents $\Omega$.
      \item \texttt{mValue} stores the value stored at this node.  For an empty node,
            \texttt{mValue} is \texttt{om}.
      \item \texttt{mLeft} is the left subtree.  An empty subtree is represented as \texttt{om}.
      \item \texttt{mRight} is the right subtree.  
      \end{enumerate}
\item The function \texttt{isEmpty} checks whether \texttt{this} represents an empty tree.
      The assumption is that if \texttt{mKey} is \texttt{om}, then the member variables
      \texttt{mValue}, \texttt{mLeft}, and \texttt{mRight} will also be \texttt{om}.
\item The implementation of \texttt{find} works as follows:
      \begin{enumerate}
      \item If the node is empty, there is no value to find and the function returns \texttt{om}.
            Note that in \textsc{SetlX} a \texttt{return} statement which does not return a value 
            automatically returns \texttt{om}.
      \item If the key we are looking for is stored at the root of this tree, the value stored for
            this key is \texttt{mValue}.
      \item Otherwise, we have to compare the key \texttt{k}, which is the key we are looking for,
            with the key \texttt{mKey}, which is the key stored in this node.  If \texttt{k}
            is less than \texttt{mKey}, \texttt{k} can at most be stored in the left subtree
            \texttt{mLeft}, while if $k$ is greater than \texttt{mKey}, \texttt{k} can only be
            stored in the right subtree.
      \end{enumerate}


\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    class map(cmp) {
        mKey    := om;
        mValue  := om; 
        mLeft   := om;
        mRight  := om;
        mCmpFct := cmp;  // function to compare keys
      static {
        isEmpty := [] |-> mKey == om;
        find := procedure(k) {
            if      (isEmpty())        { return;                }
            else if (mKey == k)        { return mValue;         }
            else if (mCmpFct(k, mKey)) { return mLeft .find(k); }
            else                       { return mRight.find(k); }
        };
        insert := procedure(k, v) {
              if (isEmpty()) { 
                this.mKey   := k;
                this.mValue := v; 
                this.mLeft  := map(mCmpFct);
                this.mRight := map(mCmpFct);
            } else if (mKey == k) { 
                mValue := v; 
            } else if (mCmpFct(k, mKey)) { 
                mLeft .insert(k, v); 
            } else { 
                mRight.insert(k, v); 
            }
        };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Implementierung geordneter Bäume in \textsc{SetlX}, 1.~Teil.}
  \label{fig:binary-tree.stlx-1}
\end{figure}
\item The implementation of \texttt{insert} is similar to the implementation of \texttt{find}.
      \begin{enumerate}
      \item If the binary tree is empty, we set the member variables \texttt{mKey} and
            \texttt{mValue} to the appropriate values.  The member variables \texttt{mLeft} and 
            \texttt{mRight} are initialized as empty trees.
      \item If the key \texttt{k} under which the value \texttt{v} is to be inserted is identical
            to the key \texttt{mKey} stored at this node, then we have found the node where we need
            to insert \texttt{v}.  In this case, \texttt{mValue} is overwritten with \texttt{v}.
      \item Otherwise, \texttt{k} is compared with \texttt{mKey} and the search is continued in the
            appropriate subtree.
      \end{enumerate}      


\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = last,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
        delMin := procedure() {
            if (mLeft.isEmpty()) { 
                return [ mRight, mKey, mValue ]; 
            } else {
                 [ ls, km, vm ] := mLeft.delMin();
                 this.mLeft := ls;
                 return [ this, km, vm ];
            }
        };
        delete := procedure(k) {
            if      (isEmpty())  { return; } 
            else if (k == mKey)  {
                if      (mLeft .isEmpty()) { update(r); }  
                else if (mRight.isEmpty()) { update(l); } 
                else {
                    [ rs, km, vm ] := mRight.delMin();
                    this.mKey   := km;
                    this.mValue := vm; 
                    this.mRight := rs;
                }
            } else if (mCmpFct(k, mKey)) {
                if (!mLeft .isEmpty()) { mLeft.delete(k); }
            } else {
                if (!mRight.isEmpty()) { mRight.delete(k); }
            }
        };
        update := procedure(t) {
            this.mKey   := t.mKey;
            this.mValue := t.mValue;
            this.mLeft  := t.mLeft;
            this.mRight := t.mRight;
        };
      }
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Ordered binary trees in \textsc{SetlX}, part2.}
  \label{fig:binary-tree.stlx-2}
\end{figure}

\item The implementation of \texttt{delMin} and \texttt{delete} is done in a similar way as the
      implementation of \texttt{insert}.  It should be noted that the implementation follows directly from the
      equations derived  previously. 
\end{enumerate}

\begin{figure}[!th]
  \centering 
  \framebox{\epsfig{file=degenerated-bin-tree}} 
  \caption{Ein entarteter  geordneter binärer Baum.}
  \label{fig:degenerated}
\end{figure}


\subsection{Analyse der Komplexität}
In this section we will first discuss the worst case complexity, which is quite bad.  In fact, in
the worst case, the call $b.\mathtt{find}(k)$ will perform $\Oh(n)$ key comparisons if $b$ is an ordered
binary search tree of $n$ elements.  After that, we investigate the average case complexity.  We
will show that the average case complexity is $\Oh\bigr(\ln(n)\bigr)$.

\subsubsection{Worst Case Complexity}
Wir untersuchen zunächst die Komplexität der Funktion \textsl{find} im schlechtesten Fall.
Dieser Fall tritt dann ein, wenn der binäre Baum zu einer Liste entartet.  Abbildung
\ref{fig:degenerated} auf Seite \pageref{fig:degenerated} zeigt den geordneten binären Baum, der
dann entsteht, wenn die Paare aus Schlüssel und Werten aus der Abbildung
\ref{fig:graph1} in aufsteigender Reihenfolge eingegeben werden.  Wird hier nach dem
größten Schlüssel gesucht, so muss der komplette Baum durchlaufen werden.  Enthält der Baum
$n$ Schlüssel, so sind also insgesamt $n$ Vergleiche erforderlich.  In diesem Fall ist ein
geordneter binärer Baum also nicht besser als eine Liste.

\subsubsection{Average Case Complexity}
Erfreulicherweise tritt der schlechteste Fall im statistischen Durchschnitt selten auf.
Im Durchschnitt ist ein zufällig erzeugter binärer Baum recht gut balanciert, so dass 
beispielsweise für einen Aufruf von \texttt{find()} für einen Baum mit $n$ Schlüsseln
durchschnittlich  $\Oh\bigl(\ln(n)\bigr)$
Vergleiche erforderlich sind. Wir werden diese Behauptung nun beweisen.

%Dazu definieren wir auf binären Bäumen zunächst eine Funktion 
%\[ \textsl{height}: \Bin \rightarrow \N, \]
%die die Höhe eines binären Baums angibt.  Die Definition erfolgt induktiv.
%\begin{enumerate}
%\item $\textsl{Nil}.\textsl{height}() = 0$.

%      Der leere Baum hat die Höhe $0$.
%\item $\textsl{node}(k,v,l,r).\textsl{height}() = 
%       1 + \max\bigl(l.\textsl{height}(),\, r.\textsl{height}()\bigr)$.

%      Die Höhe des Baums $\textsl{node}(k,v,l,r)$ ist um eins größer als die Höhe des
%      größten Teilbaums.
%\end{enumerate}
%Analog definieren wir für einen binären Baum $b$ die Anzahl $b.\textsl{count}()$ der Schlüssel, die
%der Baum enthält.   Die Definition von $b.\textsl{count}()$ erfolgt durch Induktion nach $b$.
%\begin{enumerate}
%\item $\textsl{Nil}.\textsl{count}() = 0$.

%      Der leere Baum enthält keine Schlüssel.
%\item $\textsl{node}(k,v,l,r).\textsl{count}() = 
%       1 + l.\textsl{count}() + r.\textsl{height}()\bigr)$.

%      Der Baum $\textsl{node}(k,v,l,r)$ enthält zusätzlich zu dem Schlüssel $k$ die
%      Schlüssel aus den Teilbäumen $l$ und $r$.
%\end{enumerate}
%Der folgende Satz zeigt, wieviel Schlüssel ein Baum der Höhe $h$ höchstens enthalten
%kann.

%\begin{Satz}
%  Ein binärer Baum $b$ der Höhe $h$ enthält höchstens $2^h - 1$ Schlüssel.
%\end{Satz}
%\noindent
%\textbf{Beweis}:  Wir bezeichnen die maximale Anzahl Schlüssel eines Baums der Höhe $h$
%mit $c_h$.  Wir beweisen  durch Induktion nach $h$, dass gilt:
%\[ c_h = 2^h - 1. \]
%\begin{enumerate}
%\item[I.A.] $h = 0$: Der einzige Baum der Höhe $0$ ist $\textsl{Nil}$.
%            Dieser enthält $0$ Schlüssel.  Also gilt
%            \\[0.2cm]
%            \hspace*{1.3cm}
%            $c_0 = 0 = 2^0 - 1$.
%\item[I.S.] $h \mapsto h + 1$: Ein Baum der Höhe $h+1$, der die maximale Anzahl
%            Schlüssel enthält, hat die Form $\textsl{node}(k,v,l,r)$, wobei dann $l$ und
%            $r$  Bäume der Höhe $h$ sind, die die maximale Anzahl Schlüssel enthalten.
%            Folglich gilt:
%            \begin{eqnarray*}
%               c_{h+1} &               =  & 1 + c_h + c_h \\
%                       & \stackrel{IV}{=} & 1 + (2^h - 1) + (2^h - 1) \\
%                       &               =  & 2 \cdot 2^h - 1 \\
%                       &               =  & 2^{h+1} - 1. \hspace*{9cm} \Box
%            \end{eqnarray*}
%\end{enumerate}

%Die Höhe eines Baumes gibt ein Maß für die Komplexität der Methoden \textsl{find},
%\textsl{insert} und \textsl{delete}, denn bei einem Baum der Höhe $h$ sind für jede dieser
%Operationen höchstens $h$ Vergleiche von Schlüsseln erforderlich.

Wir bezeichnen die \underline{durchschnittliche} Anzahl von Vergleichen, die beim Aufruf
$b.\textsl{find}(k)$ für einen geordneten binären Baum $b$ durchgeführt werden müssen, falls $b$
insgesamt $n$ Schlüssel enthält, mit $d_n$.  Wir wollen annehmen, dass der Schlüssel $k$ auch
wirklich in $b$ zu finden ist.  Unser Ziel ist es, für $d_n$ eine Rekurrenz-Gleichung aufzustellen.
Zunächst
ist klar, dass \\[0.2cm]
\hspace*{1.3cm} $d_1 = 1$ \\[0.2cm]
ist, denn wenn der Baum $b$ nur einen Schlüssel enthält, wird genau einen Vergleich durchgeführt.
Wir betrachten nun einen binären Baum $b$, der $n+1$ Schlüssel enthält.  Dann hat $b$
die Form \\[0.2cm]
\hspace*{1.3cm} $b = \textsl{node}(k',v,l,r)$. \\[0.2cm]
Ordnen wir die $n+1$ Schlüssel der Größe nach in der Form 
\\[0.2cm]
\hspace*{1.3cm}
$k_0 < k_1 < \cdots < k_i < k_{i+1} < k_{i+2} < \cdots < k_{n-1} < k_n$,
\\[0.2cm]
so gibt es $n+1$ verschiedene Positionen, an denen
der Schlüssel $k'$ auftreten kann.  Wenn $k' = k_i$ ist, so enthält der
linke Teilbaum $i$ Schlüssel und der rechte Teilbaum enthält $n-i$ Schlüssel:
\\[0.2cm]
\hspace*{1.3cm}
$\underbrace{k_0 < k_1 < \cdots < k_{i-1}}_{\mbox{Schlüssel in $l$}} < 
 \underbrace{k_{i}}_{\stackrel{\displaystyle \shortparallel}{\displaystyle k'}} < 
 \underbrace{k_{i+1} < \cdots < k_{n-1} < k_n}_{\mbox{Schlüssel in $r$}}$,
\\[0.2cm]
Da $b$ insgesamt $n+1$ Schlüssel enthält, gibt es $n+1$ Möglichkeiten, wie die
verbleibenden $n$ Schlüssel auf die beiden Teilbäume $l$ und $r$ verteilt sein können, denn
$l$ kann $i$ Schlüssel enthalten, wobei \\[0.2cm]
\hspace*{1.3cm} $i \in \{0,1, \cdots, n\}$ \\[0.2cm]
gilt.  Entsprechend enthält $r$ dann $n-i$ Schlüssel.  
Bezeichnen wir die durchschnittliche Anzahl von Vergleichen bei einer Suche in einem Baum mit $n+1$
Schlüsseln, dessen linker Teilbaum $i$ Elemente hat, mit
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{anzVgl}(i,\, n\!+\!1)$,
\\
so gilt
\\[-0.1cm]
\hspace*{1.3cm}
$\ds d_{n+1} =  \frac{1}{n+1} \cdot \sum\limits_{i=0}^n \textsl{anzVgl}(i,\, n\!+\!1)$,
\\[0.2cm]
denn wir haben ja angenommen, dass alle Werte von $i$ die gleiche Wahrscheinlichkeit,
nämlich $\frac{1}{n+1}$, haben.
\vspace*{0.1cm}

Berechnen wir nun den Wert von $\textsl{anzVgl}(i,n\!+\!1)$:
Falls $l$ aus $i$ Schlüsseln besteht und die restlichen $n-i$ Schlüssel in $r$ liegen,
so gibt es für den Schlüssel $k$, nach dem wir in dem Aufruf $b.\textsl{find}(k)$ suchen, 
$3$ Möglichkeiten:
\begin{enumerate}
\item $k$ kann mit dem Schlüssel $k'$ an der Wurzel des Baums übereinstimmen.
      In diesem Fall führen wir nur einen Vergleich durch.  Da es insgesamt
      $n+1$ Schlüssel in dem Baum gibt und nur in einem dieser Fälle
      der Schlüssel, den wir suchen, an der Wurzel steht, hat dieser Fall die
      Wahrscheinlichkeit
      \\[0.2cm]
      \hspace*{1.3cm} $\bruch{1}{\,n+1\,}$.

\item $k$ kann mit einem der $i$ Schlüssel im linken Teilbaum $l$ übereinstimmen.
      Da  der linke Teilbaum $i$ Schlüssel enthält und  es insgesamt
      $n+1$ Schlüssel gibt, hat die Wahrscheinlichkeit, dass $k$ in dem linken Teilbaum $l$
      auftritt, den Wert \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle\bruch{i}{n+1}$. \\[0.2cm]
       In diesem Fall werden \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle d_i + 1$ \\[0.2cm]
      Vergleiche durchgeführt, denn außer den $d_i$ Vergleichen mit den Schlüsseln aus dem
      linken Teilbaum muss der Schlüssel, der gesucht wird, ja noch mit dem Schlüssel an
      der Wurzel verglichen werden.
\item $k$ kann mit einem der $n-i$ Schlüssel im rechten Teilbaum $r$ übereinstimmen.

      Da  der rechte Teilbaum $n-i$ Schlüssel enthält und  es insgesamt
      $n+1$ Schlüssel gibt, hat die Wahrscheinlichkeit, dass $k$ in dem rechten Teilbaum $r$
      auftritt, den Wert \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle \bruch{n-i}{n+1}$. \\[0.2cm]
      Analog zum zweiten Fall werden diesmal \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle d_{n-i} + 1$ \\[0.2cm]
      Vergleiche durchgeführt. 
\end{enumerate}
Um nun  $\textsl{anzVgl}(i, n\!+\!1)$ berechnen zu können, müssen wir in jedem der drei
Fälle die Wahrscheinlichkeit mit der Anzahl der Vergleiche multiplizieren und
die Werte, die sich für die drei Fälle ergeben, aufsummieren.  Wir erhalten
\begin{eqnarray*}
  \textsl{anzVgl}(i, n\!+\!1) 
& = & \bruch{1}{\,n+1\,} \cdot 1 + \bruch{i}{n+1} \cdot (d_i + 1) + \bruch{n-i}{n+1} \cdot (d_{n-i} + 1) 
      \\[0.2cm]
& = & \bruch{1}{\,n+1\,} \cdot \bigl(1 + i \cdot (d_i + 1) + (n-i) \cdot (d_{n-i} + 1)\bigr)      \\[0.2cm]
& = & \bruch{1}{\,n+1\,} \cdot \bigl(1 + i + (n-i) + i \cdot d_i + (n-i) \cdot d_{n-i} \bigr)    \\[0.2cm]
& = & \bruch{1}{\,n+1\,} \cdot \bigl(n + 1 + i \cdot d_i + (n-i) \cdot d_{n-i} \bigr)            \\[0.2cm]
& = & 1 + \bruch{1}{\,n+1\,} \cdot \bigl(i \cdot d_i + (n-i) \cdot d_{n-i} \bigr) 
\end{eqnarray*}


Damit können wir nun die Rekurrenz-Gleichung für $d_{n+1}$ aufstellen: 
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}{lcl}
d_{n+1} 
& = &  
\ds\sum\limits_{i=0}^n \bruch{1}{\,n+1\,} \cdot \textsl{anzVgl}(i,\,n\!+\!1)  \\[0.5cm]
& = &  
\ds\bruch{1}{n+1} \cdot \sum\limits_{i=0}^n  
           \left(1 + \bruch{1}{n+1} \cdot \bigl(i \cdot d_i + (n-i) \cdot d_{n-i} \bigr) \right)
\\[0.5cm]
& = &  
\bruch{1}{n+1} \cdot \Biggl(\underbrace{\sum\limits_{i=0}^n 1}_{\stackrel{\displaystyle \shortparallel}{n+1}} \;+\;
           \bruch{1}{n+1} \cdot \ds\sum\limits_{i=0}^n \bigl(i \cdot d_i + (n-i) \cdot d_{n-i} \bigr) \Biggr)
\\[1.3cm]
& = &  
1 + \bruch{1}{(n+1)^2} \cdot \left(\ds\sum\limits_{i=0}^n \left(i\cdot d_i + (n-i)\cdot d_{n-i}\right) \right) 
\\[0.5cm]
& = &  
1 + \bruch{2}{(n+1)^2} \cdot \ds\sum\limits_{i=0}^n i\cdot d_i 
\end{array}
$
\\[0.2cm]
Bei der letzten Umformung haben wir die Gleichung  \\[0.2cm]
\hspace*{1.3cm}
$\ds\sum\limits_{i=0}^n f(n-i) = \sum\limits_{i=0}^n f(i)$ \\[0.2cm]
benutzt, die wir bei der Analyse der Komplexität von Quick-Sort gezeigt hatten.
Wir lösen jetzt die Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:bin1}
d_{n+1} = \displaystyle 1 + \bruch{2}{(n+1)^2} \cdot \sum\limits_{i=0}^n i\cdot d_i  
\end{equation}
mit der Anfangs-Bedingungen $d_1 = 1$.  
Zur Lösung von Gleichung (\ref{eq:bin1}) führen wir die Substitution $n \mapsto n+1$ durch und erhalten 
\begin{equation}
  \label{eq:bin2}
d_{n+2} = \displaystyle 1 + \bruch{2}{(n+2)^2} \cdot \sum\limits_{i=0}^{n+1} i\cdot d_i  
\end{equation}
Wir multiplizieren nun Gleichung (\ref{eq:bin1}) mit $(n+1)^2$ und Gleichung (\ref{eq:bin2}) 
mit $(n+2)^2$ und finden die Gleichungen 
\begin{eqnarray}
  \label{eq:bin3}
(n+1)^2 \cdot d_{n+1} & = & (n+1)^2 + 2 \cdot \sum\limits_{i=0}^n i\cdot d_i, \\
  \label{eq:bin4}
(n+2)^2 \cdot d_{n+2} & = & (n+2)^2 + 2 \cdot \sum\limits_{i=0}^{n+1} i\cdot d_i
\end{eqnarray}
Subtrahieren wir Gleichung (\ref{eq:bin3}) von Gleichung (\ref{eq:bin4}),
so erhalten wir \\[0.2cm]
\hspace*{1.3cm} 
$(n+2)^2 \cdot d_{n+2} - (n+1)^2 \cdot d_{n+1} = (n+2)^2 - (n+1)^2 + 2 \cdot (n+1) \cdot d_{n+1}$.
\\[0.2cm]
Zur Vereinfachung substituieren wir hier $n \mapsto n - 1$ und erhalten \\[0.2cm]
\hspace*{1.3cm} 
$(n+1)^2 \cdot d_{n+1} - n^2 \cdot d_{n} = (n+1)^2 - n^2 + 2 \cdot n \cdot d_{n}$.
\\[0.2cm]
Dies vereinfachen wir zu \\[0.2cm]
\hspace*{1.3cm} $(n+1)^2 \cdot d_{n+1}  =  n \cdot (n + 2) \cdot d_{n} + 2 \cdot n + 1$. \\[0.2cm]
Bei dieser Gleichung teilen wir auf beiden Seiten durch $(n+2)\cdot (n+1)$ und bekommen \\[0.2cm]
\hspace*{1.3cm}  
$\displaystyle \bruch{n+1}{n+2} \cdot d_{n+1}  =  \bruch{n}{n + 1} \cdot d_{n} + \bruch{2 \cdot n + 1}{(n+2)\cdot (n+1)}$. \\[0.2cm]
Nun definieren wir \\[0.2cm]
\hspace*{1.3cm} $\displaystyle c_n = \bruch{n}{n+1} \cdot d_n$. \\[0.4cm]
Dann gilt $c_1 = \bruch{1}{2} \cdot d_1 = \bruch{1}{2}$ und wir  haben die Rekurrenz-Gleichung \\[0.2cm]
\hspace*{1.3cm} 
$\displaystyle c_{n+1}  =  c_{n} + \frac{2 \cdot n + 1}{(n+2)\cdot (n+1)}$. \\[0.2cm]
Durch Partialbruch-Zerlegung finden wir \\[0.2cm]
\hspace*{1.3cm} 
$\displaystyle \frac{2 \cdot n + 1}{(n+2)\cdot (n+1)} = \frac{3}{n+2} - \frac{1}{n+1}$. \\[0.2cm]
Also haben wir \\[0.2cm]
\hspace*{1.3cm} $\displaystyle c_{n+1} = c_n +  \frac{3}{n+2} - \frac{1}{n+1}$. \\[0.2cm]
Wegen $c_1 = \bruch{1}{2}$ ist die Gleichung auch für $n=0$ richtig, wenn wir $c_0 = 0$ setzen, denn es gilt
\\[0.2cm]
\hspace*{1.3cm}
$\bruch{1}{2} = 0 + \bruch{3}{0+2} - \bruch{1}{0+1}$.
\\[0.2cm]
Die Rekurrenz-Gleichung für $c_n$ können wir mit dem Teleskop-Verfahren lösen:
\begin{eqnarray*}  
  c_{n+1} & = & c_0 + \sum\limits_{i=0}^{n} \frac{3}{i+2} - \sum\limits_{i=0}^{n} \frac{1}{i+1} 
\\[0.2cm]
          & = & \sum\limits_{i=2}^{n+2} \frac{3}{i} - \sum\limits_{i=1}^{n+1} \frac{1}{i}.
\end{eqnarray*}
Wir substituieren $n \mapsto n-1$ und vereinfachen dies zu 
\\[0.2cm]
\hspace*{1.3cm}
$c_{n} =  \displaystyle\sum\limits_{i=2}^{n+1} \frac{3}{i} - \sum\limits_{i=1}^{n} \frac{1}{i}$
\\[0.2cm]
Die harmonische Zahl $H_n$ ist als
$H_n = \ds\sum\limits_{i=1}^{n} \bruch{1}{i}$   
definiert.  Wir können $c_n$ auf $H_n$ zurückführen: 
\\[0.2cm]
\hspace*{1.3cm}
$c_n = \ds 3 \cdot H_n - \frac{3}{1} + \frac{3}{n+1} - H_n  =  \ds 2 \cdot H_n - 3 \cdot \frac{n}{n+1}$
\\[0.2cm] 
Wegen $H_n = \displaystyle\sum\limits_{i=1}^{n} \frac{1}{i} = \ln(n) + \Oh(1)$ und $\ds 3 \cdot\frac{n}{n+1} \in \Oh(1)$
gilt dann \\[0.3cm]
\hspace*{1.3cm} 
$\displaystyle c_n = 2 \cdot \ln(n) + \Oh(1)$.
\\[0.3cm]
Berücksichtigen wir  $d_n = \bruch{n+1}{n}\cdot c_n$, so finden wir für große $n$ ebenfalls \\[0.2cm]
\hspace*{1.3cm} $\displaystyle d_n = 2 \cdot \ln(n) + \Oh\bigl(1\bigr)$.
\\[0.2cm]
Das ist unser zentrales Ergebnis: Im Durchschnitt erfordert das Suchen in einem zufällig
erzeugten geordneten binären Baum für große Werte von $n$ etwa 
\\[0.2cm]
\hspace*{1.3cm}
$2 \cdot \ln(n) = 2 \cdot \ln(2) \cdot \log_2(n) \approx 1.386 \cdot \log_2(n)$ 
\\[0.2cm]
Vergleiche.  Damit werden etwa 39 \% 
mehr Vergleiche ausgeführt als bei einem optimal balancierten binären Baum.
Ähnliche Ergebnisse können wir für das Einfügen oder Löschen erhalten.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "algorithms"
%%% End: 
