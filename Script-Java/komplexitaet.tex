\chapter{Komplexität von Algorithmen} 
In diesem Kapitel führen wir 
Rekurrenz-Gleichungen\footnote{
Rekurrenz-Gleichungen werden in der Literatur auch als \emph{Rekursions-Gleichungen} bezeichnet.}
ein und zeigen, wie diese in einfachen Fällen gelöst werden können.  Außerdem stellen wir
die $O$-Notation vor.  Diese beiden Begriffe benötigen wir, um die Laufzeit von
Algorithmen analysieren zu können.  Die Algorithmen selber stehen in diesem Kapitel noch
im Hintergrund.

\section{Die Fibonacci-Zahlen}
Wir wollen \emph{Rekurrenz-Gleichungen} an Hand eines eher spielerischen Beispiels
einführen.  Dazu betrachten wir eine Kaninchen-Farm, für die wir einen Geschäftsplan
erstellen wollen.   Wir beschäftigen uns hier nur mit der Frage, wie sich eine
Kaninchen-Population entwickelt.  Wir gehen dabei von folgenden vereinfachenden Annahmen aus:
\begin{enumerate}
\item Jedes Kaninchen-Paar bringt jeden Monat ein neues Kaninchen-Paar zur Welt.
\item Kaninchen haben nach zwei Monaten zum ersten Mal Junge.
\item Kaninchen leben ewig.
\end{enumerate}
Wir nehmen nun an, wir hätten ein neugeborenes Kaninchen-Paar und stellen uns die Frage, wie
viele Kaninchen-Paare wir nach $n$ Monaten haben.  Bezeichnen wir die Zahl der
Kaninchen-Paare nach $n$ Monaten mit $k(n)$, so gilt:
\begin{enumerate}
\item $k(0) = 1$

      Wir starten mit einem neugeborenem Kaninchen-Paar.
\item $k(1) = 1$

      Kaninchen bekommen das erste Mal nach zwei Monaten Junge, also hat sich die Zahl
      der Kaninchen-Paare nach einem Monat noch nicht verändert.
\item $k(2) = 1 + 1$

      Nach zwei Monaten bekommt unser Kaninchen-Paar zum ersten Mal Junge.
\item Allgemein gilt nach $n + 2$ Monaten: \\[0.1cm]
      \hspace*{1.3cm} 
      $k(n+2) = k(n+1) + k(n)$

      Alle Kaninchen-Paare, die zum Zeitpunkt $n$ schon da sind, bekommen zum Zeitpunkt
      $n+2$ Junge. Dies erklärt den Term $k(n)$.  Da wir zur Vereinfachung unserer
      Rechnung von genetisch manipulierten unsterblichen Kaninchen ausgehen, sind alle
      Kaninchen, die zum Zeitpunkt $n+1$ vorhanden sind, auch noch zum Zeitpunkt $n+2$
      vorhanden. Dies erklärt den Term $k(n+1)$. 
\end{enumerate}
Die Folge der Zahlen $\bigl(k(n)\bigr)_{n\in\mathbb{N}}$ heißt Folge der \emph{Fibonacci-Zahlen}.  Das \Java-Programm in Abbildung
\ref{fig:fibonacci} auf Seite \pageref{fig:fibonacci} berechnet diese Zahlen.

\begin{figure}[!h]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    public class Fibonacci 
    {
        public static void main(String[] args) {
            for (int i = 0; i < 100; ++i) {
                int n = fibonacci(i);
                System.out.printf("fibonacci(%d) = %d\n", i, n);
            }
        }
        
        public static int fibonacci(int n) {
            if (n == 0) return 1;
            if (n == 1) return 1;
            return fibonacci(n - 1) + fibonacci(n - 2);
        }
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Ein \textsl{Java}-Programm zur Berechnung der Fibonacci-Zahlen.}
  \label{fig:fibonacci}
\end{figure} 

Wenn wir dieses Programm laufen lassen, stellen wir fest, dass die Laufzeiten mit
wachsendem Parameter $n$ sehr schnell anwachsen.  Um dieses Phänomen zu analysieren,
untersuchen wir exemplarisch, wie viele Additionen bei der Berechnung von
$\texttt{fibonacci}(n)$ für ein gegebenes $n \in \mathbb{N}$ benötigt werden.  Bezeichnen wir
diese Zahl mit $a_n$, so finden wir:
\begin{enumerate}
\item $a_0 = 0$.
\item $a_1 = 0$.
\item $n \geq 2 \rightarrow a_n = a_{n-1} + a_{n-2} + 1$,

      denn in den rekursiven Aufrufen $\texttt{fibonacci}(n-1)$ und $\texttt{fibonacci}(n-2)$ haben wir 
      $a_{n-1}$ bzw.~$a_{n-2}$ Additionen und dazu kommt noch die Addition der Werte
      $\texttt{fibonacci}(n-1)$ und $\texttt{fibonacci}(n-2)$.
\end{enumerate}
Wir setzen in der  Gleichung $a_n = 1 + a_{n-1} + a_{n-2}$ für $n$ den Wert $i+2$ ein und
haben dann \\[0.1cm]
\hspace*{1.3cm} $a_{i+2} = a_{i+1} + a_i + 1$ \hspace*{\fill} $(1)$\\[0.1cm]
Eine solche Gleichung nennen wir eine \emph{lineare} \emph{inhomogene}
\emph{Rekur\-renz-Gleichung}.   Die dieser Gleichung zugeordnete \emph{homogene}
\emph{Rekurrenz-Gleichung} lautet \\[0.1cm]
\hspace*{1.3cm} $a_{i+2} = a_{i+1} + a_i$ \hspace*{\fill} $(2)$\\[0.1cm]
Wir lösen diese Gleichung mit folgendem Ansatz: \\[0.1cm]
\hspace*{1.3cm} $a_i = \lambda^i$. \\[0.1cm]
Einsetzen dieses Ansatzes in $(*)$ führt auf die Gleichung 
\[ \lambda^{i+2} = \lambda^{i+1} + \lambda^i. \]
Wenn wir beide Seiten  dieser Gleichung durch $\lambda^i$ dividieren, erhalten wir die
quadratische Gleichung \\[0.1cm]
\hspace*{1.3cm} $\lambda^2 = \lambda + 1$, \\[0.1cm]
die wir mit Hilfe einer quadratischen Ergänzung lösen: \\[0.1cm]
\[\begin{array}{lcll}
  \lambda^2     & = & \lambda + 1                               & |\;- \lambda \\[0.1cm]
  \lambda^2 - 2 \cdot \frac{1}{2} \lambda & = & 1                   & |\;+ \frac{1}{4} \\[0.1cm]
  \lambda^2 - 2 \cdot \frac{1}{2} \lambda + \Big(\frac{1}{2}\Big)^2 & = &  \frac{5}{4} &  \\[0.1cm]
  \Big(\lambda -\frac{1}{2}\Big)^2 & = & \frac{5}{4}         & |\;\sqrt{\;\;} \\[0.1cm]
  \lambda -\frac{1}{2} & = & \pm\frac{\sqrt{5}}{2}           & | + \frac{1}{2} \\[0.1cm]
  \lambda_{1/2}  & = & \frac{1}{2} (1 \pm \sqrt{5}) & \\
 \end{array}
\]
Wir bemerken, dass jede Linear-Kombination der Form
\\[0.2cm]
\hspace*{1.3cm}
$a_n = \alpha \cdot \lambda_1^n + \beta \cdot \lambda_2^n$
\\[0.2cm]
eine Lösung der homogenen Rekurrenz-Gleichung $(2)$ ist.
Wir bemerken weiter, dass für die Lösungen $\lambda_1$ und $\lambda_2$ folgende Identitäten gelten:
\\[0.1cm]
\hspace*{1.3cm} 
$\lambda_1 - \lambda_2 = \sqrt{5}$ \quad und \quad $\lambda_1 + \lambda_2 = 1$. \hspace*{\fill} (3) \\[0.1cm]
Aus der letzen Gleichung folgt dann sofort \\[0.1cm]
\hspace*{1.3cm} $1 - \lambda_1 = \lambda_2$ \quad und \quad $1 - \lambda_2 = \lambda_1$ \hspace*{\fill} (4)  \\[0.1cm]
Um nun die ursprüngliche Rekurrenz-Gleichung (1) zu lösen, machen wir den Ansatz 
$a_i = c$.  Setzen wir diesen Ansatz in der Gleichung (1) ein, so erhalten wir die Gleichung \\[0.1cm]
\hspace*{1.3cm} $c = c + c + 1$, \\[0.1cm]
die die Lösung $c = -1$ hat.  Diese Lösung bezeichnen wir als eine \emph{spezielle Lösumg}.
Die \emph{allgemeine Lösung} der Rekurrenz-Gleichung (1) 
ergibt sich als Summe aus der Lösung der homogenen Rekurrenz-Gleichung und der speziellen
Lösung und lautet daher 
\[ a_i = \alpha \cdot \lambda_1^i + \beta \cdot \lambda_2^i - 1 \]
mit $\lambda_1 = \frac{1}{2} (1 + \sqrt{5})$ und $\lambda_2 = \frac{1}{2} (1 - \sqrt{5})$.
Die Koeffizienten $\alpha$ und $\beta$ sind jetzt so zu bestimmen, dass die
Anfangs-Bedingungen $a_0 = 0$ und $a_1 = 0$ erfüllt sind.  Das führt auf folgendes
lineares Gleichungs-System: 
\[\begin{array}{lcl}
    0 & = & \alpha \cdot \lambda_1^0 + \beta \cdot \lambda_2^0 - 1 \\[0.1cm]
    0 & = & \alpha \cdot \lambda_1^1 + \beta \cdot \lambda_2^1 - 1 \\
  \end{array}
\]
Addieren wir bei beiden Gleichungen 1 und vereinfachen für $i=1,2$ die Potenzen $\lambda_i^0$ zu $1$ und
$\lambda_i^1$ zu $\lambda_i$, so erhalten wir:
\[\begin{array}{lcl}
    1 & = & \alpha + \beta \\[0.1cm]
    1 & = & \alpha \cdot \lambda_1 + \beta \cdot \lambda_2  \\
  \end{array}
\]
Die erste dieser beiden Gleichungen liefert die Beziehung $\alpha = 1 - \beta$.  Setzen
wir dies für $\alpha$ in der zweiten Gleichung ein, so erhalten wir 
\[
\begin{array}{clcl}
                      &  1 & = & (1 - \beta)\cdot  \lambda_1 + \beta \cdot \lambda_2 \\[0.1cm]
\Leftrightarrow\quad  &  1 & = & 
 \lambda_1  + \beta \cdot \bigl( \lambda_2 - \lambda_1\bigr) \\[0.1cm]
\Leftrightarrow\quad  &  1 - \lambda_1 & = & \beta \cdot \bigl(\lambda_2 - \lambda_1\bigr)  \\[0.1cm]
\Leftrightarrow\quad  &  \bruch{1 - \lambda_1}{\lambda_2 - \lambda_1} & = & \beta \\[0.1cm]
\end{array}
\]
Wegen $\alpha = 1 - \beta$ finden wir dann \\[0.1cm]
\hspace*{1.3cm} $\alpha = - \bruch{1 - \lambda_2}{\lambda_2 - \lambda_1}$. \\[0.1cm]
Verwenden  wir hier die Gleichungen (3) und (4), so finden wir \\[0.1cm]
\hspace*{1.3cm} 
$\alpha = \bruch{\lambda_1}{\sqrt{5}} $ \quad und \quad $\beta  = -\bruch{\lambda_2}{\sqrt{5}}$. \\[0.1cm]
Damit können wir die Folge $(a_i)_i$ explizit angeben: \\[0.1cm]
\hspace*{1.3cm} 
$\displaystyle 
   a_i = \bruch{1}{\sqrt{5}} \cdot \left( \lambda_1^{i+1} - \lambda_2^{i+1} \right) - 1$ \\[0.1cm]
Wegen $\lambda_1\approx 1.61803$ und $\lambda_2 \approx - 0.61803$ dominiert der erste Term
der Summe und die Zahl der Additionen wächst exponentiell mit dem Faktor $\lambda_1$ an.
Dies erklärt das starke Anwachsen der Rechenzeit.
\vspace*{0.3cm}

\noindent
\textbf{Bemerkung}:  Die Zahl $\lambda_1$ wird auch als \emph{goldener Schnitt} bezeichnet
und spielt sowohl in der Geometrie als auch in der Kunst eine Rolle.

\noindent
Die Ursache der Ineffezienz der Berechnung der Fibonacci-Zahlen ist leicht zu sehen: Berechnen wir 
den Wert \texttt{fibonacci(5)} mit dem Programm aus Abbildung
\ref{fig:fibonacci}, so müssen wir \texttt{fibonacci(4)} und \texttt{fibonacci(3)} berechnen.
Die Berechnung von \texttt{fibonacci(4)} erfordert ihrerseits die Berechnung von \texttt{fibonacci(3)} und \texttt{fibonacci(2)}. 
Dann berechnen wir \texttt{fibonacci(3)} aber zweimal!  
Abbildung \ref{fig:fibonacci.eps} zeigt den sogenannten \emph{Rekursions-Baum} für den
Aufruf von $\textsl{fibonacci}(5)$, der den oben dargestellten Zusammenhang graphisch verdeutlicht.

\begin{figure}[!ht]
  \centering
  \framebox{\epsfig{file=fibonacci.eps, scale=0.6}} 
  \caption{Rekursions-Baum für die Berechnung von $\textsl{fibonacci}(5)$.}
  \label{fig:fibonacci.eps}
\end{figure}


Wir können eine effizientere Berechnung der Fibonacci-Zahlen implementieren, indem wir
uns die berechneten Werte merken.  Dazu können wir in \Java\ ein Feld benutzen.
 Dies führt zu dem in Abbildung \ref{fig:fibonacci-dynamic}
auf Seite \pageref{fig:fibonacci-dynamic} angegebenen Programm.
Da die Werte der Funktion \texttt{fibonacci}() exponentiell wachsen, reichen 32-Bit-Zahlen
nicht aus, um diese Werte darzustellen.  Wir verwenden daher die Klasse
\texttt{BigInteger}, mit der sich ganze Zahlen beliebiger Größe darstellen lassen.
Da Felder in \Java\ genau wie in \texttt{C} mit 0 beginnend indiziert werden,
hat ein Feld, dessen oberster Index $n$ ist, insgesamt $n+1$ Elemente.  Wir legen daher in
Zeile 19 ein Feld von $n+1$ Elementen an.

\begin{figure}[!h]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    import java.math.*;
    
    public class FibonacciBig
    {
        public static void main(String[] args) 
        {
            for (int i = 0; i < 100; ++i) {
                BigInteger n = fibonacci(i);
                System.out.println("fib(" + i + ") = " + n);
            }
        }
        
        public static BigInteger fibonacci(int n) 
        {
            if (n <= 2) {
                return BigInteger.valueOf(1);
            }
            BigInteger[] mem = new BigInteger[n+1];
            mem[0] = BigInteger.valueOf(1);  // fibonacci(0) = 1
            mem[1] = BigInteger.valueOf(1);  // fibonacci(1) = 1
            for (int i = 0; i < n - 1; ++i) {
                mem[i + 2] = mem[i].add(mem[i + 1]);
            }
            return mem[n];
        }
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Berechnung der Fibonacci-Zahlen mit Speicherung der Zwischenwerte.}
  \label{fig:fibonacci-dynamic}
\end{figure} 


\section{Lineare Rekurrenz-Gleichung \label{sec:lineare-RG}}
Wir waren bei der Analyse der Komplexität des ersten Programms zur Berechnung der
Fibonacci-Zahlen auf die Gleichung \\[0.1cm]
\hspace*{1.3cm} $a_{i+2} = a_{i+1} + {a_i} + 1$ \quad für alle $i \in \mathbb{N}$ \\[0.1cm]
gestoßen. Gleichungen dieser Form treten bei der Analyse der Komplexität rekursiver
Programme häufig auf. Wir wollen uns daher in diesem Abschnitt näher mit solchen
Gleichungen beschäftigen.

\begin{Definition}[Lineare homogene Rekurrenz-Gleichung] \hspace*{\fill} \\
{\em 
  Die \emph{lineare homogene Rekurrenz-Gleichung der Ordnung $k$ mit konstanten Koeffizienten} hat die Form
  \begin{equation}
    \label{eq:lhrg}
  a_{n+k} = c_{k-1} \cdot a_{n+k-1} + c_{k-2} \cdot a_{n+k-2} + \cdots + c_1 \cdot a_{n+1} + c_0 \cdot a_{n}
     \quad \mbox{für alle $n \in \N$}. 
  \end{equation}
     In Summen-Schreibweise kann diese Gleichung kompakter als 
     \\[0.1cm]
     \hspace*{1.3cm}
     $a_{n+k} = \sum\limits_{i=0}^{k-1} c_i \cdot a_{n+i}$ \quad für alle $n \in \mathbb{N}$
     \\[0.1cm]
     geschreiben werden.
     Zusätzlich werden \emph{Anfangs-Bedingungen}  
      \\[0.1cm]
      \hspace*{1.3cm}      
      $a_0 = d_0, \cdots, a_{k-1} = d_{k-1}$ 
      \\[0.1cm]
      für die Folge $\folge{a_n}$ vorgegeben.    
    \hspace*{\fill} $\Box$
}
\end{Definition}
Durch eine lineare homogene Rekurrenz-Gleichung wird die Folge $(a_n)_{n\in\mathbb{N}}$
eindeutig bestimmt: Die Werte $a_n$ für $n < k$ sind durch die Anfangs-Bedingungen gegeben und
alle weiteren Werte können dann durch die Rekurrenz-Gleichung (\ref{eq:lhrg}) bestimmt werden.
Noch  etwas zur Nomenklatur:
\begin{enumerate}
\item Die Rekurrenz-Gleichung (\ref{eq:lhrg}) heißt \emph{linear}, weil die Glieder der Folge $(a_n)_n$ nur
      linear in der Gleichung (\ref{eq:lhrg}) auftreten.  Ein Beispiel für eine
      Rekurrenz-Gleichung, die nicht linear ist, wäre \\[0.1cm]
      \hspace*{1.3cm} $a_{n+1} = a_n^2$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
      Nicht-lineare Rekurrenz-Gleichungen sind nur in Spezialfällen geschlossen lösbar.
\item Die Rekurrenz-Gleichung (\ref{eq:lhrg}) heißt \emph{homogen}, weil auf der rechten Seite
      dieser Gleichung kein konstantes Glied mehr auftritt.  Ein Beispiel für eine
      Gleichung, die nicht homogen ist (wir sprechen auch von \emph{inhomogenen}
      Rekurrenz-Gleichungen), wäre \\[0.1cm]
      \hspace*{1.3cm} $a_{n+2} = a_{n+1} + a_n + 1$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
      Mit inhomogenen Rekurrenz-Gleichungen werden wir uns später noch beschäftigen.
\item Die Rekurrenz-Gleichung (\ref{eq:lhrg}) hat \emph{konstante Koeffizienten}, weil die
      Werte $c_i$ Konstanten sind, die nicht von dem Index $n$ abhängen.  Ein Beispiel für
      eine Rekurrenz-Gleichung, die keine konstanten Koeffizienten hat, ist \\[0.1cm]
      \hspace*{1.3cm} $a_{n+1} = n\cdot a_n$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
      Solche Rekurrenz-Gleichungen können in vielen Fällen auf Rekurrenz-Gleichungen mit
      konstanten Koeffizienten zurück geführt werden.  Wir werden das später noch im
      Detail besprechen.
\end{enumerate}
Wie lösen wir eine lineare homogene Rekurrenz-Gleichung?  Wir versuchen zunächst den Ansatz\\[0.1cm]
\hspace*{1.3cm}  $a_n = \lambda^n$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Einsetzen dieses Ansatzes in (\ref{eq:lhrg}) führt auf die Gleichung \\[0.1cm]
\hspace*{1.3cm}
$\lambda^{n+k} = \sum\limits_{i=0}^{k-1} c_i \cdot \lambda^{n+i}$
\\[0.1cm]
Dividieren wir diese Gleichung durch $\lambda^n$, so haben wir: \\[0.1cm]
\hspace*{1.3cm} $\lambda^{k} = \sum\limits_{i=0}^{k-1} c_i \cdot \lambda^{i}$  
\\[0.1cm]
Das Polynom \\[0.1cm]
\hspace*{1.3cm} 
$\chi(x) = x^{k} - \sum\limits_{i=0}^{k-1} c_i \cdot x^{i}$  
\\[0.1cm]
 heißt \emph{charakteristisches Polynom} der Rekurrenz-Gleichung (\ref{eq:lhrg}).
Wir betrachten zunächst den Fall, dass das charakteristische  Polynom  $k$  verschiedene
Nullstellen hat.  In diesem Fall sagen, dass die Rekurrenz-Gleichung (\ref{eq:lhrg}) 
\emph{nicht entartet} ist.
Bezeichnen wir diese Nullstellen mit \\[0.1cm]
\hspace*{1.3cm}  $\lambda_1$, $\lambda_2$, $\cdots$, $\lambda_k$, \\[0.1cm]
so  gilt für alle $j = 1,\cdots, k$ \\[0.1cm]
\hspace*{1.3cm} 
$\lambda_j^{n+k} = \sum\limits_{i=0}^{k-1} c_i \cdot \lambda_j^{n+i}$.
\\[0.1cm]
Damit ist die Folge  
\[\bigl(\lambda_j^n)_{n\in\mathbb{N}}\]
für alle $j=1,\cdots,k$ eine Lösung der Rekurrenz-Gleichung (\ref{eq:lhrg}).
Außerdem ist auch jede Linear-Kombination dieser Lösungen eine Lösung von (\ref{eq:lhrg}):
Definieren wir die Folge $a_n$ durch \\[0.1cm]
\hspace*{1.3cm} $a_n = \alpha_1 \lambda_1^n + \cdots + \alpha_k \lambda_k^n$ \quad für alle $n \in \mathbb{N}$ \\[0.1cm]
mit beliebigen Koeffizienten $\alpha_i \in \R$, so erfüllt auch die Folge
$(a_n)_n$ die Gleichung (\ref{eq:lhrg}).  Die oben definierte Folge $(a_n)_n$ bezeichnen wir als
die  \emph{allgemeine Lösung} der Rekurrenz-Gleichung (\ref{eq:lhrg}): \\[0.1cm]
Die Koeffizienten $\alpha_1$ bis $\alpha_k$ müssen wir nun so wählen, dass die
Anfangs-Bedingungen 
\\[0.2cm]
\hspace*{1.3cm}
$a_0 = d_0$, $\cdots$, $a_{k-1} = d_{k-1}$
\\[0.2cm]
erfüllt sind.  Das liefert ein lineares Gleichungs-System für die Koeffizienten $\alpha_1$, $\cdots$, $\alpha_k$:
\[
\begin{array}{lcl}
  d_0     & = & \lambda_1^0 \cdot \alpha_1 + \cdots +   \lambda_k^0 \cdot \alpha_k \\[0.1cm]
  d_1     & = & \lambda_1^1 \cdot \alpha_1 + \cdots +   \lambda_k^1 \cdot \alpha_k \\[0.1cm]
  \vdots  &   & \vdots                                                   \\[0.1cm]
  d_{k-1} & = & \lambda_1^{k-1} \cdot \alpha_1 + \cdots +   \lambda_{k}^{k-1} \cdot \alpha_k \\[0.1cm]
\end{array}
\]
Hier sind die Werte $\lambda_i$  die Nullstellen des charakteristischen Polynoms.  
Die Matrix $V$, die diesem Gleichungs-System
zugeordnet ist, lautet: 
\[
V = \left(
\begin{array}{lcl}
  \lambda_1^0  & \cdots &   \lambda_k^0 \\[0.1cm]
  \lambda_1^1  & \cdots &   \lambda_k^1 \\[0.1cm]
  \vdots         &         & \vdots \\[0.1cm]
  \lambda_1^{k-1} & \cdots &   \lambda_{k}^{k-1} \\[0.1cm]
\end{array}\right)
\]
Diese Matrix ist in der Mathematik als \emph{Vandermonde}'sche Matrix bekannt.  Für die
Determinate dieser Matrix gilt \\[0.1cm]
\hspace*{1.3cm} $\det(V) = \prod\limits_{1 \leq i < j \leq k} (\lambda_i - \lambda_j)$. \\[0.1cm]
Sind die Nullstellen $\lambda_i$ für $i=1,\cdots,k$ paarweise verschieden, so ist jeder
der Faktoren $(\lambda_i - \lambda_j)$ von 0 verschieden und damit ist auch das Produkt
von 0 verschieden.  Daraus folgt, das das zugehörige lineare Gleichungs-System eindeutig
lösbar ist.  Mit der Lösung dieses Gleichungs-Systems
 haben wir dann die Lösung der Rekurrenz-Gleichung (\ref{eq:lhrg}) gefunden.
\vspace*{0.1cm}

\noindent
\textbf{Beispiel}:  Wie demonstrieren das Verfahren an einem Beispiel: Wie betrachten die
Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $F_{n+2} = F_{n+1} + F_{n}$ \quad für alle $n \in \mathbb{N}$  \\[0.1cm]
mit den Anfangs-Bedingungen $F_0 = 0$ und $F_1 = 1$.  Die Lösung dieser
Rekurrenz-Gleichung sind übrigens gerade die Fibonacci-Zahlen.
Das \emph{charakteristische Polynom} dieser Rekurrenz-Gleichung lautet: \\[0.1cm]
\hspace*{1.3cm} $\chi(x) = x^2 - x - 1$.  \\[0.1cm]
Das führt auf die quadratische Gleichung \\[0.1cm]
\hspace*{1.3cm} $x^2 -x - 1 = 0$ \\[0.1cm]
Wir haben eben schon gesehen, dass diese quadratische Gleichung die Lösung \\[0.1cm]
\hspace*{1.3cm}
 $ x_{1/2} = \frac{1}{2} \cdot (1 \pm \sqrt{5})$ 
\\[0.1cm]
hat.  Wir definieren \\[0.1cm]
\hspace*{1.3cm} 
$\lambda_1 = \frac{1}{2} \cdot (1 + \sqrt{5})$ \quad und  \quad 
$\lambda_2 = \frac{1}{2} \cdot (1 - \sqrt{5})$. \\[0.1cm]
Damit lautet die \emph{allgemeine Lösung} der betrachteten Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm}  $F_n = \alpha_1 \cdot \lambda_1^n  + \alpha_2 \cdot \lambda_2^n$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Setzen wir hier die Anfangs-Bedingungen ein, so erhalten wir
\[
\begin{array}{lcl}
    0 & = & \lambda_1^0 \cdot \alpha_1 + \lambda_2^0   \cdot \alpha_2 \\[0.1cm]
    1 & = & \lambda_1^1 \cdot \alpha_1 + \lambda_2^{1} \cdot \alpha_2 
\end{array}
\]
Dies ist ein lineares Gleichungs-System in den Unbekannten $\alpha_1$ und
$\alpha_2$. Vereinfachung führt auf 
\[
\begin{array}{lcl}
    0 & = & \alpha_1 + \alpha_2 \\[0.1cm]
    1 & = & \lambda_1 \cdot \alpha_1 + \lambda_2 \cdot \alpha_2 
\end{array}
\]
Die erste dieser beiden Gleichungen lösen wir nach $\alpha_2$ auf und finden  $\alpha_2 = - \alpha_1$.
Diesen Wert setzen wir in der zweiten Gleichung ein.  Das führt auf
\[
\begin{array}{lrcl}
                 & 1 & = & \lambda_1 \cdot \alpha_1 - \lambda_2 \cdot \alpha_1 \\
 \Leftrightarrow & 1 & = & (\lambda_1 - \lambda_2) \cdot \alpha_1 \\
 \Leftrightarrow & \bruch{1}{\lambda_1 - \lambda_2} & = & \alpha_1 \\
\end{array}
\]
Setzen wir diesen Wert in der Gleichung $\alpha_2 = - \alpha_1$ ein, so erhalten wir \\[0.1cm]
\hspace*{1.3cm} 
  $\alpha_2 = \bruch{- 1}{\lambda_1 - \lambda_2}$.
\\[0.1cm]
Setzen wir die  Werte für $\lambda_1$ und $\lambda_2$ ein, so finden wir:  \\[0.1cm]
\hspace*{1.3cm} 
$\alpha_1 = \bruch{1}{\sqrt{5}}$ \quad und \quad $\alpha_2 = - \bruch{1}{\sqrt{5}}$.
\\[0.1cm]
Die Lösung der Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $F_{n+2} = F_{n+1} + F_{n}$ \quad für alle $n \in \mathbb{N}$ \\[0.1cm]
mit den Anfangs-Bedingungen $F_0 = 1$ und $F_1 = 1$   lautet also 
\\[0.1cm]
\hspace*{1.3cm} 
$F_n = \bruch{1}{\sqrt{5}}\cdot \left( \lambda_1^{n} - \lambda_2^{n} \right)$ 
\quad für alle $n \in \mathbb{N}$.  
\\[0.1cm]
Damit haben wir eine geschlossene Formel zur Berechnung der Fibonacci-Zahlen
gefunden.  Diese Formel zeigt uns, dass die Fibonacci-Zahlen selbst exponentiell anwachsen.
Wir werden diese Lösung bei der Analyse des Euklidischen-Algorithmus benötigen.

\vspace*{0.2cm}
\noindent
\textbf{Aufgabe}:  Lösen Sie die Rekurrenz-Gleichung 
$a_{n+2} = \bruch{3}{2} \cdot a_{n+1} - \bruch{1}{2}\cdot a_n$ mit
den Anfangs-Bedingungen $a_0 = 3$ und $a_1 = \bruch{5}{2}$.

%\noindent
%\textbf{Lösung}: $a_n = 2 + \left(\frac{1}{2}\right)^n$.

\subsection{Entartete Rekurrenz-Gleichungen}
Wir hatten oben zunächst den Fall betrachtet, dass das charakteristische Polynom der
Rekurrenz-Gleichung (\ref{eq:lhrg}) insgesamt $k$ verschiedene Nullstellen hat.   Dies muss
keineswegs immer der Fall sein.  Wir betrachten die Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:erg}
  a_{n+2} = 4 \cdot a_{n+1} - 4 \cdot a_n \quad \mbox{für alle $n \in \mathbb{N}$} 
\end{equation}
 mit den Anfangs-Bedingungen $a_0 = 1$, $a_1 = 4$.  Das charakteristische Polynom lautet \\[0.1cm]
\hspace*{1.3cm} $\chi(x) = x^2 - 4 \cdot x + 4 = (x - 2)^2$ \\[0.1cm]
und hat offensichtlich nur eine Nullstelle bei $x = 2$.   Eine Lösung der
Rekurrenz-Gleichung (\ref{eq:erg}) lautet daher \\[0.1cm]
\hspace*{1.3cm} $a_n = 2^n$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Eine weitere Lösung ist \\[0.1cm]
\hspace*{1.3cm} $a_n = n \cdot 2^n$ \quad für alle $n \in \mathbb{N}$.  \\[0.1cm]
Wir verifizieren dies durch Einsetzen: 
\[
\begin{array}{llcll}
 & (n+2) \cdot 2^{n+2} & = & 4 \cdot (n+1) \cdot 2^{n+1} - 4 \cdot n \cdot 2^n & \mid\; \div 2^n \\
\Leftrightarrow & 
   (n+2) \cdot 2^{2} & = & 4 \cdot (n+1) \cdot 2^{1} - 4 \cdot n  &  \mid\; \div 4 \\
\Leftrightarrow & n + 2 & = & (n + 1) \cdot 2 -  n  &  \\
\Leftrightarrow & n + 2 & = & 2 \cdot n + 2 -  n   \\
\Leftrightarrow & n + 2 & = & n + 2    \\
\end{array}
\]
Die allgemeine Lösung der Rekurrenz-Gleichung finden wir durch Linear-Kombination der
beiden Lösungen: \\[0.1cm]
\hspace*{1.3cm} $a_n = \alpha \cdot 2^n + \beta \cdot n \cdot 2^n$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Setzen wir hier die Anfangs-Bedingungen $a_0 = 1$ und $a_2 = 4$ ein, so erhalten wir:
\[
\left\{
\begin{array}{lcl}
  1 & = & \alpha \cdot 2^0 + \beta \cdot 0 \cdot 2^0 \\
  4 & = & \alpha \cdot 2^1 + \beta \cdot 1 \cdot 2^1 \\
\end{array}
\right\} \quad\Leftrightarrow\quad \left\{
\begin{array}{lcl}
  1 & = & \alpha \\
  4 & = & \alpha \cdot 2 + \beta \cdot 2 \\
\end{array}
\right\}\]
Die Lösung lautet offenbar $\alpha = 1$ und $\beta = 1$.  Damit lautet die Lösung der
Rekurrenz-Gleichung (\ref{eq:erg}) mit den Anfangs-Bedingungen $a_0 = 1$ und $a_2 = 4$ \\[0.1cm]
\hspace*{1.3cm} $a_n = 2^n + n \cdot 2^n = (n+1) \cdot 2^n$ \quad für alle $n \in \mathbb{N}$.  \\[0.1cm]
Im allgemeinen nennen wir die Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $a_{n+k} = \sum\limits_{i=0}^{k-1} c_{i} \cdot a_{n+i}$ \\[0.1cm]
\emph{entartet}, wenn das charakteristische Polynom \\[0.1cm]
\hspace*{1.3cm} $\chi(x) = x^k - \sum\limits_{i=0}^{k-1} c_{i} \cdot x^{i}$  \\[0.1cm]
weniger als $k$ verschiedene Nullstellen hat.  Dann lässt sich folgendes
zeigen:  Hat das charakteristische Polynom $\chi(x)$ eine $r$-fache Nullstelle
$\lambda$, gilt also \\[0.1cm]
\hspace*{1.3cm} $\chi(x) = (x - \lambda)^r \cdot \phi(x)$ \\[0.1cm]
mit einem geeigneten Polynom $\phi(x)$, so sind die Folgen
\begin{enumerate}
\item $(\lambda^n)_{n\in\mathbb{N}}$
\item $(n\cdot\lambda^n)_{n\in\mathbb{N}}$
\item $(n^2\cdot\lambda^n)_{n\in\mathbb{N}}$
\item $\vdots$
\item $(n^{r-1}\cdot\lambda^n)_{n\in\mathbb{N}}$
\end{enumerate}
Lösungen der Rekurrenz-Gleichung (\ref{eq:erg}).  Durch eine geeignete Linear-Kombination dieser
Lösungen zusammen mit den Lösungen, die sich aus den Nullstellen des Polynoms $\phi$
ergeben, lässt sich dann immer eine Lösung finden, die auch den Anfangs-Bedingungen genügt.
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}: Lösen Sie die Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $a_{n+3} = a_{n+2} + a_{n+1} - a_n$ \\[0.1cm]
für die Anfangs-Bedingungen $a_0 = 0$, $a_1 = 3$, $a_2 = 2$.

%\noindent
%\textbf{Lösung}: allg. $a_n = \alpha + n \cdot \beta + \gamma \cdot (-1)^n$. 
%Anfangs-Bedingungen: $a_n = 1 + n - (-1)^n$.

\subsection{Inhomogene Rekurrenz-Gleichungen}    
\begin{Definition}[Lineare inhomogene Rekurrenz-Gleichung]
{\em Die \emph{lineare \underline{inhomo}g\underline{ene} Rekur\-renz-Gleichung der Ordnung
$k$ mit konstanten Koeffizienten und konstanter Inhomogenität} hat die Form 
\begin{equation}
  \label{eq:lihrg}
     a_{n+k} = \sum\limits_{i=0}^{k-1} c_{i} \cdot a_{n+i} + c_{-1}  
\end{equation}
     mit den Anfangs-Bedingungen $a_0 = d_0$, $\cdots$, $a_{k-1} = d_{k-1}$. 
     Dabei gilt für die Koeffizienten \\[0.1cm]
     \hspace*{1.3cm} $c_i \in \R$ \quad für alle $i = -1, 0,\cdots, k-1$. \\[0.1cm]
     Für die  \emph{Anfangs-Bedingungen} $d_0, \cdots, d_{k-1}$ gilt ebenfalls \\[0.1cm]
     \hspace*{1.3cm} $d_i \in \R$ \quad für alle $i = 0,\cdots, k-1$. \\[0.1cm]
     Die Konstante $c_{-1}$ bezeichnen wir als die \emph{Inhomogenität}. 
     \hspace*{\fill} $\Box$
}
\end{Definition}

Wie lässt sich die inhomogene Rekurrenz-Gleichung (\ref{eq:lihrg}) lösen? Wir zeigen
zunächst, wie sich eine \emph{spezielle Lösung} der Rekurrenz-Gleichung (\ref{eq:lihrg})
finden lässt.  Dazu betrachten wir das charakteristische Polynom \\[0.1cm]
\hspace*{1.3cm} 
$\chi(x) = x^k - \sum\limits_{i=0}^{k-1} c_{i} \cdot x^i$
\\[0.1cm]
und definieren die \emph{Spur} $\mathtt{sp}(\chi)$ wie folgt: \\[0.1cm]
\hspace*{1.3cm} 
$\mathtt{sp}(\chi) := \chi(1) = 1 - \sum\limits_{i=0}^{k-1} c_{i}$. \\[0.1cm]
Es können zwei Fälle auftreten, $\mathtt{sp}(\chi) \not= 0$ und
$\mathtt{sp}(\chi) = 0$.
Wir betrachten die beiden Fälle getrennt.
\begin{enumerate}
\item $\mathtt{sp}(\chi) \not= 0$.

      Dann erhalten wir eine spezielle Lösung von (\ref{eq:lihrg}) durch den Ansatz \\[0.1cm]
      \hspace*{1.3cm} $a_n = \delta$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
      Den Wert von $\delta$ bestimmen wir durch Einsetzen, es muss für alle $n\in \mathbb{N}$ gelten: \\[0.1cm]
      \hspace*{1.3cm} 
      $\delta = \sum\limits_{i=0}^{k-1} c_{i} \cdot \delta + c_{-1}$.
      \\[0.1cm]
      Daraus ergibt sich \\[0.1cm]
      \hspace*{1.3cm} 
      $\delta \cdot \left(1 - \sum\limits_{i=0}^{k-1} c_{i} \right) =  c_{-1}$. \\[0.1cm]
      Das ist aber nichts anderes als \\[0.1cm]
      \hspace*{1.3cm} $\delta \cdot \mathtt{sp}(\chi) = c_{-1}$ \\[0.1cm]
      und damit lautet eine spezielle Lösung von (\ref{eq:lihrg}) \\[0.1cm]
      \hspace*{1.3cm} $a_n = \delta = \bruch{c_{-1}}{\mathtt{sp}(\chi)}$.
      \\[0.1cm]
      Jetzt sehen wir auch, warum die Voraussetzung $\mathtt{sp}(\chi) \not= 0$
      wichtig ist, denn anderfalls wäre der Quotient
      $\bruch{c_{-1}}{\mathtt{sp}(\chi)}$ undefiniert.
\item $\mathtt{sp}(\chi) = 0$.

      In diesem Fall versuchen wir, eine spezielle Lösung von (\ref{eq:lihrg}) durch den
      Ansatz \\[0.1cm]
      \hspace*{1.3cm} $a_n = \varepsilon \cdot n $ \\[0.1cm]
      zu finden.  Den Wert $\varepsilon$ erhalten wir durch Einsetzen, es muss für 
      alle $n\in\mathbb{N}$ gelten: \\[0.1cm]
      \hspace*{1.3cm} 
      $\varepsilon \cdot (n + k) = \sum\limits_{i=0}^{k-1} c_{i} \cdot \varepsilon \cdot (n + i) + c_{-1}$  
      \\[0.1cm]
      Dies formen wir wie folgt um:
      \[
        \varepsilon \cdot n + \varepsilon \cdot k = 
        \varepsilon \cdot n \cdot \sum\limits_{i=0}^{k-1} c_{i} +
        \varepsilon \cdot \sum\limits_{i=0}^{k-1} i \cdot c_{i} + c_{-1} 
      \]
      Aus  $\mathtt{sp}(\chi) = 0$ folgt $1  =  \sum\limits_{i=0}^{k-1} c_i$
      und damit gilt \\[0.1cm]
      \hspace*{1.3cm} 
      $\varepsilon \cdot n = \varepsilon \cdot n \cdot \sum\limits_{i=0}^{k-1} c_{i}$.
      \\[0.1cm]
      Daher vereinfacht sich die obige Gleichung zu 
      \[
      \begin{array}{ll}
      & \varepsilon \cdot k = \varepsilon \cdot \sum\limits_{i=0}^{k-1} i \cdot c_{i} + c_{-1} \\[0.4cm]
      \Leftrightarrow\quad 
      & \varepsilon \cdot \left(k - \sum\limits_{i=0}^{k-1} i \cdot c_{i}\right) = c_{-1} 
      \\[0.5cm]
      \Leftrightarrow\quad 
      & \varepsilon = \frac{\displaystyle c_{-1}}{\displaystyle \; k - \sum\limits_{i=0}^{k-1} i \cdot c_{i}\;} 
      \end{array}
      \]
      Wenn wir genau hin schauen, dann sehen wir, dass der Wert im Nenner nicht anderes ist
      als der Wert der Ableitung des charakteristischen Polynoms an der Stelle 1, denn es gilt: \\[0.1cm]
      \hspace*{1.3cm} 
      $\chi'(x) =\bruch{d\,\chi(x)}{dx} = k \cdot x^{k-1} - \sum\limits_{i=0}^{k-1} c_{i}\cdot i \cdot x^{i-1}$
      \\[0.1cm]
      Setzen wir hier für $x$ den Wert $1$ ein, so finden wir \\[0.1cm]
      \hspace*{1.3cm} 
      $\chi'(1) = k - \sum\limits_{i=0}^{k-1} c_{i}\cdot i$. 
      \\[0.1cm]
      Insgesamt haben wir damit also die folgende spezielle Lösung $(a_n)_{n\in\mathbb{N}}$
      der Gleichung (\ref{eq:lihrg}) gefunden: \\[0.1cm]
      \hspace*{1.3cm} $a_n = \bruch{c_{-1}}{\;\chi'(1)\;}\cdot n$.

      Wir haben oben zur Vereinfachung angenommen, dass dieser Wert von 0 verschieden ist,
      dass also das charakteristische Polynom $\chi(x)$ an der Stelle $x=1$ keine mehrfache
      Nullstelle hat, denn nur dann ist $\varepsilon$ durch die
      obige Gleichung wohldefiniert und wir haben eine spezielle Lösung der
      Rekurrenz-Gleichung (\ref{eq:lihrg}) gefunden.  Andernfalls können wir die Reihe nach die
      Ansätze $a_n = \varepsilon \cdot n^2$, $a_n = \varepsilon \cdot n^3$ , $\cdots$
      versuchen, denn es kann folgendes gezeigt werden: 
      Hat das charakteristische Polynom $\chi(x)$ am Punkt $x = 1$ eine Nullstelle vom Rang $r$,
      so führt der Ansatz $a_n = \varepsilon \cdot n^r$ zu einer speziellen Lösung von (\ref{eq:lihrg}).
\end{enumerate}
Diese spezielle Lösung genügt i.~a.~noch nicht den
Anfangs-Bedingungen. Eine Lösung, die auch den Anfangs-Bedingungen genügt, erhalten wir,
wenn wir zu der speziellen Lösung die allgemeine Lösung der zugehörigen homogenen linearen
Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} 
     $a_{n+k} = c_{k-1} \cdot a_{n+k-1} + c_{k-2} \cdot a_{n+k-2} + \cdots + c_1 \cdot a_{n+1} + c_0 \cdot a_{n}$ 
\\[0.1cm]
addieren und die Koeffizienten der allgemeinen Lösung so wählen, dass die
Anfangs-Bedingungen erfüllt sind.  Wir betrachten  ein Beispiel:
 Die zu lösende Rekurrenz-Gleichung lautet \\[0.1cm]
\hspace*{1.3cm} $a_{n+2} = 3 \cdot a_{n+1} - 2 \cdot a_n -1$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Die Anfangs-Bedingungen sind $a_0 = 1$ und $a_1 = 3$.  Wir berechnen zunächst eine
spezielle Lösung.  Das charakteristische Polynom ist \\[0.1cm]
\hspace*{1.3cm} $\chi(x) = x^2 -3 \cdot x +2 = (x - 1) \cdot (x - 2)$. \\[0.1cm]
Es gilt $\mathtt{sp}(\chi) = \chi(1) = 0$.  Wir versuchen für die spezielle Lösung
den Ansatz \\[0.1cm]
\hspace*{1.3cm} $a_n = \varepsilon \cdot n$. \\[0.1cm]
Einsetzen in die Rekurrenz-Gleichung liefert \\[0.1cm]
\hspace*{1.3cm}  $\varepsilon \cdot (n+2) = 3 \cdot \varepsilon \cdot(n+1) - 2 \cdot \varepsilon \cdot n -1$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Das ist äquivalent zu \\[0.1cm]
\hspace*{1.3cm} $\varepsilon \cdot (2 - 3) = - 1$ \\[0.1cm]
und daraus folgt sofort $\varepsilon = 1$.  Damit lautet eine spezielle Lösung \\[0.1cm]
\hspace*{1.3cm} $a_n = n$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Da die Nullstellen des charakteristischen Polynoms $\chi(x)$ bei 1 und 2 liegen, finden
wir für die allgemeine Lösung 
\\[0.1cm]
\hspace*{1.3cm} $a_n = \alpha \cdot 1^n + \beta \cdot 2^n + n$ \quad für alle $n \in \mathbb{N}$. \\[0.1cm]
Setzen wir hier für $n$ die Werte $0$ und $1$ und für $a_n$ die beiden Anfangs-Bedingungen
ein, so erhalten wir das Gleichungs-System \\[0.1cm]
\[ \left\{
\begin{array}{lcl}
1 &=& \alpha \cdot 1^0 + \beta \cdot 2^0 + 0 \\
3 &=& \alpha \cdot 1^1 + \beta \cdot 2^1 + 1
\end{array} \right\} \Leftrightarrow \left\{
\begin{array}{lcl}
1 &=& \alpha + \beta  \\
3 &=& \alpha + 2 \cdot \beta + 1
\end{array} \right\}\]
Sie können leicht nachrechnen, dass dieses Gleichungs-System die Lösung $\alpha = 0$ und
$\beta = 1$ hat.  Damit lautet die Lösung der Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $a_n = 2^n + n$ \quad für alle $n \in \mathbb{N}$.
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}: Lösen Sie die inhomogene Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $a_{n+2} = 2 \cdot a_n - a_{n+1} + 3$ \\[0.1cm]
für die Anfangs-Bedingungen $a_0 = 2$ und $a_1 = 1$.
% charakteristisches Polynom: $\chi(x) = x^2 + x - 2 = (x - 1) * (x + 2)
% sp(\chi) = 0, \chi'(x) = 2*x + 1, \chi'(1) = 3
% Lsg: a_n = \varepsilon * n mit \varepsilon = 1
% Lsg: a_n = 4/3 + 2/3*(-2)^n + n
\pagebreak

\subsection{Lineare inhomogene Rekurrenz-Gleichungen mit veränderlichen Inhomogenitäten}
Gelegentlich tauchen in der Praxis Rekurrenz-Gleichungen auf, in denen die Inhomogenität
keine Konstante ist, sondern von $n$ abhängt.  In solchen Fällen führt die
Technik des \emph{diskreten Differenzieren} oft zum Erfolg.  Wir stellen die Technik an
einem Beispiel vor und betrachten die Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:dd}
a_{n+1} = 2 \cdot a_n + n \quad \mbox{für alle $n \in \mathbb{N}$}  
\end{equation}
und der Anfangs-Bedingungen $a_0 = 0$.  Das Verfahren zur Lösung solcher
Rekurrenz-Gleichung besteht aus vier Schritten:
\begin{enumerate}
\item Substitutions-Schritt: Im \emph{Substitutions-Schritt} setzen wir in der
      ursprünglichen Rekurrenz-Gleichung (\ref{eq:dd}) für $n$ den Wert $n + 1$ ein und
      erhalten 
      \begin{equation}
        \label{eq:dd2}
        a_{n+2} = 2 \cdot a_{n+1} + n + 1 \quad \mbox{für alle $n \in \N$}
      \end{equation}
\item Subtraktions-Schritt: Im \emph{Subtraktions-Schritt} ziehen wir von der im
      Substitutions-Schritt erhaltenen Rekurrenz-Gleichung (\ref{eq:dd2}) die ursprüngliche
      gegebene Rekurrenz-Gleichung (\ref{eq:dd}) ab.  In unserem Fall erhalten wir \\[0.1cm]
      \hspace*{1.3cm} 
      $a_{n+2} - a_{n+1} = 2 \cdot a_{n+1} + n + 1 - \left( 2 \cdot a_n + n \right)$ 
      \quad für alle $n \in \mathbb{N}$.       \\[0.1cm]
      Vereinfachung dieser Gleichung liefert 
      \begin{equation}
        \label{eq:dd3}
        a_{n+2} = 3 \cdot a_{n+1} - 2 \cdot a_n + 1 \quad \mbox{für alle $n \in \N$}.
      \end{equation}
      Die beiden Schritte 1. und 2. bezeichnen wir zusammen als 
      \emph{diskretes Differenzieren} der Rekurrenz-Gleichung.
\item Berechnung zusätzlicher Anfangs-Bedingungen: Die Rekurrenz-Gleichung (\ref{eq:dd3})
      ist eine inhomogene Rekurrenz-Gleichung der Ordnung 2 mit nun aber konstanter
      Inhomogenität.  Wir haben bereits gesehen, 
      wie eine solche Rekurrenz-Gleichung zu lösen ist, wir benötigen aber eine
      zusätzliche Anfangs-Bedingung für $n=1$.  Diese erhalten wir, indem wir in der
      ursprünglichen Rekurrenz-Gleichung (\ref{eq:dd}) für $n$ den Wert 0 einsetzen: \\[0.1cm]
      \hspace*{1.3cm} $a_1 = 2 \cdot a_0 + 0 = 0$.
\item Lösen der inhomogenen Rekurrenz-Gleichung mit konstanter Inhomogenität:
      Das charakteristische Polynom der Rekurrenz-Gleichung (\ref{eq:dd3}) lautet: \\[0.1cm]
      \hspace*{1.3cm} $\chi(x) = x^2 - 3 \cdot x + 2 = (x - 2) \cdot (x - 1)$. \\[0.1cm]
      Offenbar gilt $\mathtt{sp}(\chi) = 0$.  Um eine spezielle Lösung der
      Rekurrenz-Gleichung
      (\ref{eq:dd3}) zu erhalten, machen wir daher den Ansatz \\[0.1cm]
      \hspace*{1.3cm} $a_n = \varepsilon \cdot n$ \\[0.1cm]
      und erhalten \\[0.1cm]
      \hspace*{1.3cm} 
      $\varepsilon \cdot (n+2) = 3 \cdot \varepsilon \cdot (n+1) - 2 \cdot \varepsilon \cdot n + 1$ 
      \\[0.1cm]
      Diese Gleichung liefert die Lösung \\[0.1cm]
      \hspace*{1.3cm} 
      $\varepsilon = -1$. \\[0.1cm]
      Damit lautet die allgemeine Lösung der Rekurrenz-Gleichung (\ref{eq:dd3}): \\[0.1cm]
      \hspace*{1.3cm} $a_n = \alpha_1 \cdot 2^n + \alpha_2 \cdot 1^n - n$ \\[0.1cm]
      Die Koeffizienten $\alpha_1$ und $\alpha_2$ finden wir nun durch Einsetzen der
      Anfangs-Bedingungen:
      \[
      \begin{array}{lcl}
        0 & = & \alpha_1 + \alpha_2 \\
        0 & = & 2 \cdot \alpha_1 + \alpha_2 - 1 \\
      \end{array}
      \]
      Aus der ersten Gleichung folgt $\alpha_2 = - \alpha_1$.  Damit vereinfacht sich die
      zweite Gleichung zu \\[0.1cm]
      \hspace*{1.3cm} $0 = 2 \cdot \alpha_1 - \alpha_1 - 1$ \\[0.1cm]
      und damit lautet die Lösung $\alpha_1 = 1$ und $\alpha_2 = -1$.  Die Lösung der
      ursprünglichen Rekurrenz-Gleichung (\ref{eq:dd}) mit der Anfangs-Bedingung $a_0 = 0$ 
      ist also \\[0.1cm]
      \hspace*{1.3cm} $a_n = 2^n - 1 - n$.
\end{enumerate}
Das oben gezeigte Verfahren funktioniert, wenn die Inhomogenität der Rekurrenz-Gleichung
linear ist, also die Form $\delta \cdot n$.  Ist die Inhomogenität quadratisch, so können wir
die Gleichung durch diskretes Differenzieren auf eine Rekurrenz-Gleichung reduzieren,
deren Inhomogenität linear ist.  Diese kann dann aber mit dem eben gezeigten Verfahren
gelöst werden.  Allgemein gilt:  Hat die Inhomogenität der Rekurrenz-Gleichung die Form \\[0.1cm]
\hspace*{1.3cm} $\delta \cdot n^r$ \quad $r \in \mathbb{N}$ und $r > 0$, \\[0.1cm]
so kann die Rekurrenz-Gleichung durch $r$-maliges diskretes Differenzieren auf eine
inhomogene Rekurrenz-Gleichung mit konstanter Inhomogenität reduziert werden.
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}:  Lösen Sie die Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $a_{n+1} = a_n + 2 \cdot n$ \quad für alle $n \in \mathbb{N}$ \\[0.1cm]
mit der Anfangs-Bedingung $a_0 = 0$.
\vspace*{0.3cm}

%\noindent
%\textbf{Lösung}: 
%\begin{enumerate}
%\item Charakteristisches Polynom: $\chi(x) = (x-1)^2$, doppelte Nullstelle! 
%\item Spezielle Lösung: $a_n = n^2$.
%\item Allgemeine Lösung: $a_n = \alpha_1 \cdot 1^n + \alpha_2 \cdot n \cdot 1^n + n^2$
%\item Lösung: $a_n = n\cdot(n-1)$.
%\end{enumerate}

\noindent
Die oben vorgestellte Technik des diskreten Differenzierens führt in leicht variierter
Form oft auch dann noch zu einer Lösung, wenn die Inhomogenität nicht die Form eines
Polynoms hat.  Wir betrachten als Beispiel die Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:expdd}
  a_{n+1} = a_n + 2^n \quad \mbox{für alle $n \in \N$}
\end{equation}
mit der Anfangs-Bedingungen $a_0 = 0$.   Setzen wir in (\ref{eq:expdd}) für $n$ den Wert $n+1$
ein, erhalten wir 
\begin{equation}
  \label{eq:expdd2}
  a_{n+2} = a_{n+1} + 2^{n+1} \quad \mbox{für alle $n \in \N$}
\end{equation}
Würden wir von Gleichung (\ref{eq:expdd2}) die Gleichung (\ref{eq:expdd}) subtrahieren, so würde
der Term $2^n$ erhalten bleiben.  Um diesen Term zu eliminieren müssen wir statt dessen
von Gleichung (\ref{eq:expdd2}) 2 mal die Gleichung (\ref{eq:expdd})  subtrahieren: \\[0.1cm]
\hspace*{1.3cm}  
$a_{n+2} - 2 \cdot a_{n+1} = a_{n+1} + 2^{n+1} - 2 \cdot \bigl(a_n - 2^n\bigr)$ 
                 \\[0.1cm]
Dies vereinfacht sich zu der homogenen Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:expdd3}
  a_{n+2} = 3 \cdot a_{n+1} - 2 \cdot a_n \quad \mbox{für alle $n \in \N$}  
\end{equation}
Das charakteristische Polynom lautet \\[0.1cm]
\hspace*{1.3cm} 
$\chi(x) = x^2 - 3 \cdot x + 2 = (x-1) \cdot (x-2)$.  \\[0.1cm]
Damit lautet die allgemeine Lösung der homogenen Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} 
$a_n = \alpha + \beta \cdot 2^n$.  \\[0.1cm]
Da wir hier mit $\alpha$ und $\beta$ zwei Unbekannte haben, brauchen wir eine zusätzliche
Anfangs-Bedingung.  Diese erhalten wir, indem wir in der Gleichung (\ref{eq:expdd}) für $n$
den Wert $0$ einsetzen: \\[0.1cm]
\hspace*{1.3cm} $a_1 = a_0 + 2^0 = 0 + 1 = 1$. \\[0.1cm]
Damit erhalten wir das Gleichungs-System 
\[ 
\begin{array}{lcl}
0 &=& \alpha  + \beta  \\
1 &=& \alpha  + 2 \cdot \beta
\end{array} 
\]
Dieses Gleichungs-System hat die Lösung $\alpha = -1$ und $\beta = 1$.
Damit lautet die Lösung der Rekurrenz-Gleichung (\ref{eq:expdd}) mit der Anfangs-Bedingung
$a_0 = 0$ \\[0.1cm]
\hspace*{1.3cm} $a_n = 2^n - 1$.


\subsection{Die Substitutions-Methode}
Bei der Analyse von Algorithmen, die dem Paradigma \emph{Teile-und-Herrsche} folgen,
treten häufig Rekurrenz-Gleichungen auf, bei denen der Wert von $a_n$ von dem Wert von
$a_{n/2}$ oder gelegentlich auch $a_{n/3}$ oder sogar $a_{n/4}$ abhängt.  Wir zeigen jetzt
ein Verfahren, mit dessen Hilfe sich auch solche Rekurrenz-Gleichungen behandeln lassen.
Wir demonstrieren das Verfahren an Hand der Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:wrg}
a_n = a_{n/2} + n \quad \mbox{für alle $n \in \{ 2^k \mid k \in \N \wedge k \geq 1\}$}  
\end{equation}
mit der Anfangs-Bedingung $a_1 = 0$.   Um diese Rekurrenz-Gleichung zu lösen, machen wir
den Ansatz \\
\hspace*{1.3cm} $b_k = a_{2^k}$ \quad für alle $k \in \mathbb{N}$. \\[0.1cm]
 Setzen wir dies in die
ursprüngliche Rekurrenz-Gleichung (\ref{eq:wrg}) ein, so erhalten wir \\[0.1cm]
\hspace*{1.3cm} 
$b_{k} = a_{2^{k}} = a_{2^{k}/2} + 2^{k} = a_{2^{k-1}} + 2^{k} = b_{k-1}+ 2^{k}$.
\\[0.1cm]
Setzen wir in dieser Gleichung für $k$ den Wert $k+1$ ein, so sehen wir, dass
die Folge $(b_k)_k$ der Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:wrg2}
  b_{k+1} = b_k + 2^{k+1} \quad \mbox{für alle $k \in \N$}
\end{equation}
genügt.  Dabei ist die Anfangs-Bedingung $b_0 = a_{2^0} = a_1 = 0$.  Das ist eine lineare
inhomogene Rekurrenz-Gleichung mit der Inhomogenität $2^{k+1}$. Wir 
setzen in (\ref{eq:wrg2}) für $k$ den Wert $k+1$
ein und erhalten 
\begin{equation}
  \label{eq:wrg3}
  b_{k+2} = b_{k+1} + 2^{k+2} \quad \mbox{für alle $k \in \N$.}
\end{equation}
Wir multiplizieren nun die Rekurrenz-Gleichung (\ref{eq:wrg2}) mit 2 und ziehen das Ergebnis
von Gleichung  (\ref{eq:wrg3}) ab: \\[0.1cm]
\hspace*{1.3cm} 
$b_{k+2} - 2 \cdot b_{k+1} = b_{k+1} + 2^{k+2} - 2 \cdot b_k - 2 \cdot 2^{k+1}$ \quad für alle $k \in \N$. 
\\[0.1cm]
Nach Vereinfachung erhalten wir 
\begin{equation}
  \label{eq:wrg4}
  b_{k+2} = 3 \cdot b_{k+1} - 2 \cdot b_k \quad \mbox{für alle $k \in \N$.}
\end{equation}
Die Anfangs-Bedingung für $k=1$ berechnen wir aus (\ref{eq:wrg2}) \\[0.1cm]
\hspace*{1.3cm} $b_1 = b_0 + 2^{1} = 0 + 2 = 2$. \\[0.1cm]
Damit haben wir das ursprüngliche Problem auf eine homogene lineare Rekurrenz-Gleichung
mit konstanten Koeffizienten zurück geführt.  Das charakteristische Polynom dieser
Rekurrenz-Gleichung ist \\[0.1cm]
\hspace*{1.3cm} $\chi(x) = x^2 - 3\cdot x + 2 = (x-2)\cdot(x-1)$. \\[0.1cm]
Damit lautet die allgemeine Lösung der Rekurrenz-Gleichung (\ref{eq:wrg4}) \\[0.1cm]
\hspace*{1.3cm} $b_k = \alpha_1 \cdot 2^k + \alpha_2 \cdot 1^k$ \quad für alle $k \in \N$. \\[0.1cm]
Wir setzen die Anfangs-Bedingungen ein und erhalten so für die Koeffizienten $\alpha_1$
und $\alpha_2$ das lineare Gleichungs-System 
\[
\begin{array}{lcl}
  0 & = & \alpha_1 + \alpha_2 \\
  2 & = & 2 \cdot \alpha_1 + \alpha_2 \\
\end{array}
\]
Ziehen wir die erste Gleichung von der zweiten ab, so sehen wir $\alpha_1 = 2$.  Dann
folgt aus der ersten Gleichung $\alpha_2 = -2$.  Damit haben wir \\[0.1cm]
\hspace*{1.3cm} $b_k = 2^{k+1} - 2$ \quad für alle $k \in \N$. \\[0.1cm]
Setzen wir hier $b_k = a_{2^k}$ ein, so finden wir \\[0.1cm]
\hspace*{1.3cm} $a_{2^k} = 2^{k+1} - 2$ \quad für alle $k \in \N$. \\[0.1cm]
Mit $n = 2^k$ erhalten wir die Lösung der Rekurrenz-Gleichung (\ref{eq:wrg}) mit der wir 
gestartet waren: \\[0.1cm]
\hspace*{1.3cm} $a_n = 2 \cdot n - 2$ \quad für alle $n \in \{ 2^k \mid k \in \N\}$.  
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}:  Lösen Sie die Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $a_{n} = a_{n/2} + 1$ \quad für alle $n \in \{ 2^k \mid k \in \N \wedge k \geq 1\}$\\[0.1cm]
mit der Anfangs-Bedingungen $a_1 = 1$.
\vspace*{0.3cm}

%\noindent
%\textbf{Lösung}:
%\begin{enumerate}
%\item Rückführung auf $b_{k+1} =  b_k + 1$.
%\item $b_k = k$
%\item $a_n = \log_2(n)$
%\end{enumerate}

\subsection{Das Teleskop-Verfahren}
Bestimmte Rekurrenz-Gleichungen lassen sich auf bereits bekannte Summen zurückführen.  Wir demonstrieren
das Verfahren an der Rekurrenz-Gleichung \\[0.2cm]
\hspace*{1.3cm} $a_n = a_{n-1} + n - 1$ \quad mit $a_0 = 0$. 
\\[0.2cm]
Diese Gleichung tritt bei der Analyse der Komplexität von Quick-Sort auf.
Um diese Gleichung zu lösen, setzen wir zunächst für $a_{n-1}$ den Wert $a_{n-2} + (n-1) - 1$ ein, dann 
ersetzen wir $a_{n-2}$ durch $a_{n-3} + (n-2) -2$ und fahren so fort, bis wir schließlich $a_n$ auf $a_0$
zurück geführt haben.
Damit erhalten wir insgesamt:
\[
\begin{array}{lcl}
  a_n & = & a_{n-1} + (n-1) \\
      & = & a_{n-2} + (n-2) + (n-1) \\
      & = & a_{n-3} + (n-3) + (n-2) + (n-1) \\
      & = & \vdots \\
      & = & a_{0} + 0 + 1 + 2 + \cdots  + (n-2) + (n-1) \\
      & = & 0 + 0 + 1 + 2 + \cdots  + (n-2) + (n-1) \\
      & = & \sum\limits_{i=0}^{n-1} i  \\[0.4cm]
      & = &  \frac{1}{2} n \cdot(n - 1) \\[0.2cm]
      & = & \frac{1}{2} \cdot n^2 - \frac{1}{2} \cdot n.
\end{array}
\]
Das eben demonstrierte Verfahren wird in der Literatur als \emph{Teleskop-Verfahren} bezeichnet.  In der
allgemeinen Form des Teleskop-Verfahrens gehen wir von einer Rekurrenz-Gleichung der Form
\\[0.2cm]
\hspace*{1.3cm}
$a_n = a_{n-1} + g(n)$
\\[0.2cm]
aus.  Hierbei ist $g: \mathbb{N} \rightarrow \mathbb{R}$ eine reelwertige Funktion.
Wenden wir das oben demonstrierte Schema an, so erhalten wir die folgende Rechnung:
\[ 
\begin{array}{lcl}  
  a_n & = & a_{n-1} + g(n) \\
      & = & a_{n-2} + g(n-1) + g(n) \\
      & = & a_{n-3} + g(n-2) + g(n-1) + g(n) \\
      & = & \vdots \\
      & = & a_{0} + g(1) + g(2) + \cdots  + g(n-2) + g(n-1) + g(n) \\[0.2cm]
      & = & a_0 + \sum\limits_{i=1}^{n} g(i).
\end{array}
\]
Falls wir in der Lage sind, für die Summe $\sum_{i=1}^{n} g(i)$ einen geschlossenen Ausdruck anzugeben,
dann haben wir damit eine Lösung der Rekurrenz-Gleichung $a_n = a_{n-1} + g(n)$
gefunden.

\subsection{Berechnung von Summen}
Der letzte Abschnitt hat gezeigt, dass Rekurrenz-Gleichung in bestimmten Fällen auf Summen zurück geführt
werden können.  In diesem Abschnitt zeigen wir, dass auch der umgekehrte Weg möglich ist und die  
Berechnung einer Summe auf die Lösung einer Rekurrenz-Gleichung zurückgeführt werden kann. Wir
demonstrieren das Verfahren am Beispiel der Berechnung der geometrischen Reihe.  Hier wird die Summe
$s_n$ durch die Formel
\begin{equation}
  \label{eq:sum1}
  s_n = \sum\limits_{i=0}^n q^i   
\end{equation}
definiert, wobei wir zur Ersparung von Fallunterscheidungen voraussetzen wollen, dass $q \not= 1$ gilt.
Diese Einschränkung ist nicht gravierend denn für $q=1$ sehen wir sofort, dass $s_n = n+1$ gilt. Der
erste Schritt besteht darin, dass wir aus der obigen Definition eine Rekurrenz-Gleichung herleiten.
Dies erreichen wir dadurch, dass wir in Gleichung (\ref{eq:sum1}) für $n$ den Wert $n+1$ einsetzen.  Wir
erhalten dann die Gleichung
\begin{equation}
  \label{eq:sum2}
  s_{n+1} = \sum\limits_{i=0}^{n+1} q^i    
\end{equation}
Wir bilden nun die Differenz von $s_{n+1} - q * s_n$ und erhalten
\[ s_{n+1} - s_n \cdot q = 1, \]
was wir zu
\[ s_{n+1} = q \cdot s_n + 1 \]
umformen.  Dies ist eine lineare inhomogene Rekurrenz-Gleichung mit konstanter Inhomogenität. 
Die Anfangs-Bedingung ist hier offenbar $s_0 = 1$.  Das charakteristische Polynom lautet
\[ \chi(x) = x - q. \]
Diese Polynom hat die Nullstelle $x = q$.  Um die spezielle Lösung der Rekurrenz-Gleichung zu finden,
berechnen wir die Spur des charakteristischen Polynoms.  Es gilt
\[ \mathtt{sp}(\chi) = \chi(1) = 1 - q \not= 0, \]  
denn wir hatten ja $q \not= 1$ vorausgesetzt.  Damit lautet die spezielle Lösung
\[ s_n = \frac{c_{-1}}{\mathtt{sp}(\chi)} = \frac{1}{1 - q}. \]
Folglich lautet die allgemeine Lösung
\[ s_n = \alpha \cdot q^n + \frac{1}{1 - q}.  \]
Um den Koeffizienten $\alpha$ zu bestimmen, setzen wir $n=0$ und erhalten
\[ 1 = \alpha + \frac{1}{1 - q}. \]
Lösen wir diese Gleichung nach $\alpha$ auf, so ergibt sich
\[ \alpha = \frac{(1 - q) - 1}{1 - q} = - \frac{q}{1 - q}. \]
Damit lautet die Lösung
\[ s_n = \frac{1 - q^{n+1}}{1 - q} \]
und wir haben insgesamt die folgende Formel hergeleitet:
\[ \sum\limits_{i=0}^{n} q^i = \frac{1 - q^{n+1}}{1 - q}. \]
\pagebreak

\noindent
\textbf{Aufgabe}:
Berechnen Sie eine geschlossene Formel für die Summe
der Quadratzahlen
\[ s_n := \sum\limits_{i=0}^{n} i^2. \]
Stellen Sie dazu eine Rekurrenz-Gleichung für $s_n$ auf und lösen Sie diese.

\subsection{Weitere Rekurrenz-Gleichungen}
Die Lösung allgemeiner Rekurrenz-Gleichungen kann beliebig schwierig sein und
es gibt viele Fälle, in denen eine gegebene Rekurrenz-Gleichungen überhaupt keine Lösung
hat, die sich durch elementare Funktionen als geschlossene Formel ausdrücken lässt.
Wir wollen an Hand einer etwas komplizierteren Rekurrenz-Gleichung, die uns später bei der Behandlung der
durchschnittlichen Komplexität des Quick-Sort-Algorithmus wiederbegegnen wird, zeigen, dass im Allgemeinen bei
der Lösung einer Rekurrenz-Gleichung Kreativität gefragt ist.
Wir gehen dazu von der folgenden  Rekurrenz-Gleichung aus:
\begin{equation}
  \label{eq:cqs2}
  d_{n+1} = n + \frac{2}{n+1} \cdot \sum_{i=0}^n d_i.   
\end{equation}
Zunächst versuchen wir, die Summe $\sum_{i=0}^n d_i$, die auf der rechten Seite dieser Rekurrenz-Gleichung
auftritt, zu eliminieren.  Wir versuchen, analog zu dem Verfahren des diskreten Differenzierens vorzugehen
und substituieren zunächst $n \mapsto n+1$.  Wir erhalten 
\begin{equation}
  \label{eq:cqs3}
   d_{n+2} = n+1 + \frac{2}{n+2} \cdot \sum_{i=0}^{n+1} d_i.  
\end{equation}
Wir multiplizieren nun Gleichung (\ref{eq:cqs3}) mit $n+2$ und Gleichung (\ref{eq:cqs2}) mit $n+1$ und
haben dann
\begin{eqnarray}
  \label{eq:cqs4}
 (n+2)\cdot d_{n+2} & = & (n+2)\cdot(n+1) + 2 \cdot \sum_{i=0}^{n+1} d_i \qquad \mbox{und} \\
  \label{eq:cqs5}
 (n+1)\cdot d_{n+1} & = & (n+1)\cdot n + 2 \cdot \sum_{i=0}^n d_i.  
\end{eqnarray}
Wir bilden die Differenz der Gleichungen (\ref{eq:cqs4}) und (\ref{eq:cqs5}) und beachten,
dass sich die Summationen bis auf den Term $2\cdot d_{n+1}$ gerade gegenseitig aufheben.
Das liefert
\begin{equation}
  \label{eq:cqs6}
 (n+2)\cdot d_{n+2} - (n+1)\cdot \displaystyle d_{n+1} = (n+2)\cdot(n+1) - (n+1)\cdot n+2 \cdot d_{n+1}.
\end{equation}
Diese Gleichung vereinfachen wir zu
\begin{equation}
  \label{eq:cqs7}
(n+2)\cdot d_{n+2} = (n+3)\cdot \displaystyle d_{n+1} + 2\cdot(n+1).  
\end{equation}
Um diese Gleichung zu homogenisieren teilen wir beide Seiten durch $(n+2) \cdot(n+3)$:
\begin{equation}
  \label{eq:cqs8}
 \frac{1}{n+3} \cdot d_{n+2} = \frac{1}{n+2}\cdot d_{n+1} + \frac{2\cdot(n+1)}{(n+2)\cdot(n+3)}.
\end{equation}
Wir definieren $\displaystyle a_n = \frac{d_n}{n+1}$ und erhalten dann aus der
letzten Gleichung 
\[ a_{n+2} = a_{n+1} + \frac{2\cdot(n+1)}{(n+2)\cdot(n+3)} \]
Die Substitution $n \mapsto n-2$ vereinfacht diese Gleichung zu 
\begin{equation}
  \label{eq:cqs9}
 a_{n} = a_{n-1} + \frac{2\cdot(n-1)}{n\cdot(n+1)}.
\end{equation}
Diese Gleichung können wir mit dem Teleskop-Verfahren lösen.  Um die dabei auftretenden Summen übersichlicher
schreiben zu können,  bilden wir die Partialbruch-Zerlegung von 
\[ \frac{2\cdot(n-1)}{n\cdot(n+1)}. \] 
Dazu machen wir den Ansatz
\[ \frac{2\cdot(n-1)}{n\cdot(n+1)} = \frac{\alpha}{n} + \frac{\beta}{n+1}.\]
Wir multiplizieren diese Gleichung mit dem Hauptnenner und erhalten
\[ 2\cdot n - 2 = \alpha \cdot (n+1) + \beta \cdot n, \]
was sich zu 
\[ 2\cdot n - 2 = (\alpha + \beta) \cdot n + \alpha \]
vereinfacht.  Ein Koeffizientenvergleich liefert dann das lineare Gleichungs-System
\begin{eqnarray*}
  2 & = & \alpha + \beta, \\
 -2 & = & \alpha.
\end{eqnarray*}
Setzen wir die zweite Gleichung in die erste Gleichung ein, so erhalten wir $\beta = 4$.
Damit können wir die Gleichung (\ref{eq:cqs9}) als 
\begin{equation}
  \label{eq:cqs10}
 a_{n} = a_{n-1} - \frac{2}{n} + \frac{4}{n+1}  
\end{equation}
schreiben und mit  dem Teleskop-Verfahren lösen.  Wegen $a_0 = \frac{d_0}{1} = 0$ finden wir
\begin{equation}
  \label{eq:cqs11}
 a_{n} = 4 \cdot \sum_{i=1}^n \frac{1}{i+1} - 2 \cdot \sum_{i=1}^n \frac{1}{i}.  
\end{equation}
Wir vereinfachen diese Summe:
\[
\begin{array}{lcl}
 a_{n} & = & \displaystyle 4 \cdot \sum_{i=1}^n \frac{1}{i+1} - 2 \cdot \sum_{i=1}^n \frac{1}{i} \\[0.5cm]
       & = & \displaystyle 4 \cdot \sum_{i=2}^{n+1} \frac{1}{i} - 2 \cdot \sum_{i=1}^n \frac{1}{i} \\[0.5cm]
       & = & \displaystyle 4 \cdot \frac{1}{n+1} - 4 \cdot \frac{1}{1} + 4 \cdot \sum_{i=1}^{n} \frac{1}{i} - 2 \cdot \sum_{i=1}^n \frac{1}{i} \\[0.5cm]
       & = & \displaystyle 4 \cdot \frac{1}{n+1} - 4 \cdot \frac{1}{1} + 2 \cdot \sum_{i=1}^{n} \frac{1}{i}  \\[0.5cm]
       & = & \displaystyle - \frac{4 \cdot n}{n+1}  + 2 \cdot \sum_{i=1}^{n} \frac{1}{i}  
\end{array}
\]
Um unsere Rechnung abzuschließen, berechnen wir eine Näherung für die Summe 
\[ H_n = \sum\limits_{i=1}^{n}\frac{1}{i}.\]
Der Wert $H_n$ wird in der Mathematik als die $n$-te \emph{harmonische Zahl} bezeichnet.
Dieser Wert hängt mit dem Wert $\ln(n)$ zusammen: Leonhard Euler hat gezeigt, dass für
große $n$ die Approximation
\[ \sum\limits_{i=1}^n \frac{1}{i} \approx \ln(n) + \gamma + \frac{1}{2} \cdot \frac{1}{n} \]
benutzt werden kann.  Hier ist $\gamma$ die Euler-Mascheroni'sche Konstante, deren Wert durch
\[ \gamma \approx 0,5772156649 \]
gegeben ist.  Damit haben wir für den Wert von $a_n$ die Näherung
\[ a_n = - \frac{4 \cdot n}{n+1} + 2 \cdot H_n \approx  
         2 \cdot \ln(n) + 2 \cdot \gamma - \frac{4 \cdot n}{n+1} + \frac{1}{n} 
\]
gefunden. Wegen $d_n = (n+1) \cdot a_n$ können wir für die Folge $d_n$ also folgendes schreiben:
\[ d_n \approx  
       2 \cdot (n + 1) \cdot \ln(n) + 2 \cdot (n+1) \cdot \gamma - 4 \cdot n + \frac{n+1}{n}.
\]
\vspace*{0.3cm}


Wir verallgemeinern die Idee, die wir bei der Lösung des obigen Beispiels benutzt haben.  Es seien
$f:\mathbb{N} \rightarrow \mathbb{R}$, $g:\mathbb{N} \rightarrow \mathbb{R}$ und 
$h:\mathbb{N} \rightarrow \mathbb{R}$ 
reelwertige Folgen und es sei die Rekurrenz-Gleichung
\[ 
f(n) \cdot a_n = g(n) \cdot a_{n-1} + h(n)
\]
zu lösen.  Die Idee ist, beide Seiten mit einem geeigneten Faktor, der im Allgemeinen von $n$ abhängt, zu
multiplizieren.  Bezeichnen wir diesen Faktor mit $p(n)$, so erhalten wir die Rekurrenz-Gleichung
\[ 
p(n) \cdot f(n) \cdot a_n = p(n) \cdot g(n) \cdot a_{n-1} + p(n) \cdot h(n).
\]
Das Ziel ist dabei, den Faktor $p(n)$ so zu wählen, dass der Koeffizient von $a_n$ die selbe Form hat wie der
Koeffizient von $a_{n-1}$, es soll also
\begin{equation}
  \label{eq:chomogen}
  p(n) \cdot g(n) = p(n-1) \cdot f(n-1)  
\end{equation}
gelten, denn dann können wir die ursprüngliche Rekurrenz-Gleichung in der Form
\[ 
p(n) \cdot f(n) \cdot a_n = p(n-1) \cdot f(n-1) \cdot a_{n-1} + p(n) \cdot h(n).
\]
schreiben und anschließend durch die Substitution $b_n := p(n) \cdot f(n) \cdot a_n$ auf die
Rekurrenz-Gleichung 
\[ 
b_n = b_{n-1} + p(n) \cdot h(n).
\]
Diese Gleichung lässt sich mit dem Teleskop-Verfahren auf eine Summe zurückführen und die Lösung der
ursprünglichen Gleichung kann schließlich über die Formel
\[ 
a_n = \frac{1}{p(n) \cdot f(n)} \cdot b_n
\]
aus $b_n$ berechnet werden.  Es bleibt also zu klären, wie wir den Faktor $p(n)$ so wählen können, dass
Gleichung (\ref{eq:chomogen}) erfüllt ist. Dazu schreiben wir diese Gleichung als Rekurrenz-Gleichung für
$p(n)$ um und erhalten
\[ 
  p(n) = \frac{f(n-1)}{g(n)} \cdot p(n-1) 
\]
Diese Gleichung können wir mit einer Variante des Teleskop-Verfahrens lösen:
\[ 
\begin{array}{lcl}
p(n) & = & \frac{f(n-1)}{g(n)} \cdot p(n-1)   \\[0.2cm]
     & = & \frac{f(n-1)}{g(n)} \cdot  \frac{f(n-2)}{g(n-1)} \cdot  p(n-2) \\[0.2cm]
     & = & \frac{f(n-1)}{g(n)} \cdot  \frac{f(n-2)}{g(n-1)} \cdot \frac{f(n-3)}{g(n-2)} \cdot  p(n-3) 
           \\[0.2cm]
     & = & \frac{f(n-1)}{g(n)} \cdot  \frac{f(n-2)}{g(n-1)} \cdot \frac{f(n-3)}{g(n-2)} \cdot  p(n-3) 
           \\[0.2cm]
     & \vdots & \\
     & = & \frac{f(n-1)}{g(n)} \cdot  \frac{f(n-2)}{g(n-1)} \cdot \frac{f(n-3)}{g(n-2)} \cdot \cdots
           \cdot \frac{f(2)}{g(3)} \cdot \frac{f(1)}{g(2)} \cdot p(1) 
           \\[0.2cm]
\end{array}
\]
Wir setzen willkürlich $p(1) = 1$ und haben dann für $p(n)$ die Lösung
\[ p(n) = \prod\limits_{i=1}^{n-1} \frac{f(i)}{g(i+1)} \]
gefunden.  Bei der Rekurrenz-Gleichung
\[
n\cdot d_{n} = (n+1)\cdot \displaystyle d_{n-1} + 2\cdot(n-1),
\]
die aus der Rekurrenz-Gleichung (\ref{eq:cqs7}) durch die Substitution $n \mapsto n-2$ hervorgeht,
gilt $f(n) = n$ und  $g(n) = n+1$.
Damit haben wir dann
\[
\begin{array}{lcl}
 p(n) & = & \prod\limits_{i=1}^{n-1} \frac{f(i)}{g(i+1)} \\[0.4cm]
      & = & \prod\limits_{i=1}^{n-1} \frac{i}{i+2}       \\[0.4cm]
      & = & \frac{1}{3} \cdot \frac{2}{4} \cdot\frac{3}{5} \cdot \cdots \cdot
            \frac{n-3}{n-1} \cdot \frac{n-2}{n} \cdot \frac{n-1}{n+1}            \\[0.4cm]
      & = & 2 \cdot \frac{1}{n} \cdot \frac{1}{n+1}.
\end{array}
\]
Die Konstante $2$ ist hier unwichtig und wir sehen, dass der Faktor $\frac{1}{n \cdot (n+1)}$ benutzt werden
kann, um die ursprüngliche Rekurrenz-Gleichung zu homogenisieren.

\exercise
Lösen Sie die Rekurrenz-Gleichung
\[ a_n = 2 \cdot a_{n-1} + 1 \quad \mbox{mit $a_0 = 0$} \]
mit Hilfe einer geeigneten Homogenisierung.  Gehen Sie dabei analog zu dem im letzten Abschnitt beschriebenen
Verfahren vor.
\pagebreak


\section{Die $\Oh$-Notation}
Wollen wir die Komplexität eines Algorithmus abschätzen, so wäre ein mögliches Vorgehen
wie folgt: Wir kodieren den Algorithmus in einer Programmiersprache und berechnen,
wieviele Additionen, Multiplikationen, Zuweisungungen, und andere elementare Operationen
bei einer gegebenen Eingabe von dem Programm ausgeführt werden. Anschließend schlagen wir
im Prozessor-Handbuch nach, wieviel Zeit die einzelnen Operationen in Anspruch nehmen und
errechnen daraus die Gesamtlaufzeit des Programms.\footnote{
Da die heute verfügbaren Prozessoren fast alle mit \emph{Pipelining} arbeiten, werden oft
mehrere Befehle gleichzeitig abgearbeitet. Da gleichzeitig auch das Verhalten des Caches
eine wichtige Rolle spielt, ist die genaue Berechnung der Rechenzeit faktisch unmöglich.}
Dieses Vorgehen ist aber in zweifacher Hinsicht problematisch:
\begin{enumerate}
\item Das Verfahren ist sehr kompliziert.
\item Würden wir den selben Algorithmus anschließend in einer anderen Programmier-Sprache
      kodieren, oder aber das Programm auf einem anderen Rechner laufen lassen, so wäre
      unsere Rechnung wertlos und wir müssten sie wiederholen.
\end{enumerate}
Der letzte Punkt zeigt, dass das Verfahren dem Begriff des Algorithmus, der ja eine
Abstraktion des Programm-Begriffs ist, nicht gerecht wird.  Ähnlich wie der Begriff des
Algorithmus von bestimmten Details einer Implementierung abstrahiert brauchen wir zur
Erfassung der rechenzeitlichen Komplexität eines Algorithmus einen Begriff, der von
bestimmten Details der Funktion, die die Rechenzeit für ein gegebenes Programm berechnet,
abstrahiert.  Wir haben drei Forderungen an den zu findenden  Begriff.
\begin{itemize}
\item Der Begriff soll von konstanten Faktoren abstrahieren.
\item Der Begriff soll von \emph{unwesentlichen Termen} abstrahieren.

      Nehmen wir an, wir hätten ein Programm, dass zwei $n \times n$ Matrizen
      multipliziert und wir hätten für die Rechenzeit $T(n)$ dieses Programms in Abhängigkeit von
      $n$ die Funktion \\[0.1cm]
      \hspace*{1.3cm} $T(n) = 3 \cdot n^3 + 2 \cdot n^2 + 7$ \\[0.1cm]
      gefunden.  Dann nimmt der \emph{proportionale Anteil} des Terms $2\cdot n^2 + 7$ an der
      gesamten Rechenzeit mit wachsendem $n$ immer mehr ab.  Zur Verdeutlichung haben wir
      in einer Tabelle die Werte des proportionalen Anteils für 
      $n = 1,\; 10,\; 100,\; 1000,\, 10\,000$ aufgelistet: \\[0.3cm]
      \hspace*{1.3cm} 
      \begin{tabular}{|r|r|}
        \hline
        $n$  & \rule{0pt}{16pt} $\bruch{2 \cdot n^2 + 7}{3 \cdot n^3 + 2 \cdot n^2 + 7}$ \\[0.3cm]
        \hline
        \hline
        1       &  0.75000000000000  \\
        10      &  0.06454630495800  \\
        100     &  0.00662481908150  \\
        1000    &  0.00066622484855  \\
        10\,000 &  6.6662224852\,e\,-05  \\
       \hline
      \end{tabular}
\item Der Begriff soll das \emph{Wachstum} der Rechenzeit abhängig von \emph{Wachstum} der
      Eingaben erfassen. Welchen genauen Wert die Rechenzeit für kleine Werte der Eingaben
      hat, spielt nur eine untergeordnete Rolle, denn für kleine Werte der Eingaben 
      wird auch die Rechenzeit nur klein sein.
\end{itemize}
Wir bezeichnen die Menge der positiven reellen Zahlen mit $\R_+$ \\[0.1cm]
\hspace*{1.3cm} $\R_+ := \{ x \in \R \mid x > 0 \}$. \\[0.1cm]
Wir bezeichnen die Menge aller Funktionen von $\N$ nach
 $\R_+$ mit $\R_+^{\;\N}$, es gilt also: \\[0.1cm]
\hspace*{1.3cm} 
$\R_+^{\;\N} = \bigl\{ f \mid \mbox{$f$ ist Funktion der Form $f: \N \rightarrow \R_+$} \}$.

\begin{Definition}[$\Oh(f)$] {\em
  Es sei eine Funktion $f\in \R_+^\N$ 
  gegeben.   Dann definieren wir die Menge der Funktionen, die asymptotisch
  das gleiche Wachstumsverhalten haben wie die Funktion $f$, wie folgt:
  \\[0.1cm]
  \hspace*{1.3cm} 
  $ \Oh(f) \;:=\; \left\{ g \in \R_+^{\;\N} \mid \exists k \in \N \colon 
    \bigl(\exists c \in \R_+\colon \forall n \in \N \colon n \geq k \rightarrow g(n) \leq c \cdot f(n)\bigr) \right\}$.
  \hspace*{\fill} $\Box$
}
\end{Definition}
Was sagt die obige Definition aus? Zunächst kommt es auf kleine Werte des Arguments $n$
nicht an, denn die obige Formel sagt ja, dass $g(n) \leq c \cdot f(n)$ nur für die $n$ gelten
muss, für die  $n \geq k$ ist.  Außerdem kommt es auf Proportionalitäts-Konstanten nicht
an, denn $g(n)$ muss ja nur kleinergleich $c \cdot f(n)$ sein und die Konstante $c$ können wir
beliebig wählen.  Um den Begriff zu verdeutlichen, geben wir einige Beispiele.
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}: Es gilt \\[0.1cm]
\hspace*{1.3cm} $3 \cdot n^3 + 2 \cdot n^2 + 7 \in \Oh(n^3)$. \\[0.1cm]
\textbf{Beweis}: Wir müssen eine Konstante $c$ und eine Konstante $k$ angeben, so dass für
alle $n\in \N$ mit $n \geq k$ die Ungleichung
\\[0.1cm]
\hspace*{1.3cm} 
$3 \cdot n^3 + 2 \cdot n^2 + 7 \leq c \cdot n^3$
\\[0.1cm]
gilt.  Wir setzen  $k := 1$ und $c := 12$. Dann können wir die Ungleichung 
\begin{equation}
  \label{eq:u1}
  1\leq n  
\end{equation}
voraussetzen und müssen zeigen, dass daraus 
\begin{equation}
  \label{eq:u2}
  3 \cdot n^3 + 2 \cdot n^2 + 7 \leq 12 \cdot n^3  
\end{equation}
folgt. Erheben wir beide Seiten der  Ungleichung (\ref{eq:u1}) in die dritte Potenz, so sehen wir,
dass 
\begin{equation}
  \label{eq:u3pre}
  1 \leq n^3  
\end{equation}
gilt.  Diese Ungleichung multiplizieren wir auf beiden Seiten mit $7$ und erhalten: 
\begin{equation}
  \label{eq:u3}
  7 \leq 7 \cdot n^3
\end{equation}
Multiplizieren wir die Ungleichung (\ref{eq:u1}) mit $2\cdot n^2$, so erhalten wir 
\begin{equation}
  \label{eq:u4}
  2 \cdot n^2 \leq 2 \cdot n^3  
\end{equation}
Schließlich gilt trivialerweise 
\begin{equation}
  \label{eq:u5}
  3 \cdot n^3 \leq 3 \cdot n^3
\end{equation}
Die Addition der Ungleichungen (\ref{eq:u3}), (\ref{eq:u4}) und (\ref{eq:u5}) liefert nun \\[0.1cm]
\hspace*{1.3cm} $3 \cdot n^3 + 2 \cdot n^2 + 7 \leq 12 \cdot n^3$ \\[0.1cm]
und das war zu zeigen. \hspace*{\fill} $\Box$
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}: Es gilt  $n \in \Oh(2^n)$. 
\vspace*{0.3cm}

\noindent
\textbf{Beweis}: Wir müssen eine Konstante $c$ und eine Konstante $k$ angeben, so dass für
alle $n \geq k$
\\[0.1cm]
\hspace*{1.3cm} $ n \leq c \cdot 2^n$ \\[0.1cm]
gilt.  Wir setzen $k := 0$ und $c := 1$.  Wir zeigen \\[0.1cm]
\hspace*{1.3cm} $n \leq 2^n$ \quad für alle $n \in \N$ \\[0.1cm]
durch vollständige Induktion über $n$.
\begin{enumerate}
\item \textbf{I.A.}: $n = 0$

      Es gilt $0 \leq 1 = 2^0$.
\item \textbf{I.S.}: $n \mapsto n + 1$

      Einerseits gilt nach Induktions-Voraussetzung \\[0.1cm]
      \hspace*{1.3cm} $n \leq 2^n$, \hspace*{\fill} $(1)$ \\[0.1cm]
      andererseits haben wir \\[0.1cm]
      \hspace*{1.3cm} $1 \leq 2^n$. \hspace*{\fill} $(2)$ \\[0.1cm]
      Addieren wir $(1)$ und $(2)$, so erhalten wir \\[0.1cm]
      \hspace*{1.3cm} $n+1 \leq 2^n + 2^n = 2^{n+1}$. \hspace*{\fill} $\Box$

      \textbf{Bemerkung}: Die Ungleichung $1 \leq 2^n$ hätten wir eigentlich ebenfalls
      durch Induktion  nachweisen müssen.
\end{enumerate}

\noindent
\textbf{Aufgabe}: Zeigen Sie \\[0.1cm]
\hspace*{1.3cm} $n^2 \in \Oh(2^n)$.
\vspace*{0.3cm}

\noindent
Wir zeigen nun einige Eigenschaften der $\Oh$-Notation.

\begin{Satz}[Reflexivität]
{\em
  Für alle Funktionen $f\colon \N \rightarrow {\R_+}$ gilt \\[0.1cm]
  \hspace*{1.3cm} $f \in \Oh(f)$. 
}
\end{Satz}
\textbf{Beweis}: Wählen wir $k:=0$ und $c:=1$, so folgt die Behauptung sofort aus der
Ungleichung \\[0.1cm]
\hspace*{1.3cm} $\forall n \in \N\colon f(n) \leq f(n)$. \hspace*{\fill} $\Box$

\begin{Satz}[Abgeschlossenheit unter Multiplikation mit Konstanten] \hspace*{\fill} \\
{\em
  Es seien  $f,g\colon \N \rightarrow {\R_+}$
   und $d \in \R_+$.  Dann gilt \\[0.1cm]
  \hspace*{1.3cm} $g \in \Oh(f) \Rightarrow d \cdot g \in \Oh(f)$.
}
\end{Satz}
\textbf{Beweis}: Aus $g \in \Oh(f)$ folgt, dass es Konstanten $c'\in \R_+$, $k'\in \N$ gibt,
so dass \\[0.1cm]
\hspace*{1.3cm} 
$\forall n \in \N \colon \bigl(n \geq k'  \rightarrow g(n) \leq c' \cdot f(n)\bigr)$ \\[0.1cm]
gilt.  Multiplizieren wir die Ungleichung mit $d$, so haben wir \\[0.1cm]
\hspace*{1.3cm} 
$\forall n \in \N \colon\bigl( n \geq k'  \rightarrow d \cdot g(n) \leq d \cdot c' \cdot f(n)\bigr)$ \\[0.1cm]
Setzen wir nun $k:=k'$ und $c := d \cdot c'$, so folgt \\[0.1cm]
\hspace*{1.3cm} $\forall n \in \N \colon \bigl(n \geq k  \rightarrow d \cdot g(n) \leq c \cdot f(n)\bigr)$ 
\\[0.1cm]
und daraus folgt $d \cdot g \in \Oh(f)$. \hspace*{\fill} $\Box$.

\begin{Satz}[Abgeschlossenheit unter Addition]
{\em
  Es seien $f,g,h \colon \N \rightarrow {\R_+}$.  Dann gilt \\[0.1cm]
  \hspace*{1.3cm} $f \in \Oh(h) \wedge g \in \Oh(h) \,\rightarrow\, f + g \in \Oh(h)$.
}
\end{Satz}
\textbf{Beweis}: Aus den Voraussetzungen $f \in \Oh(h)$ und $g \in \Oh(h)$ folgt, dass es
Konstanten $k_1,k_2\in \N$ und $c_1,c_2\in \R$ gibt, so dass \\[0.1cm]
\hspace*{1.3cm} 
$\forall n \in \N \colon \bigl( n \geq k_1 \rightarrow f(n) \leq c_1 \cdot h(n)\bigr)$ 
\quad und\\[0.1cm]
\hspace*{1.3cm} 
$\forall n \in \N \colon\bigl( n \geq k_2 \rightarrow g(n) \leq c_2 \cdot h(n)\bigr)$
\\[0.1cm]
gilt.  Wir setzen $k := \max(k_1,k_2)$ und $c:= c_1 + c_2$.  Für $n \geq k$ gilt dann \\[0.1cm]
\hspace*{1.3cm} $f(n) \leq c_1 \cdot h(n)$ und $g(n) \leq c_2 \cdot h(n)$. \\[0.1cm]
Addieren wir diese beiden Gleichungen, dann haben wir für alle $n \geq k$ \\[0.1cm]
\hspace*{1.3cm} $f(n) + g(n) \leq (c_1 + c_2) \cdot h(n) = c \cdot h(n)$. \hspace*{\fill} $\Box$

\begin{Satz}[Transitivität]
{\em
  Es seien $f,g,h \colon \N \rightarrow {\R_+}$.  Dann gilt \\[0.1cm]
  \hspace*{1.3cm} $f \in \Oh(g) \wedge g \in \Oh(h) \,\rightarrow\, f \in \Oh(h)$.
}
\end{Satz}
\textbf{Beweis}: Aus $f \in \Oh(g)$ folgt, dass es $k_1 \in \N$ und $c_1 \in \R$ gibt, so dass\\[0.1cm]
\hspace*{1.3cm} 
$\forall n \in \N \colon\bigl( n \geq k_1 \rightarrow f(n) \leq c_1 \cdot g(n)\bigr)$ \\[0.1cm]
gilt und aus $g \in \Oh(h)$ folgt, dass es $k_2 \in \N$ und $c_2 \in \R$ gibt, so dass \\[0.1cm]
\hspace*{1.3cm} 
$\forall n \in \N \colon\bigl( n \geq k_2 \rightarrow g(n) \leq c_2 \cdot h(n)\bigr)$ \\[0.1cm]
gilt.  Wir definieren $k:= \max(k_1,k_2)$ und $c := c_1 \cdot c_2$.  Dann haben wir für alle
$n \geq k$:\\[0.1cm]
\hspace*{1.3cm} $f(n) \leq c_1\cdot g(n)$ und $g(n) \leq c_2 \cdot h(n)$. \\[0.1cm]
Die zweite dieser Ungleichungen multiplizieren wir mit $c_1$ und erhalten \\[0.1cm]
\hspace*{1.3cm} $f(n) \leq c_1\cdot g(n)$ und $c_1\cdot g(n) \leq c_1\cdot c_2 \cdot h(n)$. \\[0.1cm]
Daraus folgt aber sofort $f(n) \leq c \cdot h(n)$. \hspace*{\fill} $\Box$

\begin{Satz}[Grenzwert-Satz] \label{limit}
{\em
  Es seien $f,g \colon \N \rightarrow {\R_+}$.  Außerdem existiere der Grenzwert \\[0.1cm]
  \hspace*{1.3cm} $\lim\limits_{n \rightarrow \infty} \bruch{\,f(n)\,}{g(n)}$.  \\[0.1cm]
  Dann gilt $f \in \Oh(g)$. 
}
\end{Satz}
\textbf{Beweis}: Es sei \\[0.1cm]
\hspace*{1.3cm} $\lambda := \lim\limits_{n \rightarrow \infty} \bruch{f(n)}{g(n)}$.  \\[0.1cm]
Nach Definition des Grenzwertes gibt es dann eine Zahl $k \in \N$, so dass 
für alle $n\in \N$ mit $n \geq k$ die Ungleichung \\[0.1cm]
\hspace*{1.3cm} $\left| \bruch{f(n)}{g(n)} - \lambda \right| \leq 1$ \\[0.1cm]
gilt.  Multiplizieren wir diese Ungleichung mit $g(n)$, so erhalten wir \\[0.1cm]
\hspace*{1.3cm} $|f(n) - \lambda \cdot g(n)| \leq g(n)$. \\[0.1cm]
Daraus folgt wegen \\[0.1cm]
\hspace*{1.3cm} $f(n) \leq \bigl|f(n) - \lambda \cdot g(n)\bigr| + \lambda \cdot g(n)$ \\[0.1cm]
die Ungleichung \\[0.1cm]
\hspace*{1.3cm} $f(n) \leq g(n) + \lambda \cdot g(n) = (1 + \lambda) \cdot g(n)$. \\[0.1cm]
Definieren wir  $c := 1 +  \lambda$, 
so folgt für alle $n \geq k$ die Ungleichung $f(n) \leq c \cdot g(n)$. \hspace*{\fill} $\Box$
\vspace*{0.3cm}

\noindent
Wir zeigen die Nützlichkeit der obigen Sätze an Hand einiger Beispiele.
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}: Es sei $k \in \N$.  Dann gilt\\[0.1cm]
\hspace*{1.3cm} $n^k \in \Oh(n^{k+1})$.
\vspace*{0.3cm}

\noindent
\textbf{Beweis}: Es gilt \\[0.1cm]
\hspace*{1.3cm} 
$\lim\limits_{n \rightarrow \infty} \bruch{n^{k}}{n^{k+1}} = \lim\limits_{n \rightarrow   \infty} \bruch{1}{n} = 0$.
\\[0.1cm]
Die Behauptung folgt nun aus dem Grenzwert-Satz. \hspace*{\fill} $\Box$
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}: Es sei $k \in \N$ und $\lambda \in \R$ mit $\lambda > 1$.  Dann gilt\\[0.1cm]
\hspace*{1.3cm} $n^k \in \Oh(\lambda^n)$.
\vspace*{0.3cm}

\noindent
\textbf{Beweis}: Wir zeigen, dass 
\hspace*{1.3cm} 
\begin{equation}
  \label{eq:star}
  \lim\limits_{n \rightarrow \infty} \bruch{n^{k}}{\lambda^n} = 0  
\end{equation}
ist, denn dann folgt die Behauptung aus dem Grenzwert-Satz. 
Nach dem Satz von L'Hospital können wir den Grenzwert wie folgt berechnen \\[0.1cm]
\hspace*{1.3cm} 
$\displaystyle \lim\limits_{n \rightarrow \infty} \bruch{n^{k}}{\lambda^n} =
\lim\limits_{x \rightarrow \infty} \bruch{x^{k}}{\lambda^x} =
\lim\limits_{x \rightarrow \infty} \bruch{\;\frac{d\,x^{k}}{dx}\;}{\frac{d\,\lambda^x}{dx}}$
\\[0.1cm]
Die Ableitungen  können wir berechnen, es gilt: \\[0.1cm]
\hspace*{1.3cm}
 $\displaystyle \frac{d\,x^{k}}{dx} = k \cdot x^{k-1}$ \quad und \quad 
 $\displaystyle \frac{d\,\lambda^{x}}{dx} = \ln(\lambda) \cdot \lambda^x$. \\[0.1cm]
Berechnen wir die zweite Ableitung so sehen wir \\[0.1cm]
\hspace*{1.3cm}  
$\displaystyle \frac{d^{2}\,x^{k}}{dx^2} = k \cdot (k-1) \cdot x^{k-2}$ \quad und \quad 
 $\displaystyle \frac{d^2\,\lambda^{x}}{dx^2} = \ln(\lambda)^2 \cdot \lambda^x$. \\[0.1cm]
Für die $k$-te Ableitung gilt analog \\[0.1cm]
\hspace*{1.3cm} 
$\displaystyle \frac{d^{k}\,x^{k}}{dx^k} = k \cdot (k-1) \cdot \cdots \cdot 1 \cdot x^{0} = k!$ \quad und \quad 
 $\displaystyle \frac{d^k\,\lambda^{x}}{dx^k} = \ln(\lambda)^k \cdot \lambda^x$. \\[0.1cm]
Wenden wir also den Satz von L'Hospital zur Berechnung des Grenzwertes  $k$ mal an, so
sehen wir \\[0.1cm]
\hspace*{1.3cm} 
$\displaystyle 
\lim\limits_{x \rightarrow \infty} \bruch{x^{k}}{\lambda^x} =
\lim\limits_{x \rightarrow \infty} \bruch{\rule[-10pt]{0pt}{10pt}\;\frac{d\,x^{k}}{dx}\;}{\rule{0pt}{12pt}\frac{d\,\lambda^x}{dx}} =
\lim\limits_{x \rightarrow \infty} \bruch{\rule[-10pt]{0pt}{10pt}\;\frac{d^2\,x^{k}}{dx^2}\;}{\rule{0pt}{12pt}\frac{d^2\,\lambda^x}{dx^2}} =
\cdots = 
\lim\limits_{x \rightarrow \infty} \bruch{\rule[-10pt]{0pt}{10pt}\;\frac{d^k\,x^{k}}{dx^k}\;}{\rule{0pt}{12pt}\frac{d^k\,\lambda^x}{dx^k}} =
\lim\limits_{x \rightarrow \infty} \bruch{k!}{\ln(\lambda)^k \lambda^x} = 0$.

\hspace*{\fill} $\Box$
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}: Es gilt $\ln(n) \in \Oh(n)$.
\vspace*{0.3cm}

\noindent
\textbf{Beweis}: Wir benutzen Satz \ref{limit} und zeigen mit der Regel von L'Hospital,
dass \\[0.1cm]
\hspace*{1.3cm} 
$\lim\limits_{n \rightarrow \infty} \bruch{\;\ln(n)\;}{n} = 0$
\\[0.1cm]
ist.  Es gilt \\[0.1cm]
\hspace*{1.3cm} $\displaystyle \frac{d\, \ln(x)}{dx} = \frac{1}{x}$ 
\quad und \quad
 $\displaystyle \frac{d\, x}{dx} = 1$. \\[0.1cm]
Also haben wir \\[0.1cm]
\hspace*{1.3cm} 
$\displaystyle \lim\limits_{n \rightarrow \infty} \bruch{\;\ln(n)\;}{n} = 
\lim\limits_{x \rightarrow \infty} \bruch{\rule[-10pt]{0pt}{10pt}\;\frac{1}{x}\;}{1} = 
\lim\limits_{x \rightarrow \infty} \bruch{1}{x} = 0$. \hspace*{\fill} $\Box$
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}:  Zeigen Sie $\sqrt{n} \in \Oh(n)$.
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}:  Es gilt $2^n \in \Oh(3^n)$, aber $3^n \notin \Oh(2^n)$.
\vspace*{0.3cm}

\noindent
\textbf{Beweis}:  Zunächst haben wir \\[0.1cm]
\hspace*{1.3cm} 
$\displaystyle\lim\limits_{n \rightarrow \infty} \bruch{2^n}{3^n} = 
 \lim\limits_{n \rightarrow \infty} \left(\bruch{2}{3}\right)^n = 0$.
\\[0.1cm]
Den Beweis, dass $3^n \notin \Oh(2^n)$ ist, führen wir indirekt und nehmen an, dass 
$3^n \in \Oh(2^n)$ ist.  Dann muss es Konstanten $c$ und $k$ geben, so dass für alle $n
\geq k$ gilt \\[0.1cm]
\hspace*{1.3cm} $3^n \leq c \cdot 2^n$. \\[0.1cm]
Wir logarithmieren beide Seiten dieser Ungleichung und finden \\[0.1cm]
\[
\begin{array}{llcl}
                & \ln(3^n) & \leq & \ln(c \cdot 2^n) \\[0.1cm]
\leftrightarrow\quad &  n \cdot \ln(3) & \leq & \ln(c) + n \cdot \ln(2) \\[0.1cm]
\leftrightarrow &  n \cdot \bigl(\ln(3) - \ln(2)\bigr) & \leq & \ln(c)  \\[0.1cm]
\leftrightarrow &  n  & \leq & \bruch{\ln(c)}{\ln(3) - \ln(2)}  \\[0.1cm]
\end{array}
\]
Die letzte Ungleichung müsste nun für beliebig große natürliche Zahlen $n$ gelten und liefert
damit den gesuchten Widerspruch zu unserer Annahme.
\vspace*{0.3cm}

\noindent
\textbf{Aufgaben}:  
\begin{enumerate}
\item Es sei $b \geq 1$. Zeigen Sie $\log_{b}(n) \in \Oh(\ln(n))$.
\item $3 \cdot n^2 + 5 \cdot n + \sqrt{n} \in \Oh(n^2)$
\item $7 \cdot n + \bigl(\log_2(n)\bigr)^2 \in \Oh(n)$
\item $\sqrt{n} + \log_2(n) \in \Oh\left(\sqrt{n}\right)$
\item $n^n \in \mathcal{O}\bigl(2^{2^n}\bigr)$.

      Hinweis:  Diese Aufgabe ist schwer!
\end{enumerate}


\section{Fallstudie: Effiziente Berechnung der Potenz}
Wir  verdeutlichen die bisher eingeführten Begriffe an einem Beispiel.  Wir betrachten ein
Programm zur Berechnung der Potenz $m^n$ für natürliche Zahlen $m$ und $n$.
Abbildung \ref{fig:power-naive} zeigt ein naives Programm zur Berechnung von $m^n$.
Die diesem Programm zu Grunde liegende Idee ist es, die Berechnung von $m^n$ 
nach der Formel \\[0.1cm]
\hspace*{1.3cm} 
$m^n = \underbrace{m * \cdots * m}_n$ \\[0.1cm]
durchzuführen.  

\begin{figure}[!h]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    static BigInteger power(BigInteger m, int n)
    {
        BigInteger r = BigInteger.valueOf(1);
        for (int i = 0; i < n; ++i) {
            r = r.multiply(m);
        } 
        return r;
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Naive Berechnung von $m^n$ für $m,n \in \N$.}
  \label{fig:power-naive}
\end{figure} 

Das Programm ist  offenbar korrekt.
Zur Berechnung  von $m^n$ werden für positive Exponenten $n$ insgesamt $n-1$ Multiplikationen durchgeführt.
Wir können $m^n$ aber wesentlich effizienter berechnen.  Die Grundidee erläutern wir an
der Berechnung von $m^4$.  Es gilt \\[0.1cm]
\hspace*{1.3cm} 
$m^4 = (m \cdot m) \cdot (m \cdot m)$.\\[0.1cm]
Wenn wir den Ausdruck $m\cdot m$ nur einmal berechnen, dann kommen wir bei der Berechnung von
$m^4$ nach der obigen Formel mit zwei Multiplikationen aus, während bei einem
naiven Vorgehen 3 Multiplikationen durchgeführt würden! Für die Berechnung von $m^8$
können wir folgende Formel verwenden: \\[0.1cm]
\hspace*{1.3cm} 
$m^8 = \bigl( (m \cdot m) \cdot (m \cdot m) \bigr) \cdot \bigl( (m \cdot m) \cdot (m \cdot m) \bigr)$. \\[0.1cm]
Berechnen wir den Term $(m \cdot m) \cdot (m \cdot m)$ nur einmal, so werden jetzt 3 Multiplikationen
benötigt um $m^8$ auszurechnen.  Ein naives Vorgehen würde 7 Multiplikationen benötigen.
Wir versuchen die oben an Beispielen erläuterte Idee in ein Programm umzusetzen.
Abbildung \ref{fig:power} zeigt das Ergebnis.  Es berechnet die Potenz $m^n$ nicht durch eine
naive $(n-1)$-malige Multiplikation sondern es verwendet das Paradigma \\[0.1cm]
\hspace*{1.3cm} \emph{Teile und Herrsche}. \quad (engl. \emph{divide and conquer})
\\[0.1cm]
Die Grundidee um den Term $m^n$ für $n \geq 1$ effizient zu berechnen,
lässt sich durch folgende Formel beschreiben: \\[0.1cm] 
\hspace*{1.3cm} 
$m^n = 
\left\{\begin{array}{ll}
m^{n/2} \cdot m^{n/2}      & \mbox{falls $n$ gerade ist};    \\
m^{n/2} \cdot m^{n/2} \cdot m  & \mbox{falls $n$ ungerade ist}.
\end{array}
\right.
$


\begin{figure}[!h]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    static BigInteger power(BigInteger m, int n)
    {
        if (n == 0)
            return BigInteger.valueOf(1);
        BigInteger p = power(m, n / 2);
        if (n % 2 == 0) {
            return p.multiply(p);
        } else {
            return p.multiply(p).multiply(m);
        }
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Berechnung von $m^n$ für $m,n \in \N$.}
  \label{fig:power}
\end{figure} 

Da es keineswegs offensichtlich ist, dass das Programm in \ref{fig:power} 
tatsächlich die Potenz $m^n$ berechnet,  wollen wir dies nachweisen.  Wir benutzen dazu
die Methode der \emph{Wertverlaufs-Induktion} (engl. \emph{computational induction}).
Die Wertverlaufs-Induktion ist eine Induktion über die Anzahl der rekursiven Aufrufe.
Diese Methode bietet sich immer dann an, wenn die Korrektheit einer rekursiven Prozedur
nachzuweisen ist. Das Verfahren besteht aus zwei Schritten:
\begin{enumerate}
\item \emph{Induktions-Anfang}.

      Beim Induktions-Anfang weisen wir nach, dass die Prozedur in allen den Fällen korrekt arbeitet,
      in denen sie sich nicht selbst aufruft.  
\item \emph{Induktions-Schritt}

      Im Induktions-Schritt beweisen wir, dass die Prozedur auch in den Fällen korrekt
      arbeitet, in denen sie sich rekursiv aufruft.   Beim Beweis dieser Tatsache dürfen
      wir voraussetzen, dass die Prozedur bei jedem rekursiven Aufruf den korrekten Wert
      produziert. Diese Voraussetzung wird auch als \emph{Induktions-Voraussetzung} bezeichnet.
\end{enumerate}
Wir demonstrieren die Methode, indem wir durch Wertverlaufs-Induktion beweisen, dass 
gilt: 
\\[0.1cm]
\hspace*{1.3cm} $\mathtt{power}(m,n) \leadsto m^n$.
\begin{enumerate}
\item \textbf{Induktions-Anfang}.

      Die Methode ruft sich dann nicht rekursiv auf, wenn $n = 0$  gilt.  In diesem Fall
      haben wir \\[0.1cm]
      \hspace*{1.3cm} 
      $\mathtt{power}(m,0) \leadsto 1 =  m^0$.
\item \textbf{Induktions-Schritt}.

      Der rekursive Aufruf der Prozedur $\mathtt{power}$ hat die Form 
       $\mathtt{power}(m,n/2)$.  Also gilt nach Induktions-Voraussetzung \\[0.1cm]
       \hspace*{1.3cm} $\displaystyle \mathtt{power}(m,n/2) \leadsto m^{n/2}$. \\[0.1cm]
       Danach können in der weiteren Rechnung zwei Fälle auftreten.
       Wir führen daher eine Fallunterscheidung entsprechend der \texttt{if}-Abfrage in Zeile 6 durch:
      \begin{enumerate}
      \item $n \;\mathtt{\%}\; 2 = 0$, $n$ ist also gerade.

            Dann gibt es ein $k \in \N$ mit $n = 2 \cdot k$ und also ist $n/2 = k$.
            In diesem Fall gilt 
            \[ 
            \begin{array}{lcl}
            \mathtt{power}(m,n) & \leadsto & \mathtt{power}(m,k) \cdot \mathtt{power}(m,k) \\[0.1cm]
                                & \stackrel{I.V.}{\leadsto} & m^k \cdot m^k  \\[0.1cm]
                                & = & m^{2\cdot k} \\[0.1cm]
                                & = & m^{n}.
            \end{array}
            \]            
      \item $n \;\mathtt{\%}\; 2 = 1$, $n$ ist also ungerade.

            Dann gibt es ein $k \in \N$ mit $n = 2 \cdot k + 1$ und wieder ist $n/2 = k$.
            In diesem Fall gilt 
            \[ 
            \begin{array}{lcl}
            \mathtt{power}(m,n) & \leadsto & \mathtt{power}(m,k) \cdot \mathtt{power}(m,k) \cdot m  \\[0.1cm]
                                & \stackrel{I.V.}{\leadsto} & m^k \cdot m^k \cdot m  \\[0.1cm]
                                & = & m^{2\cdot k+1} \\[0.1cm]
                                & = & m^{n}.
            \end{array}
            \]
      \end{enumerate}
      Damit ist der Beweis der Korrektheit abgeschlossen. \hspace*{\fill} $\Box$
\end{enumerate}
Als nächstes wollen wir die Komplexität des obigen Programms untersuchen. Dazu berechnen
wir zunächst die Anzahl der Multiplikationen, die beim Aufruf $\mathtt{power}(m,n)$
durchgeführt werden.  Je nach dem, ob der Test in Zeile 6 negativ ausgeht oder nicht, gibt
es mehr oder weniger Multiplikationen.  Wir untersuchen zunächst den schlechtesten Fall
(engl. \emph{worst case}).  Der schlechteste Fall tritt dann ein, wenn es
ein $l\in \N$ gibt, so dass \\[0.1cm]
\hspace*{1.3cm} $n = 2^l - 1$ \\[0.1cm]
ist, denn dann gilt \\[0.1cm]
\hspace*{1.3cm} $n/2 = 2^{l-1} - 1$ \quad und \quad $n \,\texttt{\symbol{37}}\, 2 = 1$, \\[0.1cm]
was wir sofort durch die Probe
\\[0.2cm]
\hspace*{1.3cm}
$2 \cdot(n/2) + n \,\texttt{\symbol{37}}\, 2 = 2 \cdot (2^{l-1} - 1) + 1 = 2^l - 1 = n$
\\[0.2cm]
verifizieren.  Folglich ist, wenn $n$ die Form $2^l - 1$ hat, bei jedem rekursiven Aufruf
der Exponent $n$ ungerade. 
Wir nehmen also $n = 2^l - 1$ an und berechnen die Zahl $a_n$ der Multiplikationen, die beim
Aufruf von $\mathtt{power}(m,n)$ durchgeführt werden. \\[0.1cm]
Zunächst gilt $a_0 = 0$, denn wenn $n =0$  ist, wird keine Multiplikation durchgeführt.
Ansonsten haben wir in Zeile 9 zwei Multiplikationen, die zu den Multiplikationen, die beim
rekursiven Aufruf in Zeile $5$ anfallen, hinzu addiert werden müssen.  Damit erhalten wir
die folgende Rekurrenz-Gleichung: \\[0.1cm]
\hspace*{1.3cm} $a_n = a_{n/2} + 2$ \qquad für alle $n \in \left\{2^l - 1 \mid l \in \N\right\}$\quad mit $a_0 = 0$. \\[0.1cm]
Wir definieren $b_l := a_{2^l-1}$ und erhalten dann für die Folge $(b_l)_l$ die
Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} 
$b_l = a_{2^l-1} = a_{(2^l-1)/2} + 2 = a_{2^{l-1}-1} + 2 = b_{l-1} +2$ \qquad für alle $l\in\N$. \\[0.1cm]
Die Anfangs-Bedingung lautet $b_0 = a_{2^0-1} = a_0 = 0$.  
Offenbar lautet die Lösung der Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $b_l = 2 \cdot l$ \qquad für alle $l \in \N$. \\[0.1cm] 
Diese Behauptung können Sie durch eine triviale Induktion verifizieren. 
Für die Folge $a_n$ haben wir dann: \\[0.1cm]
\hspace*{1.3cm} $a_{2^l-1} = 2 \cdot l$. \\[0.1cm]
Formen wir die Gleichung $n = 2^l - 1$ nach $l$ um, so erhalten wir $l =
\log_2(n+1)$. Setzen wir diesen Wert ein, so sehen wir \\[0.1cm]
\hspace*{1.3cm} $a_n = 2 \cdot \log_2(n+1) \in \Oh\bigl(\log_2(n)\bigr)$.
\vspace*{0.3cm}

Wir betrachten jetzt den günstigsten Fall, der bei der Berechnung von
$\mathtt{power}(m,n)$ auftreten kann. Der günstigste Fall tritt dann ein, wenn 
der Test in Zeile 6 immer gelingt weil $n$ jedesmal eine gerade Zahl ist.  In diesem Fall muss
es ein $l\in \N$ geben, so dass $n$ die Form \\[0.1cm]
\hspace*{1.3cm} $n = 2^l$ \\[0.1cm]
hat. Wir nehmen also $n = 2^l$ an und berechnen die Zahl $a_n$ der Multiplikationen, die
dann beim
Aufruf von $\mathtt{power}(m,n)$ durchgeführt werden. \\[0.1cm]
Zunächst gilt $a_{2^0} = a_1 = 2$, denn wenn $n = 1$  ist, scheitert der Test in Zeile 6 und Zeile 9
liefert 2 Multiplikationen.  Zeile 5 liefert in diesem Fall keine Multiplikation, weil
beim Aufruf $\mathtt{power}(m,0)$ sofort das Ergebnis in Zeile 4 zurück gegeben wird.

Ist $n = 2^l > 1$, so  haben wir in Zeile 7 eine Multiplikation, die zu den Multiplikationen, die beim
rekursiven Aufruf in Zeile $5$ anfallen, hinzu addiert werden muss.  Damit erhalten wir
die folgende Rekurrenz-Gleichung: \\[0.1cm]
\hspace*{1.3cm} $a_n = a_{n/2} + 1$ \qquad für alle $n \in \left\{2^l \mid l \in \N\right\}$\quad mit $a_1 = 2$. \\[0.1cm]
Wir definieren $b_l := a_{2^l}$ und erhalten dann für die Folge $(b_l)_l$ die
Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} 
$b_l = a_{2^l} = a_{(2^l)/2} + 1 = a_{2^{l-1}} + 1 = b_{l-1} + 1$ \qquad für alle $l\in\N$, \\[0.1cm]
mit der Anfangs-Bedingungen $b_0 = a_{2^0} = a_1 = 2$.
Also lösen wir die Rekurrenz-Gleichung \\[0.1cm]
\hspace*{1.3cm} $b_{l+1} = b_l + 1$ \qquad für alle $l \in \N$ \quad mit $b_0 = 2$.\\[0.1cm]
Offenbar lautet die Lösung \\[0.1cm]
\hspace*{1.3cm} $b_l = 2 + l$ \qquad für alle $l\in\N$.
\\[0.1cm]
Setzen wir hier $b_l = a_{2^l}$, so erhalten wir: \\[0.1cm]
\hspace*{1.3cm} $a_{2^l} = 2 + l$. \\[0.1cm]
Formen wir die Gleichung $n = 2^l$ nach $l$ um, so erhalten wir $l =
\log_2(n)$. Setzen wir diesen Wert 
ein, so sehen wir \\[0.1cm]
\hspace*{1.3cm} $a_n = 2 + \log_2(n) \in \Oh\bigl(\log_2(n)\bigr)$.
\vspace*{0.3cm}

Da wir sowohl im besten als auch im schlechtesten Fall das selbe Ergebnis bekommen haben,
können wir schließen, dass für die Zahl $a_n$ der Multiplikationen allgemein gilt:\\[0.1cm]
\hspace*{1.3cm} $a_n \in \Oh\bigl(\log_2(n)\bigr)$.
\vspace*{0.3cm}

\noindent
\textbf{Bemerkung}:  Wenn wir nicht die Zahl der Multiplikationen sondern die Rechenzeit
ermitteln wollen, die der obige Algorithmus benötigt, so wird die Rechnung wesentlich
aufwendiger.  Der Grund ist, dass wir dann berücksichtigen müssen, dass die Rechenzeit bei
der Berechnung der Produkte in den Zeilen 7 und 9 von der Größe der Faktoren abhängig ist.
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}:
Schreiben Sie eine Prozedur $\mathtt{prod}$ zur Multiplikation zweier Zahlen.
Für zwei natürliche Zahlen $m$ und $n$ soll der Aufruf $\mathtt{prod}(m, n)$  das Produkt
$m\cdot n$ mit Hilfe von Additionen
berechnen.  Benutzen Sie bei der Implementierung das Paradigma ``Teile und Herrsche'' und
beweisen Sie die Korrektheit des Algorithmus mit Hilfe einer Wertverlaufs-Induktion.
Schätzen  Sie die Anzahl der Additionen, die beim Aufruf von $\mathtt{prod}(m,n)$
im schlechtesten Fall durchgeführt werden, mit Hilfe der $\Oh$-Notation ab. 
\pagebreak

\section{Der Hauptsatz der Laufzeit-Funktionen}
Im letzten Abschnitt haben wir zur Analyse der Rechenzeit der Funktion $\textsl{power}()$
zunächst eine Rekurrenz-Gleichung aufgestellt, diese gelöst und anschließend das Ergebnis
mit Hilfe der $\Oh$-Notation abgeschätzt.  Wenn wir nur an einer Abschätzung interessiert
sind, dann ist es in vielen Fällen nicht notwendig, die zu Grunde liegende
Rekurrenz-Gleichung exakt zu lösen, denn der \textsl{Hauptsatz der Laufzeit-Funktionen}
(Englisch:~\textsl{Master Theorem}) \cite{cormen:01} bietet eine Methode zur Gewinnung von Abschätzungen,
bei der es nicht notwendig ist, die Rekurrenz-Gleichung zu lösen.  
Wir präsentieren eine etwas vereinfachte Form dieses Hauptsatzes.

\begin{Theorem}[Hauptsatz der Laufzeit-Funktionen] 
  Es seien 
  \begin{enumerate}
  \item $\alpha,\beta \in \mathbb{N}$ mit $\alpha \geq 1$ und $\beta > 1$,
  \item $f:\N \rightarrow \R_+$,
  \item die Funktion $g:\N \rightarrow \R_+$ genüge der Rekurrenz-Gleichung 
        \\[0.2cm]
        \hspace*{1.3cm}
        $g(n) = \alpha \cdot g\left(n/\beta\right) + f(n)$,
        \\[0.2cm]
        wobei der Ausdruck $n/\beta$ die ganzzahlige Division von $n$ durch $\beta$ bezeichnet.
  \end{enumerate}
  Dann können wir in den gleich genauer beschriebenen Situationen asymptotische
  Abschätzungen für die Funktion $g(n)$ angeben:
  \begin{enumerate}
  \item Falls es eine Konstante $\varepsilon > 0$ gibt, so dass 
        \\[0.2cm]
        \hspace*{1.3cm}
        $f(n) \in \Oh\bigl(n^{\log_\beta(\alpha) - \varepsilon}\bigr)$
        \\[0.2cm]
        gilt, dann haben wir 
        \\[0.2cm]
        \hspace*{1.3cm}
        $g(n) \in \Oh\left(n^{\log_\beta(\alpha)}\right)$.
  \item Falls sowohl $f(n) \in \Oh\bigl(n^{\log_\beta(\alpha)}\bigr)$ als auch $n^{\log_\beta(\alpha)} \in \Oh\bigl(f(n)\bigr)$
        gilt, dann folgt
        \\[0.2cm]
        \hspace*{1.3cm}
        $g(n) \in \Oh\bigl(\log_\beta(n) \cdot n^{\log_\beta(\alpha)}\bigr)$. 
  \item Falls es eine Konstante $\gamma < 1$ und eine Konstante $k \in \mathbb{N}$ gibt, so dass
        für $n \geq k$
        \\[0.2cm]
        \hspace*{1.3cm}
        $\alpha \cdot f\left(n/\beta\right) \leq \gamma \cdot f(n)$        
        \\[0.2cm]
        gilt, dann folgt 
        \\[0.2cm]
        \hspace*{1.3cm}
        $g(n) \in \Oh\bigl(f(n)\bigr)$. \hspace*{\fill} $\Box$
  \end{enumerate}
\end{Theorem}
\textbf{Erläuterung}:
Ein vollständiger Beweis dieses Theorems geht über den Rahmen einer einführenden Vorlesung hinaus.
Wir wollen aber erklären, wie die drei Fälle zustande kommen.
\begin{enumerate}
\item Wir betrachten zunächst den ersten Fall.  In diesem Fall kommt der asymptotisch 
wesentliche Anteil des Wachstums der Funktion $g$ von der Rekursion. 
Um diese Behauptung einzusehen, betrachten wir die homogene Rekurrenz-Gleichung
\[ g(n) = \alpha \cdot g\left(n/\beta\right). \]
Wir beschränken uns auf solche Werte von $n$, die sich als Potenzen von $\beta$ schreiben
lassen, also Werte der Form 
\[ n = \beta^k \quad \mbox{mit $k\in\N$.} \]
Definieren wir für $k \in \N$ die Folge $\bigl(b_k\bigr)_{k\in\N}$ durch
\[ b_k := g\bigl(\beta^k\bigr), \]
so erhalten wir für die Folgenglieder $b_k$ die Rekurrenz-Gleichung 
\[
     b_k = g\bigl(\beta^k\bigr) = \alpha \cdot g\left( \beta^k/\beta \right) 
   = \alpha \cdot g\bigl(\beta^{k-1}\bigr) = \alpha \cdot b_{k-1}.
\]
Wir sehen unmittelbar, dass diese Rekurrenz-Gleichung die Lösung 
\begin{equation}
  \label{eq:master}
  b_k = \alpha^k \cdot b_0   
\end{equation}
hat.  Aus $n = \beta^k$ folgt sofort 
\[  k = \log_\beta(n). \]
Berücksichtigen wir, dass $b_k = g(n)$ ist, so liefert Gleichung (\ref{eq:master}) also 
\begin{equation}
  \label{eq:master2}
   g(n) = \alpha^{\log_\beta(n)} \cdot b_0.   
\end{equation}
Wir zeigen, dass
\begin{equation}
  \label{eq:master1}
  \alpha^{\log_\beta(n)} = n^{\log_\beta(\alpha)} 
\end{equation}
gilt.  Dazu betrachten wir die folgende Kette von Äquivalenz-Umformungen:
\[ 
\begin{array}[t]{llcll}
                & \alpha^{\log_\beta(n)} & = & n^{\log_\beta(\alpha)} & \mid\; \log_\beta(\cdot)  \\[0.2cm]
\Leftrightarrow & \log_\beta\left(\alpha^{\log_\beta(n)}\right) 
                  & = & \log_\beta\left(n^{\log_\beta(\alpha)}\right) \\[0.2cm]
\Leftrightarrow & \log_\beta(n) \cdot log_\beta(\alpha) 
                  & = & \log_\beta(\alpha) \cdot \log_\beta(n) & 
                  \mbox{wegen $\log_b(x^y) = y \cdot \log_b(x)$}
\end{array}
\]
Da die letzte Gleichung offenbar richtig ist, und wir zwischendurch nur Äquivalenz-Umformungen
durchgeführt haben, ist auch die erste Gleichung richtig und wir haben Gleichung (\ref{eq:master1}) gezeigt.
Insgesamt haben wir damit 
\[ g(n) = n^{\log_\beta(\alpha)} \cdot b_0 \]
gezeigt.  Also gilt: Vernachlässigen wir die Inhomogenität $f$, so erhalten wir
die folgende asymptotische Abschätzung:
\[ g(n) \in \Oh\bigl(n^{\log_\beta(\alpha)}\bigr). \]
\item Im zweiten Fall liefert
die Inhomogenität $f$ einen Beitrag, der genau so groß ist wie die Lösung der homogenen
Rekurrenz-Gleichung.  Dies führt dazu, dass die Lösung asymptotisch um einen Faktor
$\log_\beta(n)$ größer wird.  Um das zu verstehen, betrachten wir exemplarisch die Rekurrenz-Gleichung
\[ g(n) = \alpha \cdot g\left(n/\beta\right) + n^{\log_\beta(\alpha)} \]
mit der Anfangs-Bedingung $g(1) = 0$.  Wir betrachten wieder nur Werte 
$n \in \{ \beta^k \mid k \in \N \}$ und setzen daher
\[ n = \beta^k. \]
Wie eben definieren wir
\[ b_k := g(n) = g\bigl(\beta^k\bigr). \]
Das liefert
\[ b_k = \alpha \cdot g\left(\beta^k/\beta\right) + \bigl(\beta^k\bigr)^{\log_\beta(\alpha)}
       = \alpha \cdot g(\beta^{k-1}) + \left(\beta^{\log_\beta(\alpha)}\right)^k
       = \alpha \cdot b_{k-1} + \alpha^k.
 \]
Nun gilt $b_0 = g(1) = 0$.  Um die Rekurrenz-Gleichung $b_k = \alpha \cdot b_{k-1} + \alpha^k$ zu lösen,
berechnen wir zunächst die Werte für $k=1,2,3$:
\begin{eqnarray*}
  b_1 & = & \alpha \cdot b_0 + \alpha^1               \\
      & = & \alpha \cdot 0 + \alpha                   \\
      & = & 1 \cdot \alpha^1                          \\[0.2cm]
  b_2 & = & \alpha \cdot b_1 + \alpha^1               \\
      & = & \alpha \cdot 1 \cdot \alpha^1 + \alpha^2  \\
      & = & 2 \cdot \alpha^2                          \\[0.2cm]
  b_3 & = & \alpha \cdot b_2 + \alpha^2               \\
      & = & \alpha \cdot 2 \cdot \alpha^2 + \alpha^3  \\
      & = & 3 \cdot \alpha^3                          
\end{eqnarray*}
Wir vermuten hier, dass die Lösung dieser Rekurrenz-Gleichung durch die Formel
\[ b_k = k \cdot \alpha^k \]
gegeben wird.  Den Nachweis dieser Vermutung führen wir durch eine triviale Induktion:
\begin{enumerate}
\item[I.A.:] $k = 0$
             
             Einerseits gilt $b_0 = 0$, andererseits gilt $0 \cdot \alpha^0 = 0$.

\item[I.S.:] $k \mapsto k+1$

            \[
            \begin{array}[t]{lcl}
              b_{k+1} &               =  & \alpha \cdot b_k + \alpha^{k+1}              \\[0.1cm] 
                      & \stackrel{IV}{=} & \alpha \cdot k \cdot \alpha^k + \alpha^{k+1} \\[0.1cm]  
                      &               =  & k \cdot \alpha^{k+1} + \alpha^{k+1}          \\[0.1cm] 
                      &               =  & (k + 1) \cdot \alpha^{k+1}. 
            \end{array}
            \]
\end{enumerate}
Da aus $n = \beta^k$ sofort $k = \log_\beta(n)$ folgt, ergibt sich für die Funktion
$g(n)$ 
\[ g(n) = b_k = k \cdot \alpha^k = \log_\beta(n) \cdot \alpha^{\log_\beta(n)} = \log_\beta(n) \cdot
n^{\log_\beta(\alpha)} \]
und das ist genau die Form, durch die im zweiten Fall des Hauptsatzes die Funktion
$g(n)$ abgeschätzt wird.
\item
Im letzten Fall des Hauptsatzes überwiegt schließlich der Beitrag der Inhomogenität, so dass die Lösung 
nun asymptotisch durch die Inhomogenität dominiert wird.
Wir machen wieder den Ansatz 
\[ n = \beta^k \quad \mbox{und} \quad b_k = g\bigl(\beta^k\bigr). \]
Wir überlegen uns, wie die Ungleichung 
\[ \alpha \cdot f\left(n/\beta\right) \leq \gamma \cdot f(n) \]
für $n = \beta^k$ aussieht und erhalten
\begin{equation}
  \label{eq:master_u1}
 \alpha \cdot f\left(\beta^{k-1}\right) \leq \gamma \cdot f\bigl(\beta^k\bigr) 
\end{equation}
Setzen wir hier für $k$ den Wert $k-1$ ein, so erhalten wir
\begin{equation}
  \label{eq:master_u2}
 \alpha \cdot f\left(\beta^{k-2}\right) \leq \gamma \cdot f\bigl(\beta^{k-1}\bigr) 
\end{equation}
Wir multiplizieren nun die Ungleichung (\ref{eq:master_u2}) mit $\alpha$ und
Ungleichung (\ref{eq:master_u1}) mit $\gamma$ und erhalten die Ungleichungen
\[ \alpha^2 \cdot f\left(\beta^{k-2}\right) \leq \alpha \cdot \gamma \cdot f\bigl(\beta^{k-1}\bigr) 
   \quad \mbox{und} \quad
   \alpha \cdot \gamma \cdot f\left(\beta^{k-1}\right) \leq \gamma^2 \cdot f\bigl(\beta^k\bigr) 
\]
Setzen wir diese Ungleichungen zusammen, so erhalten wir die neue Ungleichung
\[ \alpha^2 \cdot f\left(\beta^{k-2}\right) \leq \gamma^2 \cdot f\bigl(\beta^k\bigr) \]
Iterieren wir diesen Prozess, so sehen wir, dass 

\begin{equation}
  \label{eq:master_u3}
\alpha^i \cdot f\bigl(\beta^{k-i}\bigr) \leq \gamma^i \cdot f(\beta^k) 
   \quad \mbox{für alle $i \in \{1,\cdots k\}$ gilt.}   
\end{equation}
Wir berechnen nun $g(\beta^k)$ durch Iteration der Rekurrenz-Gleichung:
\[
\begin{array}[t]{lcl}
g(\beta^k) & = & \alpha \cdot g(\beta^{k-1}) + f(\beta^k) \\
           & = & \alpha \cdot \bigl(\alpha \cdot g(\beta^{k-2}) + f(\beta^{k-1})\bigr) + f(\beta^k) \\
           & = & \alpha^2 \cdot g(\beta^{k-2}) + \alpha \cdot f(\beta^{k-1}) + f(\beta^k) \\
           & = & \alpha^3 \cdot g(\beta^{k-3}) + 
                 \alpha^2 \cdot f(\beta^{k-2}) + \alpha \cdot f(\beta^{k-1}) + f(\beta^k) \\
           &   & \vdots \\
           & = & \alpha^k \cdot g(\beta^0) + \alpha^{k-1} \cdot f(\beta^1) + \cdots +
                 \alpha^1 \cdot f(\beta^{k-1}) + \alpha^0 \cdot f(\beta^k) \\
           & = & \alpha^k \cdot g(\beta^0) + \sum\limits_{i=1}^{k} \alpha^{k-i} \cdot f(\beta^i)
\end{array}
\]
Da bei der $\Oh$-Notation die Werte von $f$ für kleine Argumente keine Rolle spielen,
können wir ohne Beschränkung der Allgemeinheit annehmen, dass $g(\beta^0) \leq f(\beta^0)$
ist.  Damit erhalten wir dann die Abschätzung
\[ 
\begin{array}{lcl}
g(\beta^k) & \leq & \alpha^k \cdot f(\beta^0) + \sum\limits_{i=1}^{k} \alpha^{k-i} \cdot f(\beta^i) \\[0.3cm]
           & =    & \sum\limits_{i=0}^{k} \alpha^{k-i} \cdot f(\beta^i) \\[0.3cm]
           & =    & \sum\limits_{j=0}^{k} \alpha^{j} \cdot f(\beta^{k-j}) 
\end{array}
\]
wobei wir im letzten Schritt den Index $i$ durch $k-j$ ersetzt haben.  Berücksichtigen wir
nun die Ungleichung (\ref{eq:master_u3}), so erhalten wir die Ungleichungen
\[
\begin{array}{lcl}
   g(\beta^k) & \leq & \sum\limits_{j=0}^{k} \gamma^j \cdot f(\beta^k) \\[0.3cm]
              & =    & f(\beta^k) \cdot \sum\limits_{j=0}^{k} \gamma^j \\[0.5cm]
              & \leq & f(\beta^k) \cdot \sum\limits_{j=0}^{\infty} \gamma^j \\[0.5cm]
              & =    & f(\beta^k) \cdot \bruch{1}{\;1 - \gamma\;},
\end{array}
\]
wobei wir im letzten Schritt die Formel für die geometrische Reihe 
\[ \sum\limits_{j=0}^{\infty} q^j = \bruch{1}{1 - q} \]
benutzt haben.  Ersetzen wir nun $\beta^k$ wieder durch $n$, so sehen wir, dass 
\[ g(n) \leq \bruch{1}{\;1 - \gamma\;} \cdot f(n) \]
gilt und daraus folgt sofort
\[ g(n) \in \Oh\bigl(f(n)\bigr). \hspace*{10cm} \Box \]
\end{enumerate}
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}:
Wir untersuchen das asymptotische Wachstum der Folge, die durch die Rekurrenz-Gleichung
\[ a_n = 9 \cdot a_{n/3} + n \]
definiert ist.  Wir haben hier 
\[ g(n) = 9 \cdot g(n/3) + n, \quad \mbox{also} \quad \alpha = 9, 
   \quad \beta = 3, \quad f(n) = n.
\]
Damit gilt 
\[ \log_\beta(\alpha) = \log_3(9) = 2. \]
Wir setzen $\varepsilon := 1 > 0$.  Dann gilt
\[ f(n) = n \in \Oh(n) = \Oh\left(n^{2-1}\right) = \Oh\left(n^{2-\varepsilon}\right). \]
Damit liegt der erste Fall des Hauptsatzes vor und wir können schließen, dass
\[ g(n) \in \Oh(n^2) \]
gilt. \qed
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}:
Wir  betrachten die Rekurrenz-Gleichung 
\\[0.2cm]
\hspace*{1.3cm}
$a_n = a_{n/2} + 2$
\\[0.2cm]
und analysieren das asymptotische Wachstum der Funktion $n \mapsto a_n$ mit Hilfe des
Hauptsatzes der Laufzeit-Funktionen.
Wir setzen $g(n) := a_n$ und haben also für die Funktion $g$ die Rekurrenz-Gleichung
\\[0.2cm]
\hspace*{1.3cm}
$g(n) = 1 \cdot g\left(n/2\right) + 2$
\\[0.2cm]
Wir definieren $\alpha := 1$, $\beta := 2$ und $f(n) = 2$.  Wegen 
\\[0.2cm]
\hspace*{1.3cm}
$\log_\beta(\alpha) = \log_2(1) = 0$ \quad und \quad
$2 \in \Oh(1)= \Oh(n^0)$ \quad sowie \quad $n^0 \in \Oh(2)$
\\[0.2cm]
sind die Voraussetzungen des zweiten Falls erfüllt und wir erhalten 
\\[0.2cm]
\hspace*{1.3cm}
$a_n \in \Oh\bigl(\log_2(n)\bigr)$.
\qed
\vspace*{0.3cm}

\noindent
\textbf{Beispiel}:
Diesmal betrachten  wir die Rekurrenz-Gleichung 
\\[0.2cm]
\hspace*{1.3cm}
$a_n = 3 \cdot a_{n/4} + n \cdot \log_2(n)$.
\\[0.2cm]
Es gilt $\alpha = 3$, $\beta = 4$ und $f(n) = n \cdot \log_2(n)$.  Damit gilt
\[ log_\beta(\alpha) = \log_4(3) < 1. \]
Damit ist klar, dass die Funktion $f(n) = n \cdot log_2(n)$ schneller wächst als die
Funktion $n^{\log_4(3)}$.  Damit kann höchstens der dritte Fall des Hauptsatzes vorliegen.
Wir suchen also ein $\gamma < 1$, so dass die Ungleichung
\[ \alpha \cdot f(n/\beta) \leq \gamma \cdot f(n) \]
gilt.  Setzen wir hier die Funktion $f(n) = n \cdot \log_2(n)$ und die Werte für $\alpha$
und $\beta$ ein, so erhalten wir die Ungleichung 
\[ 3 \cdot n/4 \cdot \log_2(n/4) \leq \gamma \cdot n \cdot \log_2(n), \]
die für durch 4 teilbares $n$ offenbar äquivalent ist zu
\[ \frac{3}{4} \cdot \log_2(n/4) \leq \gamma \cdot \log_2(n). \]
Setzen wir $\gamma := \frac{3}{4}$ und kürzen, so geht diese Ungleichung über in die
offensichtlich wahre Ungleichung
\[ \log_2(n/4) \leq \log_2(n). \] 
Damit liegt also der dritte Fall des Hauptsatzes vor und wir können schließen, dass
\[ a_n \in \Oh\left(n \cdot \log_2(n)\right) \]
gilt. \qed
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}:
Benutzen Sie den Hauptsatz der Laufzeit-Funktionen um das asymptotische Wachstum 
der Folgen $\folge{a_n}$, $\folge{b_n}$ und $\folge{c_n}$  abzuschätzen, falls diese
Folgen den nachstehenden Rekurrenz-Gleichungen genügen:
\begin{enumerate}
\item $a_n = 4 \cdot a_{n/2} + 2 \cdot n + 3$.
\item $b_n = 4 \cdot b_{n/2} + n^2$.
\item $c_n = 3 \cdot c_{n/2} + n^3$.
\end{enumerate}

\noindent
\textbf{Bemerkung}: Es ist wichtig zu sehen, dass die drei Fälle des Theorems nicht vollständig sind:
Es gibt Situationen, in denen der Hauptsatz nicht anwendbar ist.  Beispielsweise lässt sich der Hauptsatz nicht
für die Funktion $g$, die durch die Rekurrenz-Gleichung
\[ g(n) = 2 \cdot g(n/2) + n \cdot \log_2(n) \quad \mbox{mit der Anfangs-Bedingung $g(1) = 0$}\]
definiert ist, anwenden, denn die Inhomogenität wächst schneller als im zweiten Fall, aber
nicht so schnell, dass der dritte Fall vorliegen würde.  Dies können wir wie folgt sehen.
Es gilt 
\[ \alpha = 2, \quad \beta = 2 \quad \mbox{und damit} \quad \log_\beta(\alpha) = 1. \]
Damit der zweite Fall vorliegt, müsste 
\[ n \cdot \log_2(n) \in \Oh(n^1) \]
gelten, was sicher falsch ist.  Da die Inhomogenität $n \cdot \log_2(n)$ offenbar
schneller wächst als der Term $n^1$, kann jetzt höchstens noch der dritte Fall vorliegen.
Um diese Vermutung zu überprüfen, nehmen wir an, dass ein $\gamma < 1$ existiert, so dass die Inhomogenität 
\[ f(n) := n \cdot \log_2(n) \]
die Ungleichung 
\[ \alpha \cdot f(n/\beta) \leq \gamma \cdot f(n) \]
erfüllt.  Einsetzen von $f$ sowie von $\alpha$ und $\beta$ führt auf die Ungleichung
\[ 2 \cdot n/2 \cdot \log_2(n/2) \leq \gamma \cdot n \cdot \log_2(n). \]
Dividieren wir diese Ungleichung durch $n$ und vereinfachen, so erhalten wir
\[ \log_2(n) - \log_2(2) \leq \gamma \cdot \log_2(n). \]
Wegen $\log_2(2) = 1$ addieren wir auf beiden Seiten 1 und subtrahieren $\gamma \cdot \log_2(n)$.
Dann erhalten wir
\[ \log_2(n) \cdot (1 - \gamma) \leq 1, \]
woraus schließlich 
\[ \log_2(n) \leq \bruch{1}{\;1 - \gamma\;} \]
folgt.  Daraus folgt durch Anwenden der Funktion $x \mapsto 2^x$ die Ungleichung
\[ \displaystyle n \leq 2^\frac{1}{\;1 - \gamma\;}, \]
die aber sicher nicht für beliebige $n$ gelten kann.  Damit haben wir einen Widerspruch
zu der Annahme, dass der dritte Fall des Hauptsatzes vorliegt.
\hspace*{\fill} $\Box$
\vspace*{0.3cm}

\noindent
\textbf{Aufgabe}:  Lösen Sie die Rekurrenz-Gleichung
\[ g(n) = 2 \cdot g(n/2) + n \cdot \log_2(n) \quad \mbox{mit der Anfangs-Bedingung $g(1) = 0$} \]
für den Fall, dass $n$ eine Zweier-Potenz ist.
\hspace*{\fill} $\Box$


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "algorithmen"
%%% End: 
